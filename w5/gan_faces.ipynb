{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import time\n",
    "import os\n",
    "\n",
    "from ops import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MachineLearningUser\\AppData\\Local\\conda\\conda\\envs\\ml\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['random', 'imsave', 'imread']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorboard\n",
    "tensorboard.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we are going to train GAN for generating faces and then we will make fun playing with it. Generative adversarial networks (GANs) are deep neural net architectures comprised of two nets, pitting one against the other (thus the “adversarial”). One neural network, called the generator, generates new faces, while the other, the discriminator,  decides whether each instance of face it reviews belongs to the actual training dataset or not.\n",
    "\n",
    "Firstly download aligned faces of celebrities from here <a href=\"https://yadi.sk/d/xjuClJJH3MAVXh\">link</a> and extract them into folder near ipython notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constant variables below depends on your dataset and choosing of architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './aligned_celebA/' # Path to the dataset with celebA faces\n",
    "Z_DIM = 128 # Dimension of face's manifold\n",
    "GENERATOR_DENSE_SIZE = 1024 # Length of first tensor in generator\n",
    "\n",
    "IMAGE_SIZE = 64 # Shapes of input image\n",
    "BATCH_SIZE = 128 # Batch size\n",
    "N_CHANNELS = 3 # Number channels of input image\n",
    "\n",
    "FLIP_LABEL_PROB = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(os.path.exists(DATA_PATH)), 'Please, download aligned celebA to DATA_PATH folder'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define GAN. To do it, we need to define generator, discriminator and loss functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some tips on the architecture of the generator:\n",
    "1. The deeper is convolution, the less filters is using.\n",
    "2. Apply deconvolutions-relu layers to achieve input image shape.\n",
    "3. Use batch normalization before nonlinearity for speed and stability of learning.\n",
    "4. Use tanh activation at the end of network (in this case images should be scaled to [-1, 1])\n",
    "5. To force generator not to collapse and produce different outputs initialize bias with zero (see linear layer).\n",
    "\n",
    "Other useful tips: https://github.com/soumith/ganhacks. Example of architecture see below. You may also use defined layers from ops.py. <b> Please, use names for layers started with \"g\\_\" for generator and \"d_\" for discriminator.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/carpedm20/DCGAN-tensorflow/master/DCGAN.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing generator function (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, is_training):\n",
    "    h_out = linear(z, GENERATOR_DENSE_SIZE * 4 * 4, 'g_h0_lin')\n",
    "    h_out = batch_norm(name='g_bn0')(h_out)\n",
    "    h_out = lrelu(h_out, leak=0.2, name=\"g_h0_lrelu\")    \n",
    "    h_out = tf.reshape(h_out, [-1, 4, 4, GENERATOR_DENSE_SIZE])\n",
    "    \n",
    "    h_out = deconv2d(h_out, [BATCH_SIZE, 4, 4, GENERATOR_DENSE_SIZE], name='g_h1_deconv', k_h=5, k_w=5, d_h=1, d_w=1, use_bias=False)\n",
    "    h_out = batch_norm(name='g_bn1')(h_out)\n",
    "    h_out = lrelu(h_out, leak=0.2, name=\"g_h1_lrelu\")\n",
    "    \n",
    "    h_out = deconv2d(h_out, [BATCH_SIZE, 8, 8, 512], name='g_h2_deconv', k_h=5, k_w=5, d_h=2, d_w=2, use_bias=False)\n",
    "    h_out = batch_norm(name='g_bn2')(h_out)\n",
    "    h_out = lrelu(h_out, leak=0.2, name=\"g_h2_lrelu\")\n",
    "        \n",
    "    h_out = deconv2d(h_out, [BATCH_SIZE, 16, 16, 256], name='g_h3_deconv', k_h=5, k_w=5, d_h=2, d_w=2, use_bias=False)\n",
    "    h_out = batch_norm(name='g_bn3')(h_out)\n",
    "    h_out = lrelu(h_out, leak=0.2, name=\"g_h3_lrelu\")\n",
    "    \n",
    "    h_out = deconv2d(h_out, [BATCH_SIZE, 32, 32, 128], name='g_h4_deconv', use_bias=False)\n",
    "    h_out = batch_norm(name='g_bn4')(h_out)\n",
    "    h_out = lrelu(h_out, leak=0.2, name=\"g_h4_lrelu\")\n",
    "        \n",
    "    h_out = deconv2d(h_out, [BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, N_CHANNELS], name='g_out')\n",
    "\n",
    "    return tf.nn.tanh(h_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define discriminator. Discriminator takes 3d tensor as input and outputs one number - probability that this is an image.\n",
    "\n",
    "Some advice for discriminator's architecture:\n",
    "1. Use batch normalization between convolutions and nonlinearities.\n",
    "2. Use leaky relu with the leak about 0.2.\n",
    "3. The deeper the layer, the more filters you can use.\n",
    "\n",
    "If you use batch normalization, please define every layer in their own scope and pass is_training parameter there. Or you may use class of batch normalization from ops.py. Do not forget to fratten tensor after the convolution blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing discriminator function (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(image, is_training, batch_norms=None):\n",
    "    \n",
    "    h_out = image\n",
    "    \n",
    "    #h_out = tf.nn.dropout(h_out, 0.1)\n",
    "    \n",
    "    h_out = conv2d(h_out, output_dim = 128, k_h = 5, k_w = 5, d_h = 2, d_w = 2, stddev=0.02, name=\"d_h0_conv\")\n",
    "    if batch_norms is not None and len(batch_norms) > 0:\n",
    "        h_out = batch_norms[0](h_out)\n",
    "    h_out = lrelu(h_out, leak=0.2, name=\"d_h0_lrelu\")\n",
    "    h_out = tf.nn.dropout(h_out, 0.3)\n",
    "    \n",
    "    h_out = conv2d(h_out, output_dim = 256, k_h = 5, k_w = 5, d_h = 2, d_w = 2, stddev=0.02, name=\"d_h1_conv\")\n",
    "    if batch_norms is not None and len(batch_norms) > 1:\n",
    "        h_out = batch_norms[1](h_out)\n",
    "    h_out = lrelu(h_out, leak=0.2, name=\"d_h1_lrelu\")\n",
    "    h_out = tf.nn.dropout(h_out, 0.3)\n",
    "    \n",
    "    h_out = conv2d(h_out, output_dim = 512, k_h = 5, k_w = 5, d_h = 2, d_w = 2, stddev=0.02, name=\"d_h2_conv\")\n",
    "    if batch_norms is not None and len(batch_norms) > 2:\n",
    "        h_out = batch_norms[2](h_out)\n",
    "    h_out = lrelu(h_out, leak=0.2, name=\"d_h2_lrelu\")\n",
    "    h_out = tf.nn.dropout(h_out, 0.2)\n",
    "    \n",
    "    h_out = conv2d(h_out, output_dim = 1024, k_h = 5, k_w = 5, d_h = 2, d_w = 2, stddev=0.02, name=\"d_h3_conv\")\n",
    "    if batch_norms is not None and len(batch_norms) > 3:\n",
    "        h_out = batch_norms[3](h_out)\n",
    "    h_out = lrelu(h_out, leak=0.2, name=\"d_h3_lrelu\")\n",
    "    h_out = tf.nn.dropout(h_out, 0.2)\n",
    "    \n",
    "    shape = h_out.get_shape().as_list()    \n",
    "    h_out = tf.reshape(h_out, [-1, np.prod(shape[1:])])\n",
    "    \n",
    "    h_out = linear(h_out, 1024*2, 'd_h4_lin')\n",
    "    h_out = lrelu(h_out, leak=0.2, name=\"d_h4_lrelu\")\n",
    "    h_out = tf.nn.dropout(h_out, 0.1)\n",
    "    \n",
    "    h_out = linear(h_out, 1024, 'd_h5_lin')\n",
    "    h_out = lrelu(h_out, leak=0.2, name=\"d_h5_lrelu\")\n",
    "    h_out = tf.nn.dropout(h_out, 0.1)\n",
    "    \n",
    "    h_out = linear(h_out, 1024, 'd_h6_lin')\n",
    "    h_out = lrelu(h_out, leak=0.2, name=\"d_h6_lrelu\")\n",
    "    h_out = tf.nn.dropout(h_out, 0.1)\n",
    "    \n",
    "    linear_out = linear(h_out, 1, 'd_h7_lin')\n",
    "    \n",
    "    return tf.nn.sigmoid(linear_out), linear_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define generator and discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\arkadiumarena_vsts\\cv_course\\w5\\ops.py:70: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-8-50f522ad7387>:5: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:Large dropout rate: 0.9 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.9 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "\n",
    "with tf.variable_scope(\"G\") as scope:\n",
    "    z = tf.placeholder(tf.float32, [None, Z_DIM], name='z')\n",
    "    G = generator(z, is_training)\n",
    "\n",
    "with tf.variable_scope('D') as scope:\n",
    "    images = tf.placeholder(tf.float32, shape=[None, IMAGE_SIZE, IMAGE_SIZE, N_CHANNELS])\n",
    "    real_labels = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "    fake_labels = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "    \n",
    "    #batch_norms = [   batch_norm(name='d_bn0'),\n",
    "    #                  batch_norm(name='d_bn1'),\n",
    "    #                  batch_norm(name='d_bn2'),\n",
    "    #                  batch_norm(name='d_bn3') ]\n",
    "    \n",
    "    D_real, D_real_logits = discriminator(images, is_training, \n",
    "                                          batch_norms = None)\n",
    "    \n",
    "    scope.reuse_variables()\n",
    "    D_fake, D_fake_logits = discriminator(G, is_training, \n",
    "                                          batch_norms = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'G/Tanh:0' shape=(128, 64, 64, 3) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'D/Sigmoid_1:0' shape=(128, 1) dtype=float32>,\n",
       " <tf.Tensor 'D/d_h7_lin_1/add:0' shape=(128, 1) dtype=float32>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_fake, D_fake_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write definition of loss funstions according to formulas:\n",
    "$$ D\\_loss = \\frac{-1}{m} \\sum_{i=1}^{m}[\\log{D(x_i)} + \\log{(1 - D(G(z_i)))}]$$\n",
    "$$ G\\_loss = \\frac{1}{m} \\sum_{i=1}^{m} \\log{(1 - D(G(z_i)))}$$\n",
    "\n",
    "Or for better learning you may try other loss for generator:\n",
    "$$ G\\_loss = \\frac{-1}{m} \\sum_{i=1}^{m} \\log{(D(G(z_i)))}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing loss functions (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_loss_real = -tf.reduce_mean( tf.log(D_real) * real_labels  )\n",
    "\n",
    "d_loss_fake = -tf.reduce_mean( tf.log(1. - D_fake) * (1. - fake_labels) )\n",
    "\n",
    "#d_loss = d_loss_real + d_loss_fake\n",
    "#d_loss = -tf.reduce_mean( tf.log(D_real) + tf.log(1. - D_fake) )\n",
    "\n",
    "g_loss = -tf.reduce_mean(tf.log(D_fake))\n",
    "#g_loss = tf.reduce_mean(tf.log(1. - D_fake))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create optimizers. We use different optimizers for discriminator and generator, so we needed a separate prefix for the discriminator and generator variables (g_ for generator, d_ for disciminator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D params: 53920001\n",
      "G params: 45577347\n"
     ]
    }
   ],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "## All variables of discriminator\n",
    "d_vars = [v for v in tvars if 'd_' in v.name]\n",
    "print(\"D params:\", np.sum([ np.prod(v.get_shape().as_list()) for v in d_vars ]) )\n",
    "\n",
    "## All variables of generator\n",
    "g_vars = [v for v in tvars if 'g_' in v.name]\n",
    "print(\"G params:\", np.sum([ np.prod(v.get_shape().as_list()) for v in g_vars ]) )\n",
    "\n",
    "LEARNING_RATE = 0.00001 # Learning rate for adam optimizer\n",
    "BETA = 0.8 # Beta paramater in adam optimizer\n",
    "\n",
    "##Optimizers - ypu may use your favourite instead.\n",
    "#d_optim = tf.train.AdamOptimizer(LEARNING_RATE, beta1=BETA) \\\n",
    "#                  .minimize(d_loss, var_list=d_vars)\n",
    "d_real_optim = tf.train.AdamOptimizer(LEARNING_RATE, beta1=BETA) \\\n",
    "                  .minimize(d_loss_real, var_list=d_vars)\n",
    "d_fake_optim = tf.train.AdamOptimizer(LEARNING_RATE, beta1=BETA) \\\n",
    "                  .minimize(d_loss_fake, var_list=d_vars)\n",
    "# SGD for discriminator \n",
    "\n",
    "g_optim = tf.train.AdamOptimizer(LEARNING_RATE, beta1=BETA) \\\n",
    "                  .minimize(g_loss, var_list=g_vars) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = glob(os.path.join(DATA_PATH, \"*.jpg\"))\n",
    "assert(len(data) > 0), \"Length of training data should be more than zero\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = get_image(data[0], IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0, 0.9921568627450981)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(img), np.max(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = inverse_transform([img])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a26734a688>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'is_training:0' shape=<unknown> dtype=bool>,)\n",
      "(<tf.Tensor 'G/z:0' shape=(?, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/Matrix/Initializer/random_normal/shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/Matrix/Initializer/random_normal/mean:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/Matrix/Initializer/random_normal/stddev:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/Matrix/Initializer/random_normal/RandomStandardNormal:0' shape=(128, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/Matrix/Initializer/random_normal/mul:0' shape=(128, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/Matrix/Initializer/random_normal:0' shape=(128, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/Matrix:0' shape=(128, 16384) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/Matrix/Assign:0' shape=(128, 16384) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/Matrix/read:0' shape=(128, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/bias/Initializer/Const:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/bias:0' shape=(16384,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/bias/Assign:0' shape=(16384,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/bias/read:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/MatMul:0' shape=(?, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/add:0' shape=(?, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0_1/Reshape/shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_bn0_1/Reshape:0' shape=(?, 1, 1, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0/beta/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_bn0/beta/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0/beta/Initializer/zeros:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0/beta:0' shape=(16384,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn0/beta/Assign:0' shape=(16384,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn0/beta/read:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0/gamma/Initializer/ones/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_bn0/gamma/Initializer/ones/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0/gamma/Initializer/ones:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0/gamma:0' shape=(16384,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn0/gamma/Assign:0' shape=(16384,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn0/gamma/read:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0/moving_mean/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_bn0/moving_mean/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0/moving_mean/Initializer/zeros:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0/moving_mean:0' shape=(16384,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn0/moving_mean/Assign:0' shape=(16384,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn0/moving_mean/read:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0/moving_variance/Initializer/ones/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_bn0/moving_variance/Initializer/ones/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0/moving_variance/Initializer/ones:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0/moving_variance:0' shape=(16384,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn0/moving_variance/Assign:0' shape=(16384,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn0/moving_variance/read:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0_1/Const:0' shape=(0,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0_1/Const_1:0' shape=(0,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0_1/FusedBatchNormV3:0' shape=(?, 1, 1, 16384) dtype=float32>, <tf.Tensor 'G/g_bn0_1/FusedBatchNormV3:1' shape=(16384,) dtype=float32>, <tf.Tensor 'G/g_bn0_1/FusedBatchNormV3:2' shape=(16384,) dtype=float32>, <tf.Tensor 'G/g_bn0_1/FusedBatchNormV3:3' shape=(16384,) dtype=float32>, <tf.Tensor 'G/g_bn0_1/FusedBatchNormV3:4' shape=(16384,) dtype=float32>, <tf.Tensor 'G/g_bn0_1/FusedBatchNormV3:5' shape=<unknown> dtype=float32>)\n",
      "(<tf.Tensor 'G/g_bn0_1/AssignMovingAvg/decay:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0_1/AssignMovingAvg/sub:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0_1/AssignMovingAvg/mul:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0_1/AssignMovingAvg:0' shape=(16384,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn0_1/AssignMovingAvg_1/decay:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0_1/AssignMovingAvg_1/sub:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0_1/AssignMovingAvg_1/mul:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0_1/AssignMovingAvg_1:0' shape=(16384,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn0_1/Identity:0' shape=(?, 1, 1, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0_1/Shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_bn0_1/Reshape_1:0' shape=(?, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lrelu/mul/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lrelu/mul:0' shape=(?, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lrelu/Abs:0' shape=(?, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lrelu/mul_1/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lrelu/mul_1:0' shape=(?, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lrelu/add:0' shape=(?, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'G/Reshape/shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/Reshape:0' shape=(?, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h1_deconv/w/Initializer/random_normal/shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_h1_deconv/w/Initializer/random_normal/mean:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h1_deconv/w/Initializer/random_normal/stddev:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h1_deconv/w/Initializer/random_normal/RandomStandardNormal:0' shape=(5, 5, 1024, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h1_deconv/w/Initializer/random_normal/mul:0' shape=(5, 5, 1024, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h1_deconv/w/Initializer/random_normal:0' shape=(5, 5, 1024, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h1_deconv/w:0' shape=(5, 5, 1024, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h1_deconv/w/Assign:0' shape=(5, 5, 1024, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h1_deconv/w/read:0' shape=(5, 5, 1024, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h1_deconv/conv2d_transpose/input_sizes:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_h1_deconv/conv2d_transpose:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1/beta/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_bn1/beta/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1/beta/Initializer/zeros:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1/beta:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn1/beta/Assign:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn1/beta/read:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1/gamma/Initializer/ones/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_bn1/gamma/Initializer/ones/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1/gamma/Initializer/ones:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1/gamma:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn1/gamma/Assign:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn1/gamma/read:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1/moving_mean/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_bn1/moving_mean/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1/moving_mean/Initializer/zeros:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1/moving_mean:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn1/moving_mean/Assign:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn1/moving_mean/read:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1/moving_variance/Initializer/ones/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_bn1/moving_variance/Initializer/ones/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1/moving_variance/Initializer/ones:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1/moving_variance:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn1/moving_variance/Assign:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn1/moving_variance/read:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1_1/Const:0' shape=(0,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1_1/Const_1:0' shape=(0,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1_1/FusedBatchNormV3:0' shape=(128, 4, 4, 1024) dtype=float32>, <tf.Tensor 'G/g_bn1_1/FusedBatchNormV3:1' shape=(1024,) dtype=float32>, <tf.Tensor 'G/g_bn1_1/FusedBatchNormV3:2' shape=(1024,) dtype=float32>, <tf.Tensor 'G/g_bn1_1/FusedBatchNormV3:3' shape=(1024,) dtype=float32>, <tf.Tensor 'G/g_bn1_1/FusedBatchNormV3:4' shape=(1024,) dtype=float32>, <tf.Tensor 'G/g_bn1_1/FusedBatchNormV3:5' shape=<unknown> dtype=float32>)\n",
      "(<tf.Tensor 'G/g_bn1_1/AssignMovingAvg/decay:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1_1/AssignMovingAvg/sub:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1_1/AssignMovingAvg/mul:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1_1/AssignMovingAvg:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn1_1/AssignMovingAvg_1/decay:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1_1/AssignMovingAvg_1/sub:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1_1/AssignMovingAvg_1/mul:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1_1/AssignMovingAvg_1:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn1_1/Identity:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h1_lrelu/mul/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h1_lrelu/mul:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h1_lrelu/Abs:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h1_lrelu/mul_1/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h1_lrelu/mul_1:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h1_lrelu/add:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h2_deconv/w/Initializer/random_normal/shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_h2_deconv/w/Initializer/random_normal/mean:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h2_deconv/w/Initializer/random_normal/stddev:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h2_deconv/w/Initializer/random_normal/RandomStandardNormal:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h2_deconv/w/Initializer/random_normal/mul:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h2_deconv/w/Initializer/random_normal:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h2_deconv/w:0' shape=(5, 5, 512, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h2_deconv/w/Assign:0' shape=(5, 5, 512, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h2_deconv/w/read:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h2_deconv/conv2d_transpose/input_sizes:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_h2_deconv/conv2d_transpose:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn2/beta/Initializer/zeros:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn2/beta:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn2/beta/Assign:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn2/beta/read:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn2/gamma/Initializer/ones:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn2/gamma:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn2/gamma/Assign:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn2/gamma/read:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn2/moving_mean/Initializer/zeros:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn2/moving_mean:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn2/moving_mean/Assign:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn2/moving_mean/read:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn2/moving_variance/Initializer/ones:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn2/moving_variance:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn2/moving_variance/Assign:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn2/moving_variance/read:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn2_1/Const:0' shape=(0,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn2_1/Const_1:0' shape=(0,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn2_1/FusedBatchNormV3:0' shape=(128, 8, 8, 512) dtype=float32>, <tf.Tensor 'G/g_bn2_1/FusedBatchNormV3:1' shape=(512,) dtype=float32>, <tf.Tensor 'G/g_bn2_1/FusedBatchNormV3:2' shape=(512,) dtype=float32>, <tf.Tensor 'G/g_bn2_1/FusedBatchNormV3:3' shape=(512,) dtype=float32>, <tf.Tensor 'G/g_bn2_1/FusedBatchNormV3:4' shape=(512,) dtype=float32>, <tf.Tensor 'G/g_bn2_1/FusedBatchNormV3:5' shape=<unknown> dtype=float32>)\n",
      "(<tf.Tensor 'G/g_bn2_1/AssignMovingAvg/decay:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn2_1/AssignMovingAvg/sub:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn2_1/AssignMovingAvg/mul:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn2_1/AssignMovingAvg:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn2_1/AssignMovingAvg_1/decay:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn2_1/AssignMovingAvg_1/sub:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn2_1/AssignMovingAvg_1/mul:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn2_1/AssignMovingAvg_1:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn2_1/Identity:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h2_lrelu/mul/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h2_lrelu/mul:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h2_lrelu/Abs:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h2_lrelu/mul_1/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h2_lrelu/mul_1:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h2_lrelu/add:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h3_deconv/w/Initializer/random_normal/shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_h3_deconv/w/Initializer/random_normal/mean:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h3_deconv/w/Initializer/random_normal/stddev:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h3_deconv/w/Initializer/random_normal/RandomStandardNormal:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h3_deconv/w/Initializer/random_normal/mul:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h3_deconv/w/Initializer/random_normal:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h3_deconv/w:0' shape=(5, 5, 256, 512) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h3_deconv/w/Assign:0' shape=(5, 5, 256, 512) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h3_deconv/w/read:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h3_deconv/conv2d_transpose/input_sizes:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_h3_deconv/conv2d_transpose:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn3/beta/Initializer/zeros:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn3/beta:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn3/beta/Assign:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn3/beta/read:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn3/gamma/Initializer/ones:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn3/gamma:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn3/gamma/Assign:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn3/gamma/read:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn3/moving_mean/Initializer/zeros:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn3/moving_mean:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn3/moving_mean/Assign:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn3/moving_mean/read:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn3/moving_variance/Initializer/ones:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn3/moving_variance:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn3/moving_variance/Assign:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn3/moving_variance/read:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn3_1/Const:0' shape=(0,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn3_1/Const_1:0' shape=(0,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn3_1/FusedBatchNormV3:0' shape=(128, 16, 16, 256) dtype=float32>, <tf.Tensor 'G/g_bn3_1/FusedBatchNormV3:1' shape=(256,) dtype=float32>, <tf.Tensor 'G/g_bn3_1/FusedBatchNormV3:2' shape=(256,) dtype=float32>, <tf.Tensor 'G/g_bn3_1/FusedBatchNormV3:3' shape=(256,) dtype=float32>, <tf.Tensor 'G/g_bn3_1/FusedBatchNormV3:4' shape=(256,) dtype=float32>, <tf.Tensor 'G/g_bn3_1/FusedBatchNormV3:5' shape=<unknown> dtype=float32>)\n",
      "(<tf.Tensor 'G/g_bn3_1/AssignMovingAvg/decay:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn3_1/AssignMovingAvg/sub:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn3_1/AssignMovingAvg/mul:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn3_1/AssignMovingAvg:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn3_1/AssignMovingAvg_1/decay:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn3_1/AssignMovingAvg_1/sub:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn3_1/AssignMovingAvg_1/mul:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn3_1/AssignMovingAvg_1:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn3_1/Identity:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h3_lrelu/mul/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h3_lrelu/mul:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h3_lrelu/Abs:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h3_lrelu/mul_1/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h3_lrelu/mul_1:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h3_lrelu/add:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h4_deconv/w/Initializer/random_normal/shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_h4_deconv/w/Initializer/random_normal/mean:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h4_deconv/w/Initializer/random_normal/stddev:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h4_deconv/w/Initializer/random_normal/RandomStandardNormal:0' shape=(5, 5, 128, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h4_deconv/w/Initializer/random_normal/mul:0' shape=(5, 5, 128, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h4_deconv/w/Initializer/random_normal:0' shape=(5, 5, 128, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h4_deconv/w:0' shape=(5, 5, 128, 256) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h4_deconv/w/Assign:0' shape=(5, 5, 128, 256) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h4_deconv/w/read:0' shape=(5, 5, 128, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h4_deconv/conv2d_transpose/input_sizes:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_h4_deconv/conv2d_transpose:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn4/beta/Initializer/zeros:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn4/beta:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn4/beta/Assign:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn4/beta/read:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn4/gamma/Initializer/ones:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn4/gamma:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn4/gamma/Assign:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn4/gamma/read:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn4/moving_mean/Initializer/zeros:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn4/moving_mean:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn4/moving_mean/Assign:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn4/moving_mean/read:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn4/moving_variance/Initializer/ones:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn4/moving_variance:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn4/moving_variance/Assign:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn4/moving_variance/read:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn4_1/Const:0' shape=(0,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn4_1/Const_1:0' shape=(0,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn4_1/FusedBatchNormV3:0' shape=(128, 32, 32, 128) dtype=float32>, <tf.Tensor 'G/g_bn4_1/FusedBatchNormV3:1' shape=(128,) dtype=float32>, <tf.Tensor 'G/g_bn4_1/FusedBatchNormV3:2' shape=(128,) dtype=float32>, <tf.Tensor 'G/g_bn4_1/FusedBatchNormV3:3' shape=(128,) dtype=float32>, <tf.Tensor 'G/g_bn4_1/FusedBatchNormV3:4' shape=(128,) dtype=float32>, <tf.Tensor 'G/g_bn4_1/FusedBatchNormV3:5' shape=<unknown> dtype=float32>)\n",
      "(<tf.Tensor 'G/g_bn4_1/AssignMovingAvg/decay:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn4_1/AssignMovingAvg/sub:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn4_1/AssignMovingAvg/mul:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn4_1/AssignMovingAvg:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn4_1/AssignMovingAvg_1/decay:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn4_1/AssignMovingAvg_1/sub:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn4_1/AssignMovingAvg_1/mul:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn4_1/AssignMovingAvg_1:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn4_1/Identity:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h4_lrelu/mul/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h4_lrelu/mul:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h4_lrelu/Abs:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h4_lrelu/mul_1/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h4_lrelu/mul_1:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h4_lrelu/add:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_out/w/Initializer/random_normal/shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_out/w/Initializer/random_normal/mean:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_out/w/Initializer/random_normal/stddev:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_out/w/Initializer/random_normal/RandomStandardNormal:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_out/w/Initializer/random_normal/mul:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_out/w/Initializer/random_normal:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_out/w:0' shape=(5, 5, 3, 128) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_out/w/Assign:0' shape=(5, 5, 3, 128) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_out/w/read:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_out/conv2d_transpose/input_sizes:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_out/conv2d_transpose:0' shape=(128, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_out/biases/Initializer/Const:0' shape=(3,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_out/biases:0' shape=(3,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_out/biases/Assign:0' shape=(3,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_out/biases/read:0' shape=(3,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_out/BiasAdd:0' shape=(128, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_out/Reshape/shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_out/Reshape:0' shape=(128, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'G/Tanh:0' shape=(128, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'D/Placeholder:0' shape=(?, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'D/Placeholder_1:0' shape=(?, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'D/Placeholder_2:0' shape=(?, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout/rate:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout/Shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/dropout/random_uniform/min:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout/random_uniform/max:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout/random_uniform/RandomUniform:0' shape=(?, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout/random_uniform/sub:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout/random_uniform/mul:0' shape=(?, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout/random_uniform:0' shape=(?, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout/sub/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout/sub:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout/truediv/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout/truediv:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout/GreaterEqual:0' shape=(?, 64, 64, 3) dtype=bool>,)\n",
      "(<tf.Tensor 'D/dropout/mul:0' shape=(?, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout/Cast:0' shape=(?, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout/mul_1:0' shape=(?, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Initializer/truncated_normal/shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Initializer/truncated_normal/mean:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Initializer/truncated_normal/stddev:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Initializer/truncated_normal/TruncatedNormal:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Initializer/truncated_normal/mul:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Initializer/truncated_normal:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w:0' shape=(5, 5, 3, 128) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Assign:0' shape=(5, 5, 3, 128) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/read:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/Conv2D:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/biases/Initializer/Const:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/biases:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/biases/Assign:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/biases/read:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/BiasAdd:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_lrelu/mul/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_lrelu/mul:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_lrelu/Abs:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_lrelu/mul_1/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_lrelu/mul_1:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_lrelu/add:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_1/rate:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_1/Shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/dropout_1/random_uniform/min:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_1/random_uniform/max:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_1/random_uniform/RandomUniform:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_1/random_uniform/sub:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_1/random_uniform/mul:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_1/random_uniform:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_1/sub/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_1/sub:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_1/truediv/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_1/truediv:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_1/GreaterEqual:0' shape=(?, 32, 32, 128) dtype=bool>,)\n",
      "(<tf.Tensor 'D/dropout_1/mul:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_1/Cast:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_1/mul_1:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Initializer/truncated_normal/shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Initializer/truncated_normal/mean:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Initializer/truncated_normal/stddev:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Initializer/truncated_normal/TruncatedNormal:0' shape=(5, 5, 128, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Initializer/truncated_normal/mul:0' shape=(5, 5, 128, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Initializer/truncated_normal:0' shape=(5, 5, 128, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w:0' shape=(5, 5, 128, 256) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Assign:0' shape=(5, 5, 128, 256) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/read:0' shape=(5, 5, 128, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/Conv2D:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/biases/Initializer/Const:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/biases:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/biases/Assign:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/biases/read:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/BiasAdd:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_lrelu/mul/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_lrelu/mul:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_lrelu/Abs:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_lrelu/mul_1/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_lrelu/mul_1:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_lrelu/add:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_2/rate:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_2/Shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/dropout_2/random_uniform/min:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_2/random_uniform/max:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_2/random_uniform/RandomUniform:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_2/random_uniform/sub:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_2/random_uniform/mul:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_2/random_uniform:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_2/sub/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_2/sub:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_2/truediv/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_2/truediv:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_2/GreaterEqual:0' shape=(?, 16, 16, 256) dtype=bool>,)\n",
      "(<tf.Tensor 'D/dropout_2/mul:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_2/Cast:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_2/mul_1:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Initializer/truncated_normal/shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Initializer/truncated_normal/mean:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Initializer/truncated_normal/stddev:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Initializer/truncated_normal/TruncatedNormal:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Initializer/truncated_normal/mul:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Initializer/truncated_normal:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w:0' shape=(5, 5, 256, 512) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Assign:0' shape=(5, 5, 256, 512) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/read:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/Conv2D:0' shape=(?, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/biases/Initializer/Const:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/biases:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/biases/Assign:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/biases/read:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/BiasAdd:0' shape=(?, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_lrelu/mul/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_lrelu/mul:0' shape=(?, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_lrelu/Abs:0' shape=(?, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_lrelu/mul_1/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_lrelu/mul_1:0' shape=(?, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_lrelu/add:0' shape=(?, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Initializer/truncated_normal/shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Initializer/truncated_normal/mean:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Initializer/truncated_normal/stddev:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Initializer/truncated_normal/TruncatedNormal:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Initializer/truncated_normal/mul:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Initializer/truncated_normal:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w:0' shape=(5, 5, 512, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Assign:0' shape=(5, 5, 512, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/read:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/Conv2D:0' shape=(?, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases/Initializer/Const:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases/Assign:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases/read:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/BiasAdd:0' shape=(?, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_lrelu/mul/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_lrelu/mul:0' shape=(?, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_lrelu/Abs:0' shape=(?, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_lrelu/mul_1/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_lrelu/mul_1:0' shape=(?, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_lrelu/add:0' shape=(?, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/Reshape/shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/Reshape:0' shape=(?, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Initializer/random_normal/shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Initializer/random_normal/mean:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Initializer/random_normal/stddev:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Initializer/random_normal/RandomStandardNormal:0' shape=(16384, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Initializer/random_normal/mul:0' shape=(16384, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Initializer/random_normal:0' shape=(16384, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix:0' shape=(16384, 2048) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Assign:0' shape=(16384, 2048) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/read:0' shape=(16384, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias/Initializer/Const:0' shape=(2048,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias:0' shape=(2048,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias/Assign:0' shape=(2048,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias/read:0' shape=(2048,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/MatMul:0' shape=(?, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/add:0' shape=(?, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lrelu/mul/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lrelu/mul:0' shape=(?, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lrelu/Abs:0' shape=(?, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lrelu/mul_1/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lrelu/mul_1:0' shape=(?, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lrelu/add:0' shape=(?, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Initializer/random_normal/shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Initializer/random_normal/mean:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Initializer/random_normal/stddev:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Initializer/random_normal/RandomStandardNormal:0' shape=(2048, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Initializer/random_normal/mul:0' shape=(2048, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Initializer/random_normal:0' shape=(2048, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix:0' shape=(2048, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Assign:0' shape=(2048, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/read:0' shape=(2048, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias/Initializer/Const:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias/Assign:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias/read:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/MatMul:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/add:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lrelu/mul/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lrelu/mul:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lrelu/Abs:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lrelu/mul_1/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lrelu/mul_1:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lrelu/add:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Initializer/random_normal/shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Initializer/random_normal/mean:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Initializer/random_normal/stddev:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Initializer/random_normal/RandomStandardNormal:0' shape=(1024, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Initializer/random_normal/mul:0' shape=(1024, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Initializer/random_normal:0' shape=(1024, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix:0' shape=(1024, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Assign:0' shape=(1024, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/read:0' shape=(1024, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias/Initializer/Const:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias/Assign:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias/read:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/MatMul:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/add:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lrelu/mul/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lrelu/mul:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lrelu/Abs:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lrelu/mul_1/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lrelu/mul_1:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lrelu/add:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Initializer/random_normal/shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Initializer/random_normal/mean:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Initializer/random_normal/stddev:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Initializer/random_normal/RandomStandardNormal:0' shape=(1024, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Initializer/random_normal/mul:0' shape=(1024, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Initializer/random_normal:0' shape=(1024, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix:0' shape=(1024, 1) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Assign:0' shape=(1024, 1) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/read:0' shape=(1024, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/bias/Initializer/Const:0' shape=(1,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/bias:0' shape=(1,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/bias/Assign:0' shape=(1,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/bias/read:0' shape=(1,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/MatMul:0' shape=(?, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/add:0' shape=(?, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'D/Sigmoid:0' shape=(?, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_3/rate:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_3/Shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/dropout_3/random_uniform/min:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_3/random_uniform/max:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_3/random_uniform/RandomUniform:0' shape=(128, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_3/random_uniform/sub:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_3/random_uniform/mul:0' shape=(128, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_3/random_uniform:0' shape=(128, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_3/sub/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_3/sub:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_3/truediv/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_3/truediv:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_3/GreaterEqual:0' shape=(128, 64, 64, 3) dtype=bool>,)\n",
      "(<tf.Tensor 'D/dropout_3/mul:0' shape=(128, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_3/Cast:0' shape=(128, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_3/mul_1:0' shape=(128, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv_1/Conv2D:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv_1/BiasAdd:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_lrelu_1/mul/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_lrelu_1/mul:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_lrelu_1/Abs:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_lrelu_1/mul_1/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_lrelu_1/mul_1:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_lrelu_1/add:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_4/rate:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_4/Shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/dropout_4/random_uniform/min:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_4/random_uniform/max:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_4/random_uniform/RandomUniform:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_4/random_uniform/sub:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_4/random_uniform/mul:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_4/random_uniform:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_4/sub/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_4/sub:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_4/truediv/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_4/truediv:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_4/GreaterEqual:0' shape=(128, 32, 32, 128) dtype=bool>,)\n",
      "(<tf.Tensor 'D/dropout_4/mul:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_4/Cast:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_4/mul_1:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv_1/Conv2D:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv_1/BiasAdd:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_lrelu_1/mul/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_lrelu_1/mul:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_lrelu_1/Abs:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_lrelu_1/mul_1/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_lrelu_1/mul_1:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_lrelu_1/add:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_5/rate:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_5/Shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/dropout_5/random_uniform/min:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_5/random_uniform/max:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_5/random_uniform/RandomUniform:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_5/random_uniform/sub:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_5/random_uniform/mul:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_5/random_uniform:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_5/sub/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_5/sub:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_5/truediv/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_5/truediv:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_5/GreaterEqual:0' shape=(128, 16, 16, 256) dtype=bool>,)\n",
      "(<tf.Tensor 'D/dropout_5/mul:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_5/Cast:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/dropout_5/mul_1:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv_1/Conv2D:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv_1/BiasAdd:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_lrelu_1/mul/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_lrelu_1/mul:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_lrelu_1/Abs:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_lrelu_1/mul_1/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_lrelu_1/mul_1:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_lrelu_1/add:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv_1/Conv2D:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv_1/BiasAdd:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_lrelu_1/mul/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_lrelu_1/mul:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_lrelu_1/Abs:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_lrelu_1/mul_1/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_lrelu_1/mul_1:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_lrelu_1/add:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/Reshape_1/shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/Reshape_1:0' shape=(128, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin_1/MatMul:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin_1/add:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lrelu_1/mul/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lrelu_1/mul:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lrelu_1/Abs:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lrelu_1/mul_1/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lrelu_1/mul_1:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lrelu_1/add:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin_1/MatMul:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin_1/add:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lrelu_1/mul/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lrelu_1/mul:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lrelu_1/Abs:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lrelu_1/mul_1/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lrelu_1/mul_1:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lrelu_1/add:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin_1/MatMul:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin_1/add:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lrelu_1/mul/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lrelu_1/mul:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lrelu_1/Abs:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lrelu_1/mul_1/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lrelu_1/mul_1:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lrelu_1/add:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin_1/MatMul:0' shape=(128, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin_1/add:0' shape=(128, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'D/Sigmoid_1:0' shape=(128, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'Log:0' shape=(?, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'mul:0' shape=(?, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'Const:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'Mean:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'Neg:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'sub/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'sub:0' shape=(128, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'Log_1:0' shape=(128, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'sub_1/x:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'sub_1:0' shape=(?, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'mul_1:0' shape=(128, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'Const_1:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'Mean_1:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'Neg_1:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'Log_2:0' shape=(128, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'Const_2:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'Mean_2:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'Neg_2:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/Shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/grad_ys_0:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/Fill:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/Neg_grad/Neg:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/Mean_grad/Reshape/shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/Mean_grad/Reshape:0' shape=(1, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/Mean_grad/Shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/Mean_grad/Tile:0' shape=(?, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/Mean_grad/Shape_1:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/Mean_grad/Shape_2:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/Mean_grad/Const:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/Mean_grad/Prod:0' shape=() dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/Mean_grad/Const_1:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/Mean_grad/Prod_1:0' shape=() dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/Mean_grad/Maximum/y:0' shape=() dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/Mean_grad/Maximum:0' shape=() dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/Mean_grad/floordiv:0' shape=() dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/Mean_grad/Cast:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/Mean_grad/truediv:0' shape=(?, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/mul_grad/Shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/mul_grad/Shape_1:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/mul_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/mul_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/mul_grad/Mul:0' shape=(?, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/mul_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/mul_grad/Reshape:0' shape=(?, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/mul_grad/Mul_1:0' shape=(?, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/mul_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/mul_grad/Reshape_1:0' shape=(?, 1) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/mul_grad/tuple/control_dependency:0' shape=(?, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/mul_grad/tuple/control_dependency_1:0' shape=(?, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/Log_grad/Reciprocal:0' shape=(?, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/Log_grad/mul:0' shape=(?, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/Sigmoid_grad/SigmoidGrad:0' shape=(?, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h7_lin/add_grad/Shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h7_lin/add_grad/Shape_1:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h7_lin/add_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/d_h7_lin/add_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h7_lin/add_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h7_lin/add_grad/Reshape:0' shape=(?, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h7_lin/add_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h7_lin/add_grad/Reshape_1:0' shape=(1,) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h7_lin/add_grad/tuple/control_dependency:0' shape=(?, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h7_lin/add_grad/tuple/control_dependency_1:0' shape=(1,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h7_lin/MatMul_grad/MatMul:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h7_lin/MatMul_grad/MatMul_1:0' shape=(1024, 1) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h7_lin/MatMul_grad/tuple/control_dependency:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h7_lin/MatMul_grad/tuple/control_dependency_1:0' shape=(1024, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/add_grad/Shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/add_grad/Shape_1:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/add_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/d_h6_lrelu/add_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/add_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/add_grad/Reshape:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/add_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/add_grad/Reshape_1:0' shape=(?, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/add_grad/tuple/control_dependency:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/add_grad/tuple/control_dependency_1:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/mul_grad/Shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/mul_grad/Shape_1:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/mul_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/d_h6_lrelu/mul_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/mul_grad/Mul:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/mul_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/mul_grad/Mul_1:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/mul_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/mul_grad/Reshape_1:0' shape=(?, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/mul_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/mul_grad/tuple/control_dependency_1:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/mul_1_grad/Shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/mul_1_grad/Shape_1:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/mul_1_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/d_h6_lrelu/mul_1_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/mul_1_grad/Mul:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/mul_1_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/mul_1_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/mul_1_grad/Mul_1:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/mul_1_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/mul_1_grad/Reshape_1:0' shape=(?, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/mul_1_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/mul_1_grad/tuple/control_dependency_1:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/Abs_grad/Sign:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lrelu/Abs_grad/mul:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/AddN:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lin/add_grad/Shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lin/add_grad/Shape_1:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lin/add_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/d_h6_lin/add_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lin/add_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lin/add_grad/Reshape:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lin/add_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lin/add_grad/Reshape_1:0' shape=(1024,) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h6_lin/add_grad/tuple/control_dependency:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lin/add_grad/tuple/control_dependency_1:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lin/MatMul_grad/MatMul:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lin/MatMul_grad/MatMul_1:0' shape=(1024, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h6_lin/MatMul_grad/tuple/control_dependency:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h6_lin/MatMul_grad/tuple/control_dependency_1:0' shape=(1024, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/add_grad/Shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/add_grad/Shape_1:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/add_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/d_h5_lrelu/add_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/add_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/add_grad/Reshape:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/add_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/add_grad/Reshape_1:0' shape=(?, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/add_grad/tuple/control_dependency:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/add_grad/tuple/control_dependency_1:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/mul_grad/Shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/mul_grad/Shape_1:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/mul_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/d_h5_lrelu/mul_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/mul_grad/Mul:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/mul_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/mul_grad/Mul_1:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/mul_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/mul_grad/Reshape_1:0' shape=(?, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/mul_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/mul_grad/tuple/control_dependency_1:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/mul_1_grad/Shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/mul_1_grad/Shape_1:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/mul_1_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/d_h5_lrelu/mul_1_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/mul_1_grad/Mul:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/mul_1_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/mul_1_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/mul_1_grad/Mul_1:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/mul_1_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/mul_1_grad/Reshape_1:0' shape=(?, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/mul_1_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/mul_1_grad/tuple/control_dependency_1:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/Abs_grad/Sign:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lrelu/Abs_grad/mul:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/AddN_1:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lin/add_grad/Shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lin/add_grad/Shape_1:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lin/add_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/d_h5_lin/add_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lin/add_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lin/add_grad/Reshape:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lin/add_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lin/add_grad/Reshape_1:0' shape=(1024,) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h5_lin/add_grad/tuple/control_dependency:0' shape=(?, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lin/add_grad/tuple/control_dependency_1:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lin/MatMul_grad/MatMul:0' shape=(?, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lin/MatMul_grad/MatMul_1:0' shape=(2048, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h5_lin/MatMul_grad/tuple/control_dependency:0' shape=(?, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h5_lin/MatMul_grad/tuple/control_dependency_1:0' shape=(2048, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/add_grad/Shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/add_grad/Shape_1:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/add_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/d_h4_lrelu/add_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/add_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/add_grad/Reshape:0' shape=(?, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/add_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/add_grad/Reshape_1:0' shape=(?, 2048) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/add_grad/tuple/control_dependency:0' shape=(?, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/add_grad/tuple/control_dependency_1:0' shape=(?, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/mul_grad/Shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/mul_grad/Shape_1:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/mul_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/d_h4_lrelu/mul_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/mul_grad/Mul:0' shape=(?, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/mul_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/mul_grad/Mul_1:0' shape=(?, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/mul_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/mul_grad/Reshape_1:0' shape=(?, 2048) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/mul_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/mul_grad/tuple/control_dependency_1:0' shape=(?, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/mul_1_grad/Shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/mul_1_grad/Shape_1:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/mul_1_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/d_h4_lrelu/mul_1_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/mul_1_grad/Mul:0' shape=(?, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/mul_1_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/mul_1_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/mul_1_grad/Mul_1:0' shape=(?, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/mul_1_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/mul_1_grad/Reshape_1:0' shape=(?, 2048) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/mul_1_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/mul_1_grad/tuple/control_dependency_1:0' shape=(?, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/Abs_grad/Sign:0' shape=(?, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lrelu/Abs_grad/mul:0' shape=(?, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/AddN_2:0' shape=(?, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lin/add_grad/Shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lin/add_grad/Shape_1:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lin/add_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/d_h4_lin/add_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lin/add_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lin/add_grad/Reshape:0' shape=(?, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lin/add_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lin/add_grad/Reshape_1:0' shape=(2048,) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h4_lin/add_grad/tuple/control_dependency:0' shape=(?, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lin/add_grad/tuple/control_dependency_1:0' shape=(2048,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lin/MatMul_grad/MatMul:0' shape=(?, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lin/MatMul_grad/MatMul_1:0' shape=(16384, 2048) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h4_lin/MatMul_grad/tuple/control_dependency:0' shape=(?, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h4_lin/MatMul_grad/tuple/control_dependency_1:0' shape=(16384, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/Reshape_grad/Shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/Reshape_grad/Reshape:0' shape=(?, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/add_grad/Shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/add_grad/Shape_1:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/add_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/d_h3_lrelu/add_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/add_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/add_grad/Reshape:0' shape=(?, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/add_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/add_grad/Reshape_1:0' shape=(?, 4, 4, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/add_grad/tuple/control_dependency:0' shape=(?, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/add_grad/tuple/control_dependency_1:0' shape=(?, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/mul_grad/Shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/mul_grad/Shape_1:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/mul_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/d_h3_lrelu/mul_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/mul_grad/Mul:0' shape=(?, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/mul_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/mul_grad/Mul_1:0' shape=(?, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/mul_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/mul_grad/Reshape_1:0' shape=(?, 4, 4, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/mul_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/mul_grad/tuple/control_dependency_1:0' shape=(?, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/mul_1_grad/Shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/mul_1_grad/Shape_1:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/mul_1_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/d_h3_lrelu/mul_1_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/mul_1_grad/Mul:0' shape=(?, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/mul_1_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/mul_1_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/mul_1_grad/Mul_1:0' shape=(?, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/mul_1_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/mul_1_grad/Reshape_1:0' shape=(?, 4, 4, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/mul_1_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/mul_1_grad/tuple/control_dependency_1:0' shape=(?, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/Abs_grad/Sign:0' shape=(?, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_lrelu/Abs_grad/mul:0' shape=(?, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/AddN_3:0' shape=(?, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_conv/BiasAdd_grad/BiasAddGrad:0' shape=(1024,) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h3_conv/BiasAdd_grad/tuple/control_dependency:0' shape=(?, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_conv/BiasAdd_grad/tuple/control_dependency_1:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_conv/Conv2D_grad/ShapeN:0' shape=(4,) dtype=int32>, <tf.Tensor 'gradients/D/d_h3_conv/Conv2D_grad/ShapeN:1' shape=(4,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h3_conv/Conv2D_grad/Conv2DBackpropInput:0' shape=(?, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_conv/Conv2D_grad/Conv2DBackpropFilter:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h3_conv/Conv2D_grad/tuple/control_dependency:0' shape=(?, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h3_conv/Conv2D_grad/tuple/control_dependency_1:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/add_grad/Shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/add_grad/Shape_1:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/add_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/d_h2_lrelu/add_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/add_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/add_grad/Reshape:0' shape=(?, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/add_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/add_grad/Reshape_1:0' shape=(?, 8, 8, 512) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/add_grad/tuple/control_dependency:0' shape=(?, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/add_grad/tuple/control_dependency_1:0' shape=(?, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/mul_grad/Shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/mul_grad/Shape_1:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/mul_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/d_h2_lrelu/mul_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/mul_grad/Mul:0' shape=(?, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/mul_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/mul_grad/Mul_1:0' shape=(?, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/mul_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/mul_grad/Reshape_1:0' shape=(?, 8, 8, 512) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/mul_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/mul_grad/tuple/control_dependency_1:0' shape=(?, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/mul_1_grad/Shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/mul_1_grad/Shape_1:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/mul_1_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/d_h2_lrelu/mul_1_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/mul_1_grad/Mul:0' shape=(?, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/mul_1_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/mul_1_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/mul_1_grad/Mul_1:0' shape=(?, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/mul_1_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/mul_1_grad/Reshape_1:0' shape=(?, 8, 8, 512) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/mul_1_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/mul_1_grad/tuple/control_dependency_1:0' shape=(?, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/Abs_grad/Sign:0' shape=(?, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_lrelu/Abs_grad/mul:0' shape=(?, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/AddN_4:0' shape=(?, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_conv/BiasAdd_grad/BiasAddGrad:0' shape=(512,) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h2_conv/BiasAdd_grad/tuple/control_dependency:0' shape=(?, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_conv/BiasAdd_grad/tuple/control_dependency_1:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_conv/Conv2D_grad/ShapeN:0' shape=(4,) dtype=int32>, <tf.Tensor 'gradients/D/d_h2_conv/Conv2D_grad/ShapeN:1' shape=(4,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h2_conv/Conv2D_grad/Conv2DBackpropInput:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_conv/Conv2D_grad/Conv2DBackpropFilter:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h2_conv/Conv2D_grad/tuple/control_dependency:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h2_conv/Conv2D_grad/tuple/control_dependency_1:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_2/mul_1_grad/Shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_2/mul_1_grad/Shape_1:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_2/mul_1_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/dropout_2/mul_1_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/dropout_2/mul_1_grad/Mul:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_2/mul_1_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_2/mul_1_grad/Reshape:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_2/mul_1_grad/Mul_1:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_2/mul_1_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_2/mul_1_grad/Reshape_1:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/dropout_2/mul_1_grad/tuple/control_dependency:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_2/mul_1_grad/tuple/control_dependency_1:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_2/mul_grad/Shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_2/mul_grad/Shape_1:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_2/mul_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/dropout_2/mul_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/dropout_2/mul_grad/Mul:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_2/mul_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_2/mul_grad/Reshape:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_2/mul_grad/Mul_1:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_2/mul_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_2/mul_grad/Reshape_1:0' shape=() dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/dropout_2/mul_grad/tuple/control_dependency:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_2/mul_grad/tuple/control_dependency_1:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/add_grad/Shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/add_grad/Shape_1:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/add_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/d_h1_lrelu/add_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/add_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/add_grad/Reshape:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/add_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/add_grad/Reshape_1:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/add_grad/tuple/control_dependency:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/add_grad/tuple/control_dependency_1:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/mul_grad/Shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/mul_grad/Shape_1:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/mul_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/d_h1_lrelu/mul_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/mul_grad/Mul:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/mul_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/mul_grad/Mul_1:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/mul_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/mul_grad/Reshape_1:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/mul_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/mul_grad/tuple/control_dependency_1:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/mul_1_grad/Shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/mul_1_grad/Shape_1:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/mul_1_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/d_h1_lrelu/mul_1_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/mul_1_grad/Mul:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/mul_1_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/mul_1_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/mul_1_grad/Mul_1:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/mul_1_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/mul_1_grad/Reshape_1:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/mul_1_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/mul_1_grad/tuple/control_dependency_1:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/Abs_grad/Sign:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_lrelu/Abs_grad/mul:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/AddN_5:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_conv/BiasAdd_grad/BiasAddGrad:0' shape=(256,) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h1_conv/BiasAdd_grad/tuple/control_dependency:0' shape=(?, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_conv/BiasAdd_grad/tuple/control_dependency_1:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_conv/Conv2D_grad/ShapeN:0' shape=(4,) dtype=int32>, <tf.Tensor 'gradients/D/d_h1_conv/Conv2D_grad/ShapeN:1' shape=(4,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h1_conv/Conv2D_grad/Conv2DBackpropInput:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_conv/Conv2D_grad/Conv2DBackpropFilter:0' shape=(5, 5, 128, 256) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h1_conv/Conv2D_grad/tuple/control_dependency:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h1_conv/Conv2D_grad/tuple/control_dependency_1:0' shape=(5, 5, 128, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_1/mul_1_grad/Shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_1/mul_1_grad/Shape_1:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_1/mul_1_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/dropout_1/mul_1_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/dropout_1/mul_1_grad/Mul:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_1/mul_1_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_1/mul_1_grad/Reshape:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_1/mul_1_grad/Mul_1:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_1/mul_1_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_1/mul_1_grad/Reshape_1:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/dropout_1/mul_1_grad/tuple/control_dependency:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_1/mul_1_grad/tuple/control_dependency_1:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_1/mul_grad/Shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_1/mul_grad/Shape_1:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_1/mul_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/dropout_1/mul_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/dropout_1/mul_grad/Mul:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_1/mul_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_1/mul_grad/Reshape:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_1/mul_grad/Mul_1:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_1/mul_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_1/mul_grad/Reshape_1:0' shape=() dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/dropout_1/mul_grad/tuple/control_dependency:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/dropout_1/mul_grad/tuple/control_dependency_1:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/add_grad/Shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/add_grad/Shape_1:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/add_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/d_h0_lrelu/add_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/add_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/add_grad/Reshape:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/add_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/add_grad/Reshape_1:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/add_grad/tuple/control_dependency:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/add_grad/tuple/control_dependency_1:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/mul_grad/Shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/mul_grad/Shape_1:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/mul_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/d_h0_lrelu/mul_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/mul_grad/Mul:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/mul_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/mul_grad/Mul_1:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/mul_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/mul_grad/Reshape_1:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/mul_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/mul_grad/tuple/control_dependency_1:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/mul_1_grad/Shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/mul_1_grad/Shape_1:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/mul_1_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients/D/d_h0_lrelu/mul_1_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/mul_1_grad/Mul:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/mul_1_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/mul_1_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/mul_1_grad/Mul_1:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/mul_1_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/mul_1_grad/Reshape_1:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/mul_1_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/mul_1_grad/tuple/control_dependency_1:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/Abs_grad/Sign:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_lrelu/Abs_grad/mul:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/AddN_6:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_conv/BiasAdd_grad/BiasAddGrad:0' shape=(128,) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h0_conv/BiasAdd_grad/tuple/control_dependency:0' shape=(?, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_conv/BiasAdd_grad/tuple/control_dependency_1:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_conv/Conv2D_grad/ShapeN:0' shape=(4,) dtype=int32>, <tf.Tensor 'gradients/D/d_h0_conv/Conv2D_grad/ShapeN:1' shape=(4,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients/D/d_h0_conv/Conv2D_grad/Conv2DBackpropInput:0' shape=(?, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_conv/Conv2D_grad/Conv2DBackpropFilter:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients/D/d_h0_conv/Conv2D_grad/tuple/control_dependency:0' shape=(?, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients/D/d_h0_conv/Conv2D_grad/tuple/control_dependency_1:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'beta1_power/initial_value:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'beta1_power:0' shape=() dtype=float32_ref>,)\n",
      "(<tf.Tensor 'beta1_power/Assign:0' shape=() dtype=float32_ref>,)\n",
      "(<tf.Tensor 'beta1_power/read:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'beta2_power/initial_value:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'beta2_power:0' shape=() dtype=float32_ref>,)\n",
      "(<tf.Tensor 'beta2_power/Assign:0' shape=() dtype=float32_ref>,)\n",
      "(<tf.Tensor 'beta2_power/read:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Adam/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Adam/Initializer/zeros:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Adam:0' shape=(5, 5, 3, 128) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Adam/Assign:0' shape=(5, 5, 3, 128) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Adam/read:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Adam_1/Initializer/zeros:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Adam_1:0' shape=(5, 5, 3, 128) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Adam_1/Assign:0' shape=(5, 5, 3, 128) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Adam_1/read:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/biases/Adam/Initializer/zeros:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/biases/Adam:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/biases/Adam/Assign:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/biases/Adam/read:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/biases/Adam_1/Initializer/zeros:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/biases/Adam_1:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/biases/Adam_1/Assign:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/biases/Adam_1/read:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Adam/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Adam/Initializer/zeros:0' shape=(5, 5, 128, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Adam:0' shape=(5, 5, 128, 256) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Adam/Assign:0' shape=(5, 5, 128, 256) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Adam/read:0' shape=(5, 5, 128, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Adam_1/Initializer/zeros:0' shape=(5, 5, 128, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Adam_1:0' shape=(5, 5, 128, 256) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Adam_1/Assign:0' shape=(5, 5, 128, 256) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Adam_1/read:0' shape=(5, 5, 128, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/biases/Adam/Initializer/zeros:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/biases/Adam:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/biases/Adam/Assign:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/biases/Adam/read:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/biases/Adam_1/Initializer/zeros:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/biases/Adam_1:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/biases/Adam_1/Assign:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/biases/Adam_1/read:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Adam/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Adam/Initializer/zeros:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Adam:0' shape=(5, 5, 256, 512) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Adam/Assign:0' shape=(5, 5, 256, 512) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Adam/read:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Adam_1/Initializer/zeros:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Adam_1:0' shape=(5, 5, 256, 512) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Adam_1/Assign:0' shape=(5, 5, 256, 512) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Adam_1/read:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/biases/Adam/Initializer/zeros:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/biases/Adam:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/biases/Adam/Assign:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/biases/Adam/read:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/biases/Adam_1/Initializer/zeros:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/biases/Adam_1:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/biases/Adam_1/Assign:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/biases/Adam_1/read:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Adam/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Adam/Initializer/zeros:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Adam:0' shape=(5, 5, 512, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Adam/Assign:0' shape=(5, 5, 512, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Adam/read:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Adam_1/Initializer/zeros:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Adam_1:0' shape=(5, 5, 512, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Adam_1/Assign:0' shape=(5, 5, 512, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Adam_1/read:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases/Adam/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases/Adam/Initializer/zeros:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases/Adam:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases/Adam/Assign:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases/Adam/read:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases/Adam_1/Initializer/zeros:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases/Adam_1:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases/Adam_1/Assign:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases/Adam_1/read:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Adam/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Adam/Initializer/zeros:0' shape=(16384, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Adam:0' shape=(16384, 2048) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Adam/Assign:0' shape=(16384, 2048) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Adam/read:0' shape=(16384, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Adam_1/Initializer/zeros:0' shape=(16384, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Adam_1:0' shape=(16384, 2048) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Adam_1/Assign:0' shape=(16384, 2048) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Adam_1/read:0' shape=(16384, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias/Adam/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias/Adam/Initializer/zeros:0' shape=(2048,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias/Adam:0' shape=(2048,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias/Adam/Assign:0' shape=(2048,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias/Adam/read:0' shape=(2048,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias/Adam_1/Initializer/zeros:0' shape=(2048,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias/Adam_1:0' shape=(2048,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias/Adam_1/Assign:0' shape=(2048,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias/Adam_1/read:0' shape=(2048,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Adam/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Adam/Initializer/zeros:0' shape=(2048, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Adam:0' shape=(2048, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Adam/Assign:0' shape=(2048, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Adam/read:0' shape=(2048, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Adam_1/Initializer/zeros:0' shape=(2048, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Adam_1:0' shape=(2048, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Adam_1/Assign:0' shape=(2048, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Adam_1/read:0' shape=(2048, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias/Adam/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias/Adam/Initializer/zeros:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias/Adam:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias/Adam/Assign:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias/Adam/read:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias/Adam_1/Initializer/zeros:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias/Adam_1:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias/Adam_1/Assign:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias/Adam_1/read:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Adam/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Adam/Initializer/zeros:0' shape=(1024, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Adam:0' shape=(1024, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Adam/Assign:0' shape=(1024, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Adam/read:0' shape=(1024, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Adam_1/Initializer/zeros:0' shape=(1024, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Adam_1:0' shape=(1024, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Adam_1/Assign:0' shape=(1024, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Adam_1/read:0' shape=(1024, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias/Adam/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias/Adam/Initializer/zeros:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias/Adam:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias/Adam/Assign:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias/Adam/read:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias/Adam_1/Initializer/zeros:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias/Adam_1:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias/Adam_1/Assign:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias/Adam_1/read:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Adam/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Adam/Initializer/zeros:0' shape=(1024, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Adam:0' shape=(1024, 1) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Adam/Assign:0' shape=(1024, 1) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Adam/read:0' shape=(1024, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Adam_1/Initializer/zeros:0' shape=(1024, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Adam_1:0' shape=(1024, 1) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Adam_1/Assign:0' shape=(1024, 1) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Adam_1/read:0' shape=(1024, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/bias/Adam/Initializer/zeros:0' shape=(1,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/bias/Adam:0' shape=(1,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/bias/Adam/Assign:0' shape=(1,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/bias/Adam/read:0' shape=(1,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/bias/Adam_1/Initializer/zeros:0' shape=(1,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/bias/Adam_1:0' shape=(1,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/bias/Adam_1/Assign:0' shape=(1,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/bias/Adam_1/read:0' shape=(1,) dtype=float32>,)\n",
      "(<tf.Tensor 'Adam/learning_rate:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'Adam/beta1:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'Adam/beta2:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'Adam/epsilon:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'Adam/update_D/d_h0_conv/w/ApplyAdam:0' shape=(5, 5, 3, 128) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam/update_D/d_h0_conv/biases/ApplyAdam:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam/update_D/d_h1_conv/w/ApplyAdam:0' shape=(5, 5, 128, 256) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam/update_D/d_h1_conv/biases/ApplyAdam:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam/update_D/d_h2_conv/w/ApplyAdam:0' shape=(5, 5, 256, 512) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam/update_D/d_h2_conv/biases/ApplyAdam:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam/update_D/d_h3_conv/w/ApplyAdam:0' shape=(5, 5, 512, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam/update_D/d_h3_conv/biases/ApplyAdam:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam/update_D/d_h4_lin/Matrix/ApplyAdam:0' shape=(16384, 2048) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam/update_D/d_h4_lin/bias/ApplyAdam:0' shape=(2048,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam/update_D/d_h5_lin/Matrix/ApplyAdam:0' shape=(2048, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam/update_D/d_h5_lin/bias/ApplyAdam:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam/update_D/d_h6_lin/Matrix/ApplyAdam:0' shape=(1024, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam/update_D/d_h6_lin/bias/ApplyAdam:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam/update_D/d_h7_lin/Matrix/ApplyAdam:0' shape=(1024, 1) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam/update_D/d_h7_lin/bias/ApplyAdam:0' shape=(1,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam/mul:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'Adam/Assign:0' shape=() dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam/mul_1:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'Adam/Assign_1:0' shape=() dtype=float32_ref>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/Shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/grad_ys_0:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/Fill:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/Neg_1_grad/Neg:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/Mean_1_grad/Reshape/shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/Mean_1_grad/Reshape:0' shape=(1, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/Mean_1_grad/Const:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/Mean_1_grad/Tile:0' shape=(128, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/Mean_1_grad/Const_1:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/Mean_1_grad/truediv:0' shape=(128, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/mul_1_grad/Shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/mul_1_grad/Shape_1:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/mul_1_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients_1/mul_1_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients_1/mul_1_grad/Mul:0' shape=(128, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/mul_1_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/mul_1_grad/Reshape:0' shape=(128, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/mul_1_grad/Mul_1:0' shape=(128, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/mul_1_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/mul_1_grad/Reshape_1:0' shape=(?, 1) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/mul_1_grad/tuple/control_dependency:0' shape=(128, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/mul_1_grad/tuple/control_dependency_1:0' shape=(?, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/Log_1_grad/Reciprocal:0' shape=(128, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/Log_1_grad/mul:0' shape=(128, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/sub_grad/BroadcastGradientArgs/s0:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/sub_grad/BroadcastGradientArgs/s1:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/sub_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients_1/sub_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients_1/sub_grad/Sum/reduction_indices:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/sub_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/sub_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/sub_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/sub_grad/Neg:0' shape=(128, 1) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/sub_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/sub_grad/tuple/control_dependency_1:0' shape=(128, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/Sigmoid_1_grad/SigmoidGrad:0' shape=(128, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h7_lin_1/add_grad/BroadcastGradientArgs/s0:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h7_lin_1/add_grad/BroadcastGradientArgs/s1:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h7_lin_1/add_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients_1/D/d_h7_lin_1/add_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients_1/D/d_h7_lin_1/add_grad/Sum/reduction_indices:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h7_lin_1/add_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h7_lin_1/add_grad/Reshape/shape:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h7_lin_1/add_grad/Reshape:0' shape=(1,) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h7_lin_1/add_grad/tuple/control_dependency:0' shape=(128, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h7_lin_1/add_grad/tuple/control_dependency_1:0' shape=(1,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h7_lin_1/MatMul_grad/MatMul:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h7_lin_1/MatMul_grad/MatMul_1:0' shape=(1024, 1) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h7_lin_1/MatMul_grad/tuple/control_dependency:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h7_lin_1/MatMul_grad/tuple/control_dependency_1:0' shape=(1024, 1) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lrelu_1/add_grad/tuple/control_dependency:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lrelu_1/add_grad/tuple/control_dependency_1:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lrelu_1/mul_grad/BroadcastGradientArgs/s0:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lrelu_1/mul_grad/BroadcastGradientArgs/s1:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lrelu_1/mul_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients_1/D/d_h6_lrelu_1/mul_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lrelu_1/mul_grad/Mul:0' shape=(128, 1024) dtype=float32>,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'gradients_1/D/d_h6_lrelu_1/mul_grad/Sum/reduction_indices:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lrelu_1/mul_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lrelu_1/mul_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lrelu_1/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lrelu_1/mul_grad/Mul_1:0' shape=(128, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lrelu_1/mul_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lrelu_1/mul_grad/tuple/control_dependency_1:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lrelu_1/mul_1_grad/Mul:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lrelu_1/mul_1_grad/Sum/reduction_indices:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lrelu_1/mul_1_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lrelu_1/mul_1_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lrelu_1/mul_1_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lrelu_1/mul_1_grad/Mul_1:0' shape=(128, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lrelu_1/mul_1_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lrelu_1/mul_1_grad/tuple/control_dependency_1:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lrelu_1/Abs_grad/Sign:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lrelu_1/Abs_grad/mul:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/AddN:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lin_1/add_grad/BroadcastGradientArgs/s0:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lin_1/add_grad/BroadcastGradientArgs/s1:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lin_1/add_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients_1/D/d_h6_lin_1/add_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lin_1/add_grad/Sum/reduction_indices:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lin_1/add_grad/Sum:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lin_1/add_grad/Reshape/shape:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lin_1/add_grad/Reshape:0' shape=(1024,) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lin_1/add_grad/tuple/control_dependency:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lin_1/add_grad/tuple/control_dependency_1:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lin_1/MatMul_grad/MatMul:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lin_1/MatMul_grad/MatMul_1:0' shape=(1024, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lin_1/MatMul_grad/tuple/control_dependency:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h6_lin_1/MatMul_grad/tuple/control_dependency_1:0' shape=(1024, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lrelu_1/add_grad/tuple/control_dependency:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lrelu_1/add_grad/tuple/control_dependency_1:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lrelu_1/mul_grad/Mul:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lrelu_1/mul_grad/Sum/reduction_indices:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lrelu_1/mul_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lrelu_1/mul_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lrelu_1/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lrelu_1/mul_grad/Mul_1:0' shape=(128, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lrelu_1/mul_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lrelu_1/mul_grad/tuple/control_dependency_1:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lrelu_1/mul_1_grad/Mul:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lrelu_1/mul_1_grad/Sum/reduction_indices:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lrelu_1/mul_1_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lrelu_1/mul_1_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lrelu_1/mul_1_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lrelu_1/mul_1_grad/Mul_1:0' shape=(128, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lrelu_1/mul_1_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lrelu_1/mul_1_grad/tuple/control_dependency_1:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lrelu_1/Abs_grad/Sign:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lrelu_1/Abs_grad/mul:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/AddN_1:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lin_1/add_grad/Sum/reduction_indices:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lin_1/add_grad/Sum:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lin_1/add_grad/Reshape/shape:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lin_1/add_grad/Reshape:0' shape=(1024,) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lin_1/add_grad/tuple/control_dependency:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lin_1/add_grad/tuple/control_dependency_1:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lin_1/MatMul_grad/MatMul:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lin_1/MatMul_grad/MatMul_1:0' shape=(2048, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lin_1/MatMul_grad/tuple/control_dependency:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h5_lin_1/MatMul_grad/tuple/control_dependency_1:0' shape=(2048, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lrelu_1/add_grad/tuple/control_dependency:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lrelu_1/add_grad/tuple/control_dependency_1:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lrelu_1/mul_grad/BroadcastGradientArgs/s0:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lrelu_1/mul_grad/BroadcastGradientArgs/s1:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lrelu_1/mul_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients_1/D/d_h4_lrelu_1/mul_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lrelu_1/mul_grad/Mul:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lrelu_1/mul_grad/Sum/reduction_indices:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lrelu_1/mul_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lrelu_1/mul_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lrelu_1/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lrelu_1/mul_grad/Mul_1:0' shape=(128, 2048) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lrelu_1/mul_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lrelu_1/mul_grad/tuple/control_dependency_1:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lrelu_1/mul_1_grad/Mul:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lrelu_1/mul_1_grad/Sum/reduction_indices:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lrelu_1/mul_1_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lrelu_1/mul_1_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lrelu_1/mul_1_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lrelu_1/mul_1_grad/Mul_1:0' shape=(128, 2048) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lrelu_1/mul_1_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lrelu_1/mul_1_grad/tuple/control_dependency_1:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lrelu_1/Abs_grad/Sign:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lrelu_1/Abs_grad/mul:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/AddN_2:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lin_1/add_grad/BroadcastGradientArgs/s0:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lin_1/add_grad/BroadcastGradientArgs/s1:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lin_1/add_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients_1/D/d_h4_lin_1/add_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lin_1/add_grad/Sum/reduction_indices:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lin_1/add_grad/Sum:0' shape=(2048,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lin_1/add_grad/Reshape/shape:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lin_1/add_grad/Reshape:0' shape=(2048,) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lin_1/add_grad/tuple/control_dependency:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lin_1/add_grad/tuple/control_dependency_1:0' shape=(2048,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lin_1/MatMul_grad/MatMul:0' shape=(128, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lin_1/MatMul_grad/MatMul_1:0' shape=(16384, 2048) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lin_1/MatMul_grad/tuple/control_dependency:0' shape=(128, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h4_lin_1/MatMul_grad/tuple/control_dependency_1:0' shape=(16384, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/Reshape_1_grad/Shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/Reshape_1_grad/Reshape:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_lrelu_1/add_grad/tuple/control_dependency:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_lrelu_1/add_grad/tuple/control_dependency_1:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_lrelu_1/mul_grad/BroadcastGradientArgs/s0:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_lrelu_1/mul_grad/BroadcastGradientArgs/s1:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_lrelu_1/mul_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients_1/D/d_h3_lrelu_1/mul_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_lrelu_1/mul_grad/Mul:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_lrelu_1/mul_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_lrelu_1/mul_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_lrelu_1/mul_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_lrelu_1/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_lrelu_1/mul_grad/Mul_1:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_lrelu_1/mul_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_lrelu_1/mul_grad/tuple/control_dependency_1:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_lrelu_1/mul_1_grad/Mul:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_lrelu_1/mul_1_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_lrelu_1/mul_1_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_lrelu_1/mul_1_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_lrelu_1/mul_1_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_lrelu_1/mul_1_grad/Mul_1:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_lrelu_1/mul_1_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_lrelu_1/mul_1_grad/tuple/control_dependency_1:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_lrelu_1/Abs_grad/Sign:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_lrelu_1/Abs_grad/mul:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/AddN_3:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_conv_1/BiasAdd_grad/BiasAddGrad:0' shape=(1024,) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_conv_1/BiasAdd_grad/tuple/control_dependency:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_conv_1/BiasAdd_grad/tuple/control_dependency_1:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_conv_1/Conv2D_grad/ShapeN:0' shape=(4,) dtype=int32>, <tf.Tensor 'gradients_1/D/d_h3_conv_1/Conv2D_grad/ShapeN:1' shape=(4,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_conv_1/Conv2D_grad/Conv2DBackpropInput:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_conv_1/Conv2D_grad/Conv2DBackpropFilter:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_conv_1/Conv2D_grad/tuple/control_dependency:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h3_conv_1/Conv2D_grad/tuple/control_dependency_1:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_lrelu_1/add_grad/tuple/control_dependency:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_lrelu_1/add_grad/tuple/control_dependency_1:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_lrelu_1/mul_grad/BroadcastGradientArgs/s0:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_lrelu_1/mul_grad/BroadcastGradientArgs/s1:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_lrelu_1/mul_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients_1/D/d_h2_lrelu_1/mul_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_lrelu_1/mul_grad/Mul:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_lrelu_1/mul_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_lrelu_1/mul_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_lrelu_1/mul_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_lrelu_1/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_lrelu_1/mul_grad/Mul_1:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_lrelu_1/mul_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_lrelu_1/mul_grad/tuple/control_dependency_1:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_lrelu_1/mul_1_grad/Mul:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_lrelu_1/mul_1_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_lrelu_1/mul_1_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_lrelu_1/mul_1_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_lrelu_1/mul_1_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_lrelu_1/mul_1_grad/Mul_1:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_lrelu_1/mul_1_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_lrelu_1/mul_1_grad/tuple/control_dependency_1:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_lrelu_1/Abs_grad/Sign:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_lrelu_1/Abs_grad/mul:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/AddN_4:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_conv_1/BiasAdd_grad/BiasAddGrad:0' shape=(512,) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_conv_1/BiasAdd_grad/tuple/control_dependency:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_conv_1/BiasAdd_grad/tuple/control_dependency_1:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_conv_1/Conv2D_grad/ShapeN:0' shape=(4,) dtype=int32>, <tf.Tensor 'gradients_1/D/d_h2_conv_1/Conv2D_grad/ShapeN:1' shape=(4,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_conv_1/Conv2D_grad/Conv2DBackpropInput:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_conv_1/Conv2D_grad/Conv2DBackpropFilter:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_conv_1/Conv2D_grad/tuple/control_dependency:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h2_conv_1/Conv2D_grad/tuple/control_dependency_1:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/dropout_5/mul_1_grad/Mul:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/dropout_5/mul_1_grad/Mul_1:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/dropout_5/mul_1_grad/tuple/control_dependency:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/dropout_5/mul_1_grad/tuple/control_dependency_1:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/dropout_5/mul_grad/BroadcastGradientArgs/s0:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/dropout_5/mul_grad/BroadcastGradientArgs/s1:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/dropout_5/mul_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients_1/D/dropout_5/mul_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients_1/D/dropout_5/mul_grad/Mul:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/dropout_5/mul_grad/Mul_1:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/dropout_5/mul_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/dropout_5/mul_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/dropout_5/mul_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/dropout_5/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/dropout_5/mul_grad/tuple/control_dependency:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/dropout_5/mul_grad/tuple/control_dependency_1:0' shape=() dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_lrelu_1/add_grad/tuple/control_dependency:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_lrelu_1/add_grad/tuple/control_dependency_1:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_lrelu_1/mul_grad/BroadcastGradientArgs/s0:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_lrelu_1/mul_grad/BroadcastGradientArgs/s1:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_lrelu_1/mul_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients_1/D/d_h1_lrelu_1/mul_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_lrelu_1/mul_grad/Mul:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_lrelu_1/mul_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_lrelu_1/mul_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_lrelu_1/mul_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_lrelu_1/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_lrelu_1/mul_grad/Mul_1:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_lrelu_1/mul_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_lrelu_1/mul_grad/tuple/control_dependency_1:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_lrelu_1/mul_1_grad/Mul:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_lrelu_1/mul_1_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_lrelu_1/mul_1_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_lrelu_1/mul_1_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_lrelu_1/mul_1_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_lrelu_1/mul_1_grad/Mul_1:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_lrelu_1/mul_1_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_lrelu_1/mul_1_grad/tuple/control_dependency_1:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_lrelu_1/Abs_grad/Sign:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_lrelu_1/Abs_grad/mul:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/AddN_5:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_conv_1/BiasAdd_grad/BiasAddGrad:0' shape=(256,) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_conv_1/BiasAdd_grad/tuple/control_dependency:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_conv_1/BiasAdd_grad/tuple/control_dependency_1:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_conv_1/Conv2D_grad/ShapeN:0' shape=(4,) dtype=int32>, <tf.Tensor 'gradients_1/D/d_h1_conv_1/Conv2D_grad/ShapeN:1' shape=(4,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_conv_1/Conv2D_grad/Conv2DBackpropInput:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_conv_1/Conv2D_grad/Conv2DBackpropFilter:0' shape=(5, 5, 128, 256) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_conv_1/Conv2D_grad/tuple/control_dependency:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h1_conv_1/Conv2D_grad/tuple/control_dependency_1:0' shape=(5, 5, 128, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/dropout_4/mul_1_grad/Mul:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/dropout_4/mul_1_grad/Mul_1:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/dropout_4/mul_1_grad/tuple/control_dependency:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/dropout_4/mul_1_grad/tuple/control_dependency_1:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/dropout_4/mul_grad/BroadcastGradientArgs/s0:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/dropout_4/mul_grad/BroadcastGradientArgs/s1:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/dropout_4/mul_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients_1/D/dropout_4/mul_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients_1/D/dropout_4/mul_grad/Mul:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/dropout_4/mul_grad/Mul_1:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/dropout_4/mul_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/dropout_4/mul_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/dropout_4/mul_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/dropout_4/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/dropout_4/mul_grad/tuple/control_dependency:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/dropout_4/mul_grad/tuple/control_dependency_1:0' shape=() dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_lrelu_1/add_grad/tuple/control_dependency:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_lrelu_1/add_grad/tuple/control_dependency_1:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_lrelu_1/mul_grad/BroadcastGradientArgs/s0:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_lrelu_1/mul_grad/BroadcastGradientArgs/s1:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_lrelu_1/mul_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients_1/D/d_h0_lrelu_1/mul_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_lrelu_1/mul_grad/Mul:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_lrelu_1/mul_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_lrelu_1/mul_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_lrelu_1/mul_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_lrelu_1/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_lrelu_1/mul_grad/Mul_1:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_lrelu_1/mul_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_lrelu_1/mul_grad/tuple/control_dependency_1:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_lrelu_1/mul_1_grad/Mul:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_lrelu_1/mul_1_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_lrelu_1/mul_1_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_lrelu_1/mul_1_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_lrelu_1/mul_1_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_lrelu_1/mul_1_grad/Mul_1:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_lrelu_1/mul_1_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_lrelu_1/mul_1_grad/tuple/control_dependency_1:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_lrelu_1/Abs_grad/Sign:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_lrelu_1/Abs_grad/mul:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/AddN_6:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_conv_1/BiasAdd_grad/BiasAddGrad:0' shape=(128,) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_conv_1/BiasAdd_grad/tuple/control_dependency:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_conv_1/BiasAdd_grad/tuple/control_dependency_1:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_conv_1/Conv2D_grad/ShapeN:0' shape=(4,) dtype=int32>, <tf.Tensor 'gradients_1/D/d_h0_conv_1/Conv2D_grad/ShapeN:1' shape=(4,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_conv_1/Conv2D_grad/Conv2DBackpropInput:0' shape=(128, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_conv_1/Conv2D_grad/Conv2DBackpropFilter:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_conv_1/Conv2D_grad/tuple/control_dependency:0' shape=(128, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_1/D/d_h0_conv_1/Conv2D_grad/tuple/control_dependency_1:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'beta1_power_1/initial_value:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'beta1_power_1:0' shape=() dtype=float32_ref>,)\n",
      "(<tf.Tensor 'beta1_power_1/Assign:0' shape=() dtype=float32_ref>,)\n",
      "(<tf.Tensor 'beta1_power_1/read:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'beta2_power_1/initial_value:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'beta2_power_1:0' shape=() dtype=float32_ref>,)\n",
      "(<tf.Tensor 'beta2_power_1/Assign:0' shape=() dtype=float32_ref>,)\n",
      "(<tf.Tensor 'beta2_power_1/read:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Adam_2/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Adam_2/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Adam_2/Initializer/zeros:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Adam_2:0' shape=(5, 5, 3, 128) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Adam_2/Assign:0' shape=(5, 5, 3, 128) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Adam_2/read:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Adam_3/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Adam_3/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Adam_3/Initializer/zeros:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Adam_3:0' shape=(5, 5, 3, 128) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Adam_3/Assign:0' shape=(5, 5, 3, 128) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/w/Adam_3/read:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/biases/Adam_2/Initializer/zeros:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/biases/Adam_2:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/biases/Adam_2/Assign:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/biases/Adam_2/read:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/biases/Adam_3/Initializer/zeros:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/biases/Adam_3:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/biases/Adam_3/Assign:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h0_conv/biases/Adam_3/read:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Adam_2/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Adam_2/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Adam_2/Initializer/zeros:0' shape=(5, 5, 128, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Adam_2:0' shape=(5, 5, 128, 256) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Adam_2/Assign:0' shape=(5, 5, 128, 256) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Adam_2/read:0' shape=(5, 5, 128, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Adam_3/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Adam_3/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Adam_3/Initializer/zeros:0' shape=(5, 5, 128, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Adam_3:0' shape=(5, 5, 128, 256) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Adam_3/Assign:0' shape=(5, 5, 128, 256) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/w/Adam_3/read:0' shape=(5, 5, 128, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/biases/Adam_2/Initializer/zeros:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/biases/Adam_2:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/biases/Adam_2/Assign:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/biases/Adam_2/read:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/biases/Adam_3/Initializer/zeros:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/biases/Adam_3:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/biases/Adam_3/Assign:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h1_conv/biases/Adam_3/read:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Adam_2/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Adam_2/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Adam_2/Initializer/zeros:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Adam_2:0' shape=(5, 5, 256, 512) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Adam_2/Assign:0' shape=(5, 5, 256, 512) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Adam_2/read:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Adam_3/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Adam_3/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Adam_3/Initializer/zeros:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Adam_3:0' shape=(5, 5, 256, 512) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Adam_3/Assign:0' shape=(5, 5, 256, 512) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/w/Adam_3/read:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/biases/Adam_2/Initializer/zeros:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/biases/Adam_2:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/biases/Adam_2/Assign:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/biases/Adam_2/read:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/biases/Adam_3/Initializer/zeros:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/biases/Adam_3:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/biases/Adam_3/Assign:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h2_conv/biases/Adam_3/read:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Adam_2/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Adam_2/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Adam_2/Initializer/zeros:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Adam_2:0' shape=(5, 5, 512, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Adam_2/Assign:0' shape=(5, 5, 512, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Adam_2/read:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Adam_3/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Adam_3/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Adam_3/Initializer/zeros:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Adam_3:0' shape=(5, 5, 512, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Adam_3/Assign:0' shape=(5, 5, 512, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/w/Adam_3/read:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases/Adam_2/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases/Adam_2/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases/Adam_2/Initializer/zeros:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases/Adam_2:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases/Adam_2/Assign:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases/Adam_2/read:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases/Adam_3/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases/Adam_3/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases/Adam_3/Initializer/zeros:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases/Adam_3:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases/Adam_3/Assign:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h3_conv/biases/Adam_3/read:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Adam_2/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Adam_2/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Adam_2/Initializer/zeros:0' shape=(16384, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Adam_2:0' shape=(16384, 2048) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Adam_2/Assign:0' shape=(16384, 2048) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Adam_2/read:0' shape=(16384, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Adam_3/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Adam_3/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Adam_3/Initializer/zeros:0' shape=(16384, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Adam_3:0' shape=(16384, 2048) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Adam_3/Assign:0' shape=(16384, 2048) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/Matrix/Adam_3/read:0' shape=(16384, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias/Adam_2/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias/Adam_2/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias/Adam_2/Initializer/zeros:0' shape=(2048,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias/Adam_2:0' shape=(2048,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias/Adam_2/Assign:0' shape=(2048,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias/Adam_2/read:0' shape=(2048,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias/Adam_3/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias/Adam_3/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias/Adam_3/Initializer/zeros:0' shape=(2048,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias/Adam_3:0' shape=(2048,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias/Adam_3/Assign:0' shape=(2048,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h4_lin/bias/Adam_3/read:0' shape=(2048,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Adam_2/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Adam_2/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Adam_2/Initializer/zeros:0' shape=(2048, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Adam_2:0' shape=(2048, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Adam_2/Assign:0' shape=(2048, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Adam_2/read:0' shape=(2048, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Adam_3/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Adam_3/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Adam_3/Initializer/zeros:0' shape=(2048, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Adam_3:0' shape=(2048, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Adam_3/Assign:0' shape=(2048, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/Matrix/Adam_3/read:0' shape=(2048, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias/Adam_2/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias/Adam_2/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias/Adam_2/Initializer/zeros:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias/Adam_2:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias/Adam_2/Assign:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias/Adam_2/read:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias/Adam_3/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias/Adam_3/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias/Adam_3/Initializer/zeros:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias/Adam_3:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias/Adam_3/Assign:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h5_lin/bias/Adam_3/read:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Adam_2/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Adam_2/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Adam_2/Initializer/zeros:0' shape=(1024, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Adam_2:0' shape=(1024, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Adam_2/Assign:0' shape=(1024, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Adam_2/read:0' shape=(1024, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Adam_3/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Adam_3/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Adam_3/Initializer/zeros:0' shape=(1024, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Adam_3:0' shape=(1024, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Adam_3/Assign:0' shape=(1024, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/Matrix/Adam_3/read:0' shape=(1024, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias/Adam_2/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias/Adam_2/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias/Adam_2/Initializer/zeros:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias/Adam_2:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias/Adam_2/Assign:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias/Adam_2/read:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias/Adam_3/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias/Adam_3/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias/Adam_3/Initializer/zeros:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias/Adam_3:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias/Adam_3/Assign:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h6_lin/bias/Adam_3/read:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Adam_2/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Adam_2/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Adam_2/Initializer/zeros:0' shape=(1024, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Adam_2:0' shape=(1024, 1) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Adam_2/Assign:0' shape=(1024, 1) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Adam_2/read:0' shape=(1024, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Adam_3/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Adam_3/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Adam_3/Initializer/zeros:0' shape=(1024, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Adam_3:0' shape=(1024, 1) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Adam_3/Assign:0' shape=(1024, 1) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/Matrix/Adam_3/read:0' shape=(1024, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/bias/Adam_2/Initializer/zeros:0' shape=(1,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/bias/Adam_2:0' shape=(1,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/bias/Adam_2/Assign:0' shape=(1,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/bias/Adam_2/read:0' shape=(1,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/bias/Adam_3/Initializer/zeros:0' shape=(1,) dtype=float32>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/bias/Adam_3:0' shape=(1,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/bias/Adam_3/Assign:0' shape=(1,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'D/d_h7_lin/bias/Adam_3/read:0' shape=(1,) dtype=float32>,)\n",
      "(<tf.Tensor 'Adam_1/learning_rate:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'Adam_1/beta1:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'Adam_1/beta2:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'Adam_1/epsilon:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'Adam_1/update_D/d_h0_conv/w/ApplyAdam:0' shape=(5, 5, 3, 128) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_1/update_D/d_h0_conv/biases/ApplyAdam:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_1/update_D/d_h1_conv/w/ApplyAdam:0' shape=(5, 5, 128, 256) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_1/update_D/d_h1_conv/biases/ApplyAdam:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_1/update_D/d_h2_conv/w/ApplyAdam:0' shape=(5, 5, 256, 512) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_1/update_D/d_h2_conv/biases/ApplyAdam:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_1/update_D/d_h3_conv/w/ApplyAdam:0' shape=(5, 5, 512, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_1/update_D/d_h3_conv/biases/ApplyAdam:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_1/update_D/d_h4_lin/Matrix/ApplyAdam:0' shape=(16384, 2048) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_1/update_D/d_h4_lin/bias/ApplyAdam:0' shape=(2048,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_1/update_D/d_h5_lin/Matrix/ApplyAdam:0' shape=(2048, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_1/update_D/d_h5_lin/bias/ApplyAdam:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_1/update_D/d_h6_lin/Matrix/ApplyAdam:0' shape=(1024, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_1/update_D/d_h6_lin/bias/ApplyAdam:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_1/update_D/d_h7_lin/Matrix/ApplyAdam:0' shape=(1024, 1) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_1/update_D/d_h7_lin/bias/ApplyAdam:0' shape=(1,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_1/mul:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'Adam_1/Assign:0' shape=() dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_1/mul_1:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'Adam_1/Assign_1:0' shape=() dtype=float32_ref>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/Shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/grad_ys_0:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/Fill:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/Neg_2_grad/Neg:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/Mean_2_grad/Reshape/shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/Mean_2_grad/Reshape:0' shape=(1, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/Mean_2_grad/Const:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/Mean_2_grad/Tile:0' shape=(128, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/Mean_2_grad/Const_1:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/Mean_2_grad/truediv:0' shape=(128, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/Log_2_grad/Reciprocal:0' shape=(128, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/Log_2_grad/mul:0' shape=(128, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/Sigmoid_1_grad/SigmoidGrad:0' shape=(128, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h7_lin_1/add_grad/Sum/reduction_indices:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h7_lin_1/add_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h7_lin_1/add_grad/Reshape/shape:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h7_lin_1/add_grad/Reshape:0' shape=(1,) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h7_lin_1/add_grad/tuple/control_dependency:0' shape=(128, 1) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h7_lin_1/add_grad/tuple/control_dependency_1:0' shape=(1,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h7_lin_1/MatMul_grad/MatMul:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h7_lin_1/MatMul_grad/MatMul_1:0' shape=(1024, 1) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h7_lin_1/MatMul_grad/tuple/control_dependency:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h7_lin_1/MatMul_grad/tuple/control_dependency_1:0' shape=(1024, 1) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lrelu_1/add_grad/tuple/control_dependency:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lrelu_1/add_grad/tuple/control_dependency_1:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lrelu_1/mul_grad/Mul:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lrelu_1/mul_grad/Sum/reduction_indices:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lrelu_1/mul_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lrelu_1/mul_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lrelu_1/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lrelu_1/mul_grad/Mul_1:0' shape=(128, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lrelu_1/mul_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lrelu_1/mul_grad/tuple/control_dependency_1:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lrelu_1/mul_1_grad/Mul:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lrelu_1/mul_1_grad/Sum/reduction_indices:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lrelu_1/mul_1_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lrelu_1/mul_1_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lrelu_1/mul_1_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lrelu_1/mul_1_grad/Mul_1:0' shape=(128, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lrelu_1/mul_1_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lrelu_1/mul_1_grad/tuple/control_dependency_1:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lrelu_1/Abs_grad/Sign:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lrelu_1/Abs_grad/mul:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/AddN:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lin_1/add_grad/Sum/reduction_indices:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lin_1/add_grad/Sum:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lin_1/add_grad/Reshape/shape:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lin_1/add_grad/Reshape:0' shape=(1024,) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lin_1/add_grad/tuple/control_dependency:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lin_1/add_grad/tuple/control_dependency_1:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lin_1/MatMul_grad/MatMul:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lin_1/MatMul_grad/MatMul_1:0' shape=(1024, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lin_1/MatMul_grad/tuple/control_dependency:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h6_lin_1/MatMul_grad/tuple/control_dependency_1:0' shape=(1024, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lrelu_1/add_grad/tuple/control_dependency:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lrelu_1/add_grad/tuple/control_dependency_1:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lrelu_1/mul_grad/Mul:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lrelu_1/mul_grad/Sum/reduction_indices:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lrelu_1/mul_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lrelu_1/mul_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lrelu_1/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lrelu_1/mul_grad/Mul_1:0' shape=(128, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lrelu_1/mul_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lrelu_1/mul_grad/tuple/control_dependency_1:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lrelu_1/mul_1_grad/Mul:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lrelu_1/mul_1_grad/Sum/reduction_indices:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lrelu_1/mul_1_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lrelu_1/mul_1_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lrelu_1/mul_1_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lrelu_1/mul_1_grad/Mul_1:0' shape=(128, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lrelu_1/mul_1_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lrelu_1/mul_1_grad/tuple/control_dependency_1:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lrelu_1/Abs_grad/Sign:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lrelu_1/Abs_grad/mul:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/AddN_1:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lin_1/add_grad/Sum/reduction_indices:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lin_1/add_grad/Sum:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lin_1/add_grad/Reshape/shape:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lin_1/add_grad/Reshape:0' shape=(1024,) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lin_1/add_grad/tuple/control_dependency:0' shape=(128, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lin_1/add_grad/tuple/control_dependency_1:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lin_1/MatMul_grad/MatMul:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lin_1/MatMul_grad/MatMul_1:0' shape=(2048, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lin_1/MatMul_grad/tuple/control_dependency:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h5_lin_1/MatMul_grad/tuple/control_dependency_1:0' shape=(2048, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lrelu_1/add_grad/tuple/control_dependency:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lrelu_1/add_grad/tuple/control_dependency_1:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lrelu_1/mul_grad/Mul:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lrelu_1/mul_grad/Sum/reduction_indices:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lrelu_1/mul_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lrelu_1/mul_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lrelu_1/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lrelu_1/mul_grad/Mul_1:0' shape=(128, 2048) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lrelu_1/mul_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lrelu_1/mul_grad/tuple/control_dependency_1:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lrelu_1/mul_1_grad/Mul:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lrelu_1/mul_1_grad/Sum/reduction_indices:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lrelu_1/mul_1_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lrelu_1/mul_1_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lrelu_1/mul_1_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lrelu_1/mul_1_grad/Mul_1:0' shape=(128, 2048) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lrelu_1/mul_1_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lrelu_1/mul_1_grad/tuple/control_dependency_1:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lrelu_1/Abs_grad/Sign:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lrelu_1/Abs_grad/mul:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/AddN_2:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lin_1/add_grad/Sum/reduction_indices:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lin_1/add_grad/Sum:0' shape=(2048,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lin_1/add_grad/Reshape/shape:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lin_1/add_grad/Reshape:0' shape=(2048,) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lin_1/add_grad/tuple/control_dependency:0' shape=(128, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lin_1/add_grad/tuple/control_dependency_1:0' shape=(2048,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lin_1/MatMul_grad/MatMul:0' shape=(128, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lin_1/MatMul_grad/MatMul_1:0' shape=(16384, 2048) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lin_1/MatMul_grad/tuple/control_dependency:0' shape=(128, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h4_lin_1/MatMul_grad/tuple/control_dependency_1:0' shape=(16384, 2048) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/Reshape_1_grad/Shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/Reshape_1_grad/Reshape:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_lrelu_1/add_grad/tuple/control_dependency:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_lrelu_1/add_grad/tuple/control_dependency_1:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_lrelu_1/mul_grad/Mul:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_lrelu_1/mul_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_lrelu_1/mul_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_lrelu_1/mul_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_lrelu_1/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_lrelu_1/mul_grad/Mul_1:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_lrelu_1/mul_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_lrelu_1/mul_grad/tuple/control_dependency_1:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_lrelu_1/mul_1_grad/Mul:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_lrelu_1/mul_1_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_lrelu_1/mul_1_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_lrelu_1/mul_1_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_lrelu_1/mul_1_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_lrelu_1/mul_1_grad/Mul_1:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_lrelu_1/mul_1_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_lrelu_1/mul_1_grad/tuple/control_dependency_1:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_lrelu_1/Abs_grad/Sign:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_lrelu_1/Abs_grad/mul:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/AddN_3:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_conv_1/BiasAdd_grad/BiasAddGrad:0' shape=(1024,) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_conv_1/BiasAdd_grad/tuple/control_dependency:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_conv_1/BiasAdd_grad/tuple/control_dependency_1:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_conv_1/Conv2D_grad/ShapeN:0' shape=(4,) dtype=int32>, <tf.Tensor 'gradients_2/D/d_h3_conv_1/Conv2D_grad/ShapeN:1' shape=(4,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_conv_1/Conv2D_grad/Conv2DBackpropInput:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_conv_1/Conv2D_grad/Conv2DBackpropFilter:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_conv_1/Conv2D_grad/tuple/control_dependency:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h3_conv_1/Conv2D_grad/tuple/control_dependency_1:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_lrelu_1/add_grad/tuple/control_dependency:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_lrelu_1/add_grad/tuple/control_dependency_1:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_lrelu_1/mul_grad/Mul:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_lrelu_1/mul_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_lrelu_1/mul_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_lrelu_1/mul_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_lrelu_1/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_lrelu_1/mul_grad/Mul_1:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_lrelu_1/mul_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_lrelu_1/mul_grad/tuple/control_dependency_1:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_lrelu_1/mul_1_grad/Mul:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_lrelu_1/mul_1_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_lrelu_1/mul_1_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_lrelu_1/mul_1_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_lrelu_1/mul_1_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_lrelu_1/mul_1_grad/Mul_1:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_lrelu_1/mul_1_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_lrelu_1/mul_1_grad/tuple/control_dependency_1:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_lrelu_1/Abs_grad/Sign:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_lrelu_1/Abs_grad/mul:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/AddN_4:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_conv_1/BiasAdd_grad/BiasAddGrad:0' shape=(512,) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_conv_1/BiasAdd_grad/tuple/control_dependency:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_conv_1/BiasAdd_grad/tuple/control_dependency_1:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_conv_1/Conv2D_grad/ShapeN:0' shape=(4,) dtype=int32>, <tf.Tensor 'gradients_2/D/d_h2_conv_1/Conv2D_grad/ShapeN:1' shape=(4,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_conv_1/Conv2D_grad/Conv2DBackpropInput:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_conv_1/Conv2D_grad/Conv2DBackpropFilter:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_conv_1/Conv2D_grad/tuple/control_dependency:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h2_conv_1/Conv2D_grad/tuple/control_dependency_1:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_5/mul_1_grad/Mul:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_5/mul_1_grad/Mul_1:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/dropout_5/mul_1_grad/tuple/control_dependency:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_5/mul_1_grad/tuple/control_dependency_1:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_5/mul_grad/Mul:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_5/mul_grad/Mul_1:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_5/mul_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_5/mul_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_5/mul_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_5/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/dropout_5/mul_grad/tuple/control_dependency:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_5/mul_grad/tuple/control_dependency_1:0' shape=() dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_lrelu_1/add_grad/tuple/control_dependency:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_lrelu_1/add_grad/tuple/control_dependency_1:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_lrelu_1/mul_grad/Mul:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_lrelu_1/mul_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_lrelu_1/mul_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_lrelu_1/mul_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_lrelu_1/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_lrelu_1/mul_grad/Mul_1:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_lrelu_1/mul_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_lrelu_1/mul_grad/tuple/control_dependency_1:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_lrelu_1/mul_1_grad/Mul:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_lrelu_1/mul_1_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_lrelu_1/mul_1_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_lrelu_1/mul_1_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_lrelu_1/mul_1_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_lrelu_1/mul_1_grad/Mul_1:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_lrelu_1/mul_1_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_lrelu_1/mul_1_grad/tuple/control_dependency_1:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_lrelu_1/Abs_grad/Sign:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_lrelu_1/Abs_grad/mul:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/AddN_5:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_conv_1/BiasAdd_grad/BiasAddGrad:0' shape=(256,) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_conv_1/BiasAdd_grad/tuple/control_dependency:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_conv_1/BiasAdd_grad/tuple/control_dependency_1:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_conv_1/Conv2D_grad/ShapeN:0' shape=(4,) dtype=int32>, <tf.Tensor 'gradients_2/D/d_h1_conv_1/Conv2D_grad/ShapeN:1' shape=(4,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_conv_1/Conv2D_grad/Conv2DBackpropInput:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_conv_1/Conv2D_grad/Conv2DBackpropFilter:0' shape=(5, 5, 128, 256) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_conv_1/Conv2D_grad/tuple/control_dependency:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h1_conv_1/Conv2D_grad/tuple/control_dependency_1:0' shape=(5, 5, 128, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_4/mul_1_grad/Mul:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_4/mul_1_grad/Mul_1:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/dropout_4/mul_1_grad/tuple/control_dependency:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_4/mul_1_grad/tuple/control_dependency_1:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_4/mul_grad/Mul:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_4/mul_grad/Mul_1:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_4/mul_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_4/mul_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_4/mul_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_4/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/dropout_4/mul_grad/tuple/control_dependency:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_4/mul_grad/tuple/control_dependency_1:0' shape=() dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_lrelu_1/add_grad/tuple/control_dependency:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_lrelu_1/add_grad/tuple/control_dependency_1:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_lrelu_1/mul_grad/Mul:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_lrelu_1/mul_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_lrelu_1/mul_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_lrelu_1/mul_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_lrelu_1/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_lrelu_1/mul_grad/Mul_1:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_lrelu_1/mul_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_lrelu_1/mul_grad/tuple/control_dependency_1:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_lrelu_1/mul_1_grad/Mul:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_lrelu_1/mul_1_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_lrelu_1/mul_1_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_lrelu_1/mul_1_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_lrelu_1/mul_1_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_lrelu_1/mul_1_grad/Mul_1:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_lrelu_1/mul_1_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_lrelu_1/mul_1_grad/tuple/control_dependency_1:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_lrelu_1/Abs_grad/Sign:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_lrelu_1/Abs_grad/mul:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/AddN_6:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_conv_1/BiasAdd_grad/BiasAddGrad:0' shape=(128,) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_conv_1/BiasAdd_grad/tuple/control_dependency:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_conv_1/BiasAdd_grad/tuple/control_dependency_1:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_conv_1/Conv2D_grad/ShapeN:0' shape=(4,) dtype=int32>, <tf.Tensor 'gradients_2/D/d_h0_conv_1/Conv2D_grad/ShapeN:1' shape=(4,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_conv_1/Conv2D_grad/Conv2DBackpropInput:0' shape=(128, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_conv_1/Conv2D_grad/Conv2DBackpropFilter:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_conv_1/Conv2D_grad/tuple/control_dependency:0' shape=(128, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/d_h0_conv_1/Conv2D_grad/tuple/control_dependency_1:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_3/mul_1_grad/Mul:0' shape=(128, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_3/mul_1_grad/Mul_1:0' shape=(128, 64, 64, 3) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/dropout_3/mul_1_grad/tuple/control_dependency:0' shape=(128, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_3/mul_1_grad/tuple/control_dependency_1:0' shape=(128, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_3/mul_grad/BroadcastGradientArgs/s0:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_3/mul_grad/BroadcastGradientArgs/s1:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_3/mul_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients_2/D/dropout_3/mul_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_3/mul_grad/Mul:0' shape=(128, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_3/mul_grad/Mul_1:0' shape=(128, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_3/mul_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_3/mul_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_3/mul_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_3/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/D/dropout_3/mul_grad/tuple/control_dependency:0' shape=(128, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/D/dropout_3/mul_grad/tuple/control_dependency_1:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/Tanh_grad/TanhGrad:0' shape=(128, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_out/Reshape_grad/Shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_out/Reshape_grad/Reshape:0' shape=(128, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_out/BiasAdd_grad/BiasAddGrad:0' shape=(3,) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_out/BiasAdd_grad/tuple/control_dependency:0' shape=(128, 64, 64, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_out/BiasAdd_grad/tuple/control_dependency_1:0' shape=(3,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_out/conv2d_transpose_grad/Shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_out/conv2d_transpose_grad/Conv2DBackpropFilter:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_out/conv2d_transpose_grad/Conv2D:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_out/conv2d_transpose_grad/tuple/control_dependency:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_out/conv2d_transpose_grad/tuple/control_dependency_1:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_h4_lrelu/add_grad/tuple/control_dependency:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h4_lrelu/add_grad/tuple/control_dependency_1:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h4_lrelu/mul_grad/Mul:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h4_lrelu/mul_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h4_lrelu/mul_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h4_lrelu/mul_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h4_lrelu/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h4_lrelu/mul_grad/Mul_1:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_h4_lrelu/mul_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h4_lrelu/mul_grad/tuple/control_dependency_1:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h4_lrelu/mul_1_grad/Mul:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h4_lrelu/mul_1_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h4_lrelu/mul_1_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h4_lrelu/mul_1_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h4_lrelu/mul_1_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h4_lrelu/mul_1_grad/Mul_1:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_h4_lrelu/mul_1_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h4_lrelu/mul_1_grad/tuple/control_dependency_1:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h4_lrelu/Abs_grad/Sign:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h4_lrelu/Abs_grad/mul:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/AddN_7:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/zeros_like:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/zeros_like_1:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/zeros_like_2:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/zeros_like_3:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/zeros_like_4:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn4_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:0' shape=(128, 32, 32, 128) dtype=float32>, <tf.Tensor 'gradients_2/G/g_bn4_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:1' shape=(128,) dtype=float32>, <tf.Tensor 'gradients_2/G/g_bn4_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:2' shape=(128,) dtype=float32>, <tf.Tensor 'gradients_2/G/g_bn4_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:3' shape=(0,) dtype=float32>, <tf.Tensor 'gradients_2/G/g_bn4_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:4' shape=(0,) dtype=float32>)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_bn4_1/FusedBatchNormV3_grad/tuple/control_dependency:0' shape=(128, 32, 32, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn4_1/FusedBatchNormV3_grad/tuple/control_dependency_1:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn4_1/FusedBatchNormV3_grad/tuple/control_dependency_2:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn4_1/FusedBatchNormV3_grad/tuple/control_dependency_3:0' shape=(0,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn4_1/FusedBatchNormV3_grad/tuple/control_dependency_4:0' shape=(0,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h4_deconv/conv2d_transpose_grad/Shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h4_deconv/conv2d_transpose_grad/Conv2DBackpropFilter:0' shape=(5, 5, 128, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h4_deconv/conv2d_transpose_grad/Conv2D:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_h4_deconv/conv2d_transpose_grad/tuple/control_dependency:0' shape=(5, 5, 128, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h4_deconv/conv2d_transpose_grad/tuple/control_dependency_1:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_h3_lrelu/add_grad/tuple/control_dependency:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h3_lrelu/add_grad/tuple/control_dependency_1:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h3_lrelu/mul_grad/Mul:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h3_lrelu/mul_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h3_lrelu/mul_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h3_lrelu/mul_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h3_lrelu/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h3_lrelu/mul_grad/Mul_1:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_h3_lrelu/mul_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h3_lrelu/mul_grad/tuple/control_dependency_1:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h3_lrelu/mul_1_grad/Mul:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h3_lrelu/mul_1_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h3_lrelu/mul_1_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h3_lrelu/mul_1_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h3_lrelu/mul_1_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h3_lrelu/mul_1_grad/Mul_1:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_h3_lrelu/mul_1_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h3_lrelu/mul_1_grad/tuple/control_dependency_1:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h3_lrelu/Abs_grad/Sign:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h3_lrelu/Abs_grad/mul:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/AddN_8:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/zeros_like_5:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/zeros_like_6:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/zeros_like_7:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/zeros_like_8:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/zeros_like_9:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn3_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:0' shape=(128, 16, 16, 256) dtype=float32>, <tf.Tensor 'gradients_2/G/g_bn3_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:1' shape=(256,) dtype=float32>, <tf.Tensor 'gradients_2/G/g_bn3_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:2' shape=(256,) dtype=float32>, <tf.Tensor 'gradients_2/G/g_bn3_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:3' shape=(0,) dtype=float32>, <tf.Tensor 'gradients_2/G/g_bn3_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:4' shape=(0,) dtype=float32>)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_bn3_1/FusedBatchNormV3_grad/tuple/control_dependency:0' shape=(128, 16, 16, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn3_1/FusedBatchNormV3_grad/tuple/control_dependency_1:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn3_1/FusedBatchNormV3_grad/tuple/control_dependency_2:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn3_1/FusedBatchNormV3_grad/tuple/control_dependency_3:0' shape=(0,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn3_1/FusedBatchNormV3_grad/tuple/control_dependency_4:0' shape=(0,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h3_deconv/conv2d_transpose_grad/Shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h3_deconv/conv2d_transpose_grad/Conv2DBackpropFilter:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h3_deconv/conv2d_transpose_grad/Conv2D:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_h3_deconv/conv2d_transpose_grad/tuple/control_dependency:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h3_deconv/conv2d_transpose_grad/tuple/control_dependency_1:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_h2_lrelu/add_grad/tuple/control_dependency:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h2_lrelu/add_grad/tuple/control_dependency_1:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h2_lrelu/mul_grad/Mul:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h2_lrelu/mul_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h2_lrelu/mul_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h2_lrelu/mul_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h2_lrelu/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h2_lrelu/mul_grad/Mul_1:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_h2_lrelu/mul_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h2_lrelu/mul_grad/tuple/control_dependency_1:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h2_lrelu/mul_1_grad/Mul:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h2_lrelu/mul_1_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h2_lrelu/mul_1_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h2_lrelu/mul_1_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h2_lrelu/mul_1_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h2_lrelu/mul_1_grad/Mul_1:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_h2_lrelu/mul_1_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h2_lrelu/mul_1_grad/tuple/control_dependency_1:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h2_lrelu/Abs_grad/Sign:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h2_lrelu/Abs_grad/mul:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/AddN_9:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/zeros_like_10:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/zeros_like_11:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/zeros_like_12:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/zeros_like_13:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/zeros_like_14:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn2_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:0' shape=(128, 8, 8, 512) dtype=float32>, <tf.Tensor 'gradients_2/G/g_bn2_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:1' shape=(512,) dtype=float32>, <tf.Tensor 'gradients_2/G/g_bn2_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:2' shape=(512,) dtype=float32>, <tf.Tensor 'gradients_2/G/g_bn2_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:3' shape=(0,) dtype=float32>, <tf.Tensor 'gradients_2/G/g_bn2_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:4' shape=(0,) dtype=float32>)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_bn2_1/FusedBatchNormV3_grad/tuple/control_dependency:0' shape=(128, 8, 8, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn2_1/FusedBatchNormV3_grad/tuple/control_dependency_1:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn2_1/FusedBatchNormV3_grad/tuple/control_dependency_2:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn2_1/FusedBatchNormV3_grad/tuple/control_dependency_3:0' shape=(0,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn2_1/FusedBatchNormV3_grad/tuple/control_dependency_4:0' shape=(0,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h2_deconv/conv2d_transpose_grad/Shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h2_deconv/conv2d_transpose_grad/Conv2DBackpropFilter:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h2_deconv/conv2d_transpose_grad/Conv2D:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_h2_deconv/conv2d_transpose_grad/tuple/control_dependency:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h2_deconv/conv2d_transpose_grad/tuple/control_dependency_1:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_h1_lrelu/add_grad/tuple/control_dependency:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h1_lrelu/add_grad/tuple/control_dependency_1:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h1_lrelu/mul_grad/Mul:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h1_lrelu/mul_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h1_lrelu/mul_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h1_lrelu/mul_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h1_lrelu/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h1_lrelu/mul_grad/Mul_1:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_h1_lrelu/mul_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h1_lrelu/mul_grad/tuple/control_dependency_1:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h1_lrelu/mul_1_grad/Mul:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h1_lrelu/mul_1_grad/Sum/reduction_indices:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h1_lrelu/mul_1_grad/Sum:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h1_lrelu/mul_1_grad/Reshape/shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h1_lrelu/mul_1_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h1_lrelu/mul_1_grad/Mul_1:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_h1_lrelu/mul_1_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h1_lrelu/mul_1_grad/tuple/control_dependency_1:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h1_lrelu/Abs_grad/Sign:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h1_lrelu/Abs_grad/mul:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/AddN_10:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/zeros_like_15:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/zeros_like_16:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/zeros_like_17:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/zeros_like_18:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/zeros_like_19:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn1_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:0' shape=(128, 4, 4, 1024) dtype=float32>, <tf.Tensor 'gradients_2/G/g_bn1_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:1' shape=(1024,) dtype=float32>, <tf.Tensor 'gradients_2/G/g_bn1_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:2' shape=(1024,) dtype=float32>, <tf.Tensor 'gradients_2/G/g_bn1_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:3' shape=(0,) dtype=float32>, <tf.Tensor 'gradients_2/G/g_bn1_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:4' shape=(0,) dtype=float32>)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_bn1_1/FusedBatchNormV3_grad/tuple/control_dependency:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn1_1/FusedBatchNormV3_grad/tuple/control_dependency_1:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn1_1/FusedBatchNormV3_grad/tuple/control_dependency_2:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn1_1/FusedBatchNormV3_grad/tuple/control_dependency_3:0' shape=(0,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn1_1/FusedBatchNormV3_grad/tuple/control_dependency_4:0' shape=(0,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h1_deconv/conv2d_transpose_grad/Shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h1_deconv/conv2d_transpose_grad/Conv2DBackpropFilter:0' shape=(5, 5, 1024, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h1_deconv/conv2d_transpose_grad/Conv2D:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_h1_deconv/conv2d_transpose_grad/tuple/control_dependency:0' shape=(5, 5, 1024, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h1_deconv/conv2d_transpose_grad/tuple/control_dependency_1:0' shape=(128, 4, 4, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/Reshape_grad/Shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/Reshape_grad/Reshape:0' shape=(128, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/add_grad/Shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/add_grad/Shape_1:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/add_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients_2/G/g_h0_lrelu/add_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/add_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/add_grad/Reshape:0' shape=(?, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/add_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/add_grad/Reshape_1:0' shape=(?, 16384) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/add_grad/tuple/control_dependency:0' shape=(?, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/add_grad/tuple/control_dependency_1:0' shape=(?, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/mul_grad/Shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/mul_grad/Shape_1:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/mul_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients_2/G/g_h0_lrelu/mul_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/mul_grad/Mul:0' shape=(?, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/mul_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/mul_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/mul_grad/Mul_1:0' shape=(?, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/mul_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/mul_grad/Reshape_1:0' shape=(?, 16384) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/mul_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/mul_grad/tuple/control_dependency_1:0' shape=(?, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/mul_1_grad/Shape:0' shape=(0,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/mul_1_grad/Shape_1:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/mul_1_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients_2/G/g_h0_lrelu/mul_1_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/mul_1_grad/Mul:0' shape=(?, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/mul_1_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/mul_1_grad/Reshape:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/mul_1_grad/Mul_1:0' shape=(?, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/mul_1_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/mul_1_grad/Reshape_1:0' shape=(?, 16384) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/mul_1_grad/tuple/control_dependency:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/mul_1_grad/tuple/control_dependency_1:0' shape=(?, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/Abs_grad/Sign:0' shape=(?, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lrelu/Abs_grad/mul:0' shape=(?, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/AddN_11:0' shape=(?, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn0_1/Reshape_1_grad/Shape:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn0_1/Reshape_1_grad/Reshape:0' shape=(?, 1, 1, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/zeros_like_20:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/zeros_like_21:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/zeros_like_22:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/zeros_like_23:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/zeros_like_24:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn0_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:0' shape=(?, 1, 1, 16384) dtype=float32>, <tf.Tensor 'gradients_2/G/g_bn0_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:1' shape=(16384,) dtype=float32>, <tf.Tensor 'gradients_2/G/g_bn0_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:2' shape=(16384,) dtype=float32>, <tf.Tensor 'gradients_2/G/g_bn0_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:3' shape=(0,) dtype=float32>, <tf.Tensor 'gradients_2/G/g_bn0_1/FusedBatchNormV3_grad/FusedBatchNormGradV3:4' shape=(0,) dtype=float32>)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_bn0_1/FusedBatchNormV3_grad/tuple/control_dependency:0' shape=(?, 1, 1, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn0_1/FusedBatchNormV3_grad/tuple/control_dependency_1:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn0_1/FusedBatchNormV3_grad/tuple/control_dependency_2:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn0_1/FusedBatchNormV3_grad/tuple/control_dependency_3:0' shape=(0,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn0_1/FusedBatchNormV3_grad/tuple/control_dependency_4:0' shape=(0,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn0_1/Reshape_grad/Shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_bn0_1/Reshape_grad/Reshape:0' shape=(?, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lin/add_grad/Shape:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lin/add_grad/Shape_1:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lin/add_grad/BroadcastGradientArgs:0' shape=(?,) dtype=int32>, <tf.Tensor 'gradients_2/G/g_h0_lin/add_grad/BroadcastGradientArgs:1' shape=(?,) dtype=int32>)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lin/add_grad/Sum:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lin/add_grad/Reshape:0' shape=(?, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lin/add_grad/Sum_1:0' shape=<unknown> dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lin/add_grad/Reshape_1:0' shape=(16384,) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lin/add_grad/tuple/control_dependency:0' shape=(?, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lin/add_grad/tuple/control_dependency_1:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lin/MatMul_grad/MatMul:0' shape=(?, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lin/MatMul_grad/MatMul_1:0' shape=(128, 16384) dtype=float32>,)\n",
      "()\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lin/MatMul_grad/tuple/control_dependency:0' shape=(?, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'gradients_2/G/g_h0_lin/MatMul_grad/tuple/control_dependency_1:0' shape=(128, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'beta1_power_2/initial_value:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'beta1_power_2:0' shape=() dtype=float32_ref>,)\n",
      "(<tf.Tensor 'beta1_power_2/Assign:0' shape=() dtype=float32_ref>,)\n",
      "(<tf.Tensor 'beta1_power_2/read:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'beta2_power_2/initial_value:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'beta2_power_2:0' shape=() dtype=float32_ref>,)\n",
      "(<tf.Tensor 'beta2_power_2/Assign:0' shape=() dtype=float32_ref>,)\n",
      "(<tf.Tensor 'beta2_power_2/read:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/Matrix/Adam/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/Matrix/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/Matrix/Adam/Initializer/zeros:0' shape=(128, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/Matrix/Adam:0' shape=(128, 16384) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/Matrix/Adam/Assign:0' shape=(128, 16384) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/Matrix/Adam/read:0' shape=(128, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/Matrix/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(2,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/Matrix/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/Matrix/Adam_1/Initializer/zeros:0' shape=(128, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/Matrix/Adam_1:0' shape=(128, 16384) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/Matrix/Adam_1/Assign:0' shape=(128, 16384) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/Matrix/Adam_1/read:0' shape=(128, 16384) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/bias/Adam/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/bias/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/bias/Adam/Initializer/zeros:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/bias/Adam:0' shape=(16384,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/bias/Adam/Assign:0' shape=(16384,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/bias/Adam/read:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/bias/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/bias/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/bias/Adam_1/Initializer/zeros:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/bias/Adam_1:0' shape=(16384,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/bias/Adam_1/Assign:0' shape=(16384,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h0_lin/bias/Adam_1/read:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0/beta/Adam/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_bn0/beta/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0/beta/Adam/Initializer/zeros:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0/beta/Adam:0' shape=(16384,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn0/beta/Adam/Assign:0' shape=(16384,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn0/beta/Adam/read:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0/beta/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_bn0/beta/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0/beta/Adam_1/Initializer/zeros:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0/beta/Adam_1:0' shape=(16384,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn0/beta/Adam_1/Assign:0' shape=(16384,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn0/beta/Adam_1/read:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0/gamma/Adam/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_bn0/gamma/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0/gamma/Adam/Initializer/zeros:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0/gamma/Adam:0' shape=(16384,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn0/gamma/Adam/Assign:0' shape=(16384,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn0/gamma/Adam/read:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0/gamma/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_bn0/gamma/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0/gamma/Adam_1/Initializer/zeros:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn0/gamma/Adam_1:0' shape=(16384,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn0/gamma/Adam_1/Assign:0' shape=(16384,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn0/gamma/Adam_1/read:0' shape=(16384,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h1_deconv/w/Adam/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_h1_deconv/w/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h1_deconv/w/Adam/Initializer/zeros:0' shape=(5, 5, 1024, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h1_deconv/w/Adam:0' shape=(5, 5, 1024, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h1_deconv/w/Adam/Assign:0' shape=(5, 5, 1024, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h1_deconv/w/Adam/read:0' shape=(5, 5, 1024, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h1_deconv/w/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_h1_deconv/w/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h1_deconv/w/Adam_1/Initializer/zeros:0' shape=(5, 5, 1024, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h1_deconv/w/Adam_1:0' shape=(5, 5, 1024, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h1_deconv/w/Adam_1/Assign:0' shape=(5, 5, 1024, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h1_deconv/w/Adam_1/read:0' shape=(5, 5, 1024, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1/beta/Adam/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_bn1/beta/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1/beta/Adam/Initializer/zeros:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1/beta/Adam:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn1/beta/Adam/Assign:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn1/beta/Adam/read:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1/beta/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_bn1/beta/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1/beta/Adam_1/Initializer/zeros:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1/beta/Adam_1:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn1/beta/Adam_1/Assign:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn1/beta/Adam_1/read:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1/gamma/Adam/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_bn1/gamma/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1/gamma/Adam/Initializer/zeros:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1/gamma/Adam:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn1/gamma/Adam/Assign:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn1/gamma/Adam/read:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1/gamma/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(1,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_bn1/gamma/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1/gamma/Adam_1/Initializer/zeros:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn1/gamma/Adam_1:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn1/gamma/Adam_1/Assign:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn1/gamma/Adam_1/read:0' shape=(1024,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h2_deconv/w/Adam/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_h2_deconv/w/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h2_deconv/w/Adam/Initializer/zeros:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h2_deconv/w/Adam:0' shape=(5, 5, 512, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h2_deconv/w/Adam/Assign:0' shape=(5, 5, 512, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h2_deconv/w/Adam/read:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h2_deconv/w/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_h2_deconv/w/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h2_deconv/w/Adam_1/Initializer/zeros:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h2_deconv/w/Adam_1:0' shape=(5, 5, 512, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h2_deconv/w/Adam_1/Assign:0' shape=(5, 5, 512, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h2_deconv/w/Adam_1/read:0' shape=(5, 5, 512, 1024) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn2/beta/Adam/Initializer/zeros:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn2/beta/Adam:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn2/beta/Adam/Assign:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn2/beta/Adam/read:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn2/beta/Adam_1/Initializer/zeros:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn2/beta/Adam_1:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn2/beta/Adam_1/Assign:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn2/beta/Adam_1/read:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn2/gamma/Adam/Initializer/zeros:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn2/gamma/Adam:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn2/gamma/Adam/Assign:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn2/gamma/Adam/read:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn2/gamma/Adam_1/Initializer/zeros:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn2/gamma/Adam_1:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn2/gamma/Adam_1/Assign:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn2/gamma/Adam_1/read:0' shape=(512,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h3_deconv/w/Adam/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_h3_deconv/w/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h3_deconv/w/Adam/Initializer/zeros:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h3_deconv/w/Adam:0' shape=(5, 5, 256, 512) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h3_deconv/w/Adam/Assign:0' shape=(5, 5, 256, 512) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h3_deconv/w/Adam/read:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h3_deconv/w/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_h3_deconv/w/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h3_deconv/w/Adam_1/Initializer/zeros:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h3_deconv/w/Adam_1:0' shape=(5, 5, 256, 512) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h3_deconv/w/Adam_1/Assign:0' shape=(5, 5, 256, 512) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h3_deconv/w/Adam_1/read:0' shape=(5, 5, 256, 512) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn3/beta/Adam/Initializer/zeros:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn3/beta/Adam:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn3/beta/Adam/Assign:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn3/beta/Adam/read:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn3/beta/Adam_1/Initializer/zeros:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn3/beta/Adam_1:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn3/beta/Adam_1/Assign:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn3/beta/Adam_1/read:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn3/gamma/Adam/Initializer/zeros:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn3/gamma/Adam:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn3/gamma/Adam/Assign:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn3/gamma/Adam/read:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn3/gamma/Adam_1/Initializer/zeros:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn3/gamma/Adam_1:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn3/gamma/Adam_1/Assign:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn3/gamma/Adam_1/read:0' shape=(256,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h4_deconv/w/Adam/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_h4_deconv/w/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h4_deconv/w/Adam/Initializer/zeros:0' shape=(5, 5, 128, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h4_deconv/w/Adam:0' shape=(5, 5, 128, 256) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h4_deconv/w/Adam/Assign:0' shape=(5, 5, 128, 256) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h4_deconv/w/Adam/read:0' shape=(5, 5, 128, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h4_deconv/w/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_h4_deconv/w/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h4_deconv/w/Adam_1/Initializer/zeros:0' shape=(5, 5, 128, 256) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_h4_deconv/w/Adam_1:0' shape=(5, 5, 128, 256) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h4_deconv/w/Adam_1/Assign:0' shape=(5, 5, 128, 256) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_h4_deconv/w/Adam_1/read:0' shape=(5, 5, 128, 256) dtype=float32>,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'G/g_bn4/beta/Adam/Initializer/zeros:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn4/beta/Adam:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn4/beta/Adam/Assign:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn4/beta/Adam/read:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn4/beta/Adam_1/Initializer/zeros:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn4/beta/Adam_1:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn4/beta/Adam_1/Assign:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn4/beta/Adam_1/read:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn4/gamma/Adam/Initializer/zeros:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn4/gamma/Adam:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn4/gamma/Adam/Assign:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn4/gamma/Adam/read:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn4/gamma/Adam_1/Initializer/zeros:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_bn4/gamma/Adam_1:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn4/gamma/Adam_1/Assign:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_bn4/gamma/Adam_1/read:0' shape=(128,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_out/w/Adam/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_out/w/Adam/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_out/w/Adam/Initializer/zeros:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_out/w/Adam:0' shape=(5, 5, 3, 128) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_out/w/Adam/Assign:0' shape=(5, 5, 3, 128) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_out/w/Adam/read:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_out/w/Adam_1/Initializer/zeros/shape_as_tensor:0' shape=(4,) dtype=int32>,)\n",
      "(<tf.Tensor 'G/g_out/w/Adam_1/Initializer/zeros/Const:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_out/w/Adam_1/Initializer/zeros:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_out/w/Adam_1:0' shape=(5, 5, 3, 128) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_out/w/Adam_1/Assign:0' shape=(5, 5, 3, 128) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_out/w/Adam_1/read:0' shape=(5, 5, 3, 128) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_out/biases/Adam/Initializer/zeros:0' shape=(3,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_out/biases/Adam:0' shape=(3,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_out/biases/Adam/Assign:0' shape=(3,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_out/biases/Adam/read:0' shape=(3,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_out/biases/Adam_1/Initializer/zeros:0' shape=(3,) dtype=float32>,)\n",
      "(<tf.Tensor 'G/g_out/biases/Adam_1:0' shape=(3,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_out/biases/Adam_1/Assign:0' shape=(3,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'G/g_out/biases/Adam_1/read:0' shape=(3,) dtype=float32>,)\n",
      "(<tf.Tensor 'Adam_2/learning_rate:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'Adam_2/beta1:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'Adam_2/beta2:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'Adam_2/epsilon:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'Adam_2/update_G/g_h0_lin/Matrix/ApplyAdam:0' shape=(128, 16384) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_2/update_G/g_h0_lin/bias/ApplyAdam:0' shape=(16384,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_2/update_G/g_bn0/beta/ApplyAdam:0' shape=(16384,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_2/update_G/g_bn0/gamma/ApplyAdam:0' shape=(16384,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_2/update_G/g_h1_deconv/w/ApplyAdam:0' shape=(5, 5, 1024, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_2/update_G/g_bn1/beta/ApplyAdam:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_2/update_G/g_bn1/gamma/ApplyAdam:0' shape=(1024,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_2/update_G/g_h2_deconv/w/ApplyAdam:0' shape=(5, 5, 512, 1024) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_2/update_G/g_bn2/beta/ApplyAdam:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_2/update_G/g_bn2/gamma/ApplyAdam:0' shape=(512,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_2/update_G/g_h3_deconv/w/ApplyAdam:0' shape=(5, 5, 256, 512) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_2/update_G/g_bn3/beta/ApplyAdam:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_2/update_G/g_bn3/gamma/ApplyAdam:0' shape=(256,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_2/update_G/g_h4_deconv/w/ApplyAdam:0' shape=(5, 5, 128, 256) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_2/update_G/g_bn4/beta/ApplyAdam:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_2/update_G/g_bn4/gamma/ApplyAdam:0' shape=(128,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_2/update_G/g_out/w/ApplyAdam:0' shape=(5, 5, 3, 128) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_2/update_G/g_out/biases/ApplyAdam:0' shape=(3,) dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_2/mul:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'Adam_2/Assign:0' shape=() dtype=float32_ref>,)\n",
      "(<tf.Tensor 'Adam_2/mul_1:0' shape=() dtype=float32>,)\n",
      "(<tf.Tensor 'Adam_2/Assign_1:0' shape=() dtype=float32_ref>,)\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    op = sess.graph.get_operations()\n",
    "    for m in op:\n",
    "        print( m.values() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for training and evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(sess, load_dir):\n",
    "    \"\"\"load network's paramaters\n",
    "    \n",
    "    load_dir : path to load dir\n",
    "    \"\"\"\n",
    "    saver = tf.train.Saver()\n",
    "    ckpt = tf.train.get_checkpoint_state(load_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training GAN (1 point + 2 for good results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(sess, load_dir=None, save_frequency=100, sample_frequency=100, sample_dir='sample_faces',\n",
    "          save_dir='checkpoint', max_to_keep=1, model_name='dcgan.model',\n",
    "          n_epochs=25, n_generator_update=2):\n",
    "    \"\"\"train gan\n",
    "    Parameters\n",
    "    -------------------------------------------\n",
    "    load_dir : str, default = None\n",
    "        path to the folder with parameters\n",
    "    save_frequency: int, default = 100\n",
    "        how often save parameters []\n",
    "    sample_frequency: int, default = None (not sample)\n",
    "        how often sample faces\n",
    "    sample_dir: str, default = samples\n",
    "        directory for sampled images\n",
    "    save_dir: str, default = 'checkpoint'\n",
    "        path where to save parameters\n",
    "    max_to_keep: int, default = 1\n",
    "        how many last checkpoints to store\n",
    "    model_name: str, default='dcgan.model'\n",
    "        name of model\n",
    "    n_epochs: int, default = 25 \n",
    "        number epochs to train\n",
    "    n_generator_update: int, default = 2\n",
    "        how many times run generator updates per one discriminator update\n",
    "    -------------------------------------------\n",
    "    \"\"\"\n",
    "    \n",
    "    if save_frequency is not None:\n",
    "        saver = tf.train.Saver(max_to_keep=max_to_keep)\n",
    "        \n",
    "    if load_dir is not None:\n",
    "        print(\"Reading checkpoints...\")\n",
    "        load(sess, load_dir)\n",
    "        print(\"Loaded checkpoints\")\n",
    "    else:\n",
    "        try:\n",
    "            tf.global_variables_initializer().run()\n",
    "        except:\n",
    "            tf.initialize_all_variables().run()\n",
    "\n",
    "    counter=1\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        batch_idxs = min(len(data), np.inf) // BATCH_SIZE\n",
    "        for idx in range(batch_idxs):\n",
    "            batch_files = data[idx*BATCH_SIZE:(idx+1)*BATCH_SIZE]\n",
    "            \n",
    "            batch = [ get_image(batch_file, IMAGE_SIZE) for batch_file in batch_files ]\n",
    "            batch_images = np.array(batch).astype(np.float32)\n",
    "            \n",
    "            batch_real_labels = np.random.uniform(.7, 1.2, [BATCH_SIZE, 1]).astype(np.float32)            \n",
    "            batch_fake_labels = np.random.uniform(0., .3, [BATCH_SIZE, 1]).astype(np.float32)\n",
    "            \n",
    "            label_flip_choices = np.random.uniform(0., 1., BATCH_SIZE)\n",
    "            for label_i in range(BATCH_SIZE):\n",
    "                if label_flip_choices[label_i] < FLIP_LABEL_PROB:\n",
    "                    batch_real_labels[label_i], batch_fake_labels[label_i] = batch_fake_labels[label_i], batch_real_labels[label_i]\n",
    "                        \n",
    "            #batch_z = np.random.uniform(-1, 1, [BATCH_SIZE, Z_DIM]).astype(np.float32)\n",
    "            batch_z = np.random.normal(size=(BATCH_SIZE, Z_DIM)).astype(np.float32)\n",
    "\n",
    "            # Update D network\n",
    "            #sess.run(d_optim, feed_dict={images: batch_images, z: batch_z,is_training: True})\n",
    "            sess.run(d_real_optim, feed_dict={ images: batch_images, real_labels: batch_real_labels, is_training: True})\n",
    "            sess.run(d_fake_optim, feed_dict={ z: batch_z, fake_labels: batch_fake_labels, is_training: True})\n",
    "\n",
    "            # Update G network\n",
    "            for _ in range(n_generator_update):\n",
    "                #batch_z = np.random.uniform(-1, 1, [BATCH_SIZE, Z_DIM]).astype(np.float32)\n",
    "                batch_z = np.random.normal(size=(BATCH_SIZE, Z_DIM)).astype(np.float32)\n",
    "                sess.run(g_optim, feed_dict={z: batch_z, is_training: True})\n",
    "\n",
    "            errD_fake = d_loss_fake.eval({z: batch_z, fake_labels: batch_fake_labels, is_training: False})\n",
    "            errD_real = d_loss_real.eval({images: batch_images, real_labels: batch_real_labels, is_training: False})\n",
    "            errG = g_loss.eval({z: batch_z, is_training: False})\n",
    "\n",
    "            counter += 1\n",
    "            print(\"Epoch: [{:2d}] [{:4d}/{:4d}] time: {:4.4f}, d_loss: {:.8f}, g_loss: {:.8f}\".format(\n",
    "                epoch, idx, batch_idxs, time.time() - start_time, errD_fake+errD_real, errG))\n",
    "\n",
    "            if np.mod(counter, save_frequency) == 1:\n",
    "                print(\"Saved model\")\n",
    "                saver.save(sess,\n",
    "                           os.path.join(save_dir, '{}_{:02d}_{:04d}'.format(model_name, epoch, idx)))\n",
    "\n",
    "            if np.mod(counter, sample_frequency) == 1:\n",
    "                samples = sess.run(G, feed_dict={z: batch_z, is_training: False} )\n",
    "                print(samples.shape)\n",
    "                save_images(samples[:25], None, os.path.join(sample_dir, 'train_{:02d}_{:04d}.png'.format(epoch, idx)) )\n",
    "                print(\"Sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [   0/1582] time: 5.1904, d_loss: 1.18162453, g_loss: 0.67074358\n",
      "Epoch: [ 0] [   1/1582] time: 6.4268, d_loss: 1.22052860, g_loss: 0.67773741\n",
      "Epoch: [ 0] [   2/1582] time: 7.6598, d_loss: 1.15169477, g_loss: 0.67253828\n",
      "Epoch: [ 0] [   3/1582] time: 8.8927, d_loss: 1.15027094, g_loss: 0.67159033\n",
      "Epoch: [ 0] [   4/1582] time: 10.1317, d_loss: 1.19046164, g_loss: 0.68360430\n",
      "Epoch: [ 0] [   5/1582] time: 11.3669, d_loss: 1.16520810, g_loss: 0.68026257\n",
      "Epoch: [ 0] [   6/1582] time: 12.6029, d_loss: 1.16165936, g_loss: 0.68518454\n",
      "Epoch: [ 0] [   7/1582] time: 13.8368, d_loss: 1.14737213, g_loss: 0.68087637\n",
      "Epoch: [ 0] [   8/1582] time: 15.0738, d_loss: 1.14744163, g_loss: 0.67856121\n",
      "Epoch: [ 0] [   9/1582] time: 16.3073, d_loss: 1.18219256, g_loss: 0.68423128\n",
      "Epoch: [ 0] [  10/1582] time: 17.5423, d_loss: 1.16078436, g_loss: 0.68116051\n",
      "Epoch: [ 0] [  11/1582] time: 18.7762, d_loss: 1.15791821, g_loss: 0.67726004\n",
      "Epoch: [ 0] [  12/1582] time: 20.0122, d_loss: 1.16003680, g_loss: 0.68056989\n",
      "Epoch: [ 0] [  13/1582] time: 21.2471, d_loss: 1.17981291, g_loss: 0.67415112\n",
      "Epoch: [ 0] [  14/1582] time: 22.4841, d_loss: 1.16010976, g_loss: 0.68835199\n",
      "Epoch: [ 0] [  15/1582] time: 23.7170, d_loss: 1.16384387, g_loss: 0.68035227\n",
      "Epoch: [ 0] [  16/1582] time: 24.9533, d_loss: 1.14947379, g_loss: 0.68413329\n",
      "Epoch: [ 0] [  17/1582] time: 26.1863, d_loss: 1.14044976, g_loss: 0.68636674\n",
      "Epoch: [ 0] [  18/1582] time: 27.4193, d_loss: 1.16171324, g_loss: 0.69213009\n",
      "Epoch: [ 0] [  19/1582] time: 28.6512, d_loss: 1.13990831, g_loss: 0.68391788\n",
      "Epoch: [ 0] [  20/1582] time: 29.8864, d_loss: 1.13401794, g_loss: 0.69168973\n",
      "Epoch: [ 0] [  21/1582] time: 31.1154, d_loss: 1.14393973, g_loss: 0.68010658\n",
      "Epoch: [ 0] [  22/1582] time: 32.3513, d_loss: 1.18755817, g_loss: 0.68841982\n",
      "Epoch: [ 0] [  23/1582] time: 33.5851, d_loss: 1.17961478, g_loss: 0.68246210\n",
      "Epoch: [ 0] [  24/1582] time: 34.8221, d_loss: 1.11833525, g_loss: 0.67879272\n",
      "Epoch: [ 0] [  25/1582] time: 36.0600, d_loss: 1.16118109, g_loss: 0.68805242\n",
      "Epoch: [ 0] [  26/1582] time: 37.2960, d_loss: 1.14367437, g_loss: 0.69061649\n",
      "Epoch: [ 0] [  27/1582] time: 38.5274, d_loss: 1.15103996, g_loss: 0.68560970\n",
      "Epoch: [ 0] [  28/1582] time: 39.7644, d_loss: 1.17743969, g_loss: 0.68729591\n",
      "Epoch: [ 0] [  29/1582] time: 41.0004, d_loss: 1.12312031, g_loss: 0.68109971\n",
      "Epoch: [ 0] [  30/1582] time: 42.2383, d_loss: 1.16052675, g_loss: 0.68194330\n",
      "Epoch: [ 0] [  31/1582] time: 43.4771, d_loss: 1.13171744, g_loss: 0.69000632\n",
      "Epoch: [ 0] [  32/1582] time: 44.7141, d_loss: 1.13968444, g_loss: 0.69040424\n",
      "Epoch: [ 0] [  33/1582] time: 45.9640, d_loss: 1.12633407, g_loss: 0.70063859\n",
      "Epoch: [ 0] [  34/1582] time: 47.2129, d_loss: 1.15908742, g_loss: 0.68859458\n",
      "Epoch: [ 0] [  35/1582] time: 48.4698, d_loss: 1.14125156, g_loss: 0.69255030\n",
      "Epoch: [ 0] [  36/1582] time: 49.7237, d_loss: 1.12706888, g_loss: 0.69260406\n",
      "Epoch: [ 0] [  37/1582] time: 50.9568, d_loss: 1.13248897, g_loss: 0.69580066\n",
      "Epoch: [ 0] [  38/1582] time: 52.1963, d_loss: 1.13786590, g_loss: 0.69062233\n",
      "Epoch: [ 0] [  39/1582] time: 53.4342, d_loss: 1.11247063, g_loss: 0.69881004\n",
      "Epoch: [ 0] [  40/1582] time: 54.6722, d_loss: 1.11825442, g_loss: 0.69795686\n",
      "Epoch: [ 0] [  41/1582] time: 55.9108, d_loss: 1.15344691, g_loss: 0.69465500\n",
      "Epoch: [ 0] [  42/1582] time: 57.1501, d_loss: 1.14524782, g_loss: 0.69063246\n",
      "Epoch: [ 0] [  43/1582] time: 58.3881, d_loss: 1.13867438, g_loss: 0.69172627\n",
      "Epoch: [ 0] [  44/1582] time: 59.6260, d_loss: 1.13744354, g_loss: 0.68314403\n",
      "Epoch: [ 0] [  45/1582] time: 60.8620, d_loss: 1.13943839, g_loss: 0.68462616\n",
      "Epoch: [ 0] [  46/1582] time: 62.1110, d_loss: 1.14858103, g_loss: 0.68271327\n",
      "Epoch: [ 0] [  47/1582] time: 63.3600, d_loss: 1.11255598, g_loss: 0.67830747\n",
      "Epoch: [ 0] [  48/1582] time: 64.5989, d_loss: 1.15172958, g_loss: 0.68145788\n",
      "Epoch: [ 0] [  49/1582] time: 65.8339, d_loss: 1.14880300, g_loss: 0.67671323\n",
      "Epoch: [ 0] [  50/1582] time: 67.0684, d_loss: 1.12194300, g_loss: 0.67855346\n",
      "Epoch: [ 0] [  51/1582] time: 68.3014, d_loss: 1.13317823, g_loss: 0.67524767\n",
      "Epoch: [ 0] [  52/1582] time: 69.5383, d_loss: 1.15164232, g_loss: 0.67381239\n",
      "Epoch: [ 0] [  53/1582] time: 70.7763, d_loss: 1.15481806, g_loss: 0.67653966\n",
      "Epoch: [ 0] [  54/1582] time: 72.0150, d_loss: 1.15604591, g_loss: 0.67350113\n",
      "Epoch: [ 0] [  55/1582] time: 73.2579, d_loss: 1.12652922, g_loss: 0.67542756\n",
      "Epoch: [ 0] [  56/1582] time: 74.5109, d_loss: 1.15073562, g_loss: 0.67668164\n",
      "Epoch: [ 0] [  57/1582] time: 75.7628, d_loss: 1.15277159, g_loss: 0.67700481\n",
      "Epoch: [ 0] [  58/1582] time: 77.0047, d_loss: 1.14186966, g_loss: 0.67139399\n",
      "Epoch: [ 0] [  59/1582] time: 78.2417, d_loss: 1.12832761, g_loss: 0.66600168\n",
      "Epoch: [ 0] [  60/1582] time: 79.4796, d_loss: 1.14309680, g_loss: 0.66352034\n",
      "Epoch: [ 0] [  61/1582] time: 80.7156, d_loss: 1.14310372, g_loss: 0.66914225\n",
      "Epoch: [ 0] [  62/1582] time: 81.9530, d_loss: 1.15549707, g_loss: 0.67042571\n",
      "Epoch: [ 0] [  63/1582] time: 83.1940, d_loss: 1.14002550, g_loss: 0.66567713\n",
      "Epoch: [ 0] [  64/1582] time: 84.4299, d_loss: 1.11664438, g_loss: 0.66896683\n",
      "Epoch: [ 0] [  65/1582] time: 85.6619, d_loss: 1.12855053, g_loss: 0.66976291\n",
      "Epoch: [ 0] [  66/1582] time: 86.8989, d_loss: 1.16955638, g_loss: 0.67271686\n",
      "Epoch: [ 0] [  67/1582] time: 88.1379, d_loss: 1.15953040, g_loss: 0.66449547\n",
      "Epoch: [ 0] [  68/1582] time: 89.3728, d_loss: 1.15821505, g_loss: 0.67188203\n",
      "Epoch: [ 0] [  69/1582] time: 90.6099, d_loss: 1.14668107, g_loss: 0.67583716\n",
      "Epoch: [ 0] [  70/1582] time: 91.8509, d_loss: 1.14071286, g_loss: 0.67194289\n",
      "Epoch: [ 0] [  71/1582] time: 93.0939, d_loss: 1.13757825, g_loss: 0.67523468\n",
      "Epoch: [ 0] [  72/1582] time: 94.3316, d_loss: 1.16519940, g_loss: 0.67523944\n",
      "Epoch: [ 0] [  73/1582] time: 95.5735, d_loss: 1.17675710, g_loss: 0.66986394\n",
      "Epoch: [ 0] [  74/1582] time: 96.8125, d_loss: 1.16808283, g_loss: 0.67575431\n",
      "Epoch: [ 0] [  75/1582] time: 98.0514, d_loss: 1.14201236, g_loss: 0.67400610\n",
      "Epoch: [ 0] [  76/1582] time: 99.2924, d_loss: 1.14972997, g_loss: 0.67673624\n",
      "Epoch: [ 0] [  77/1582] time: 100.5343, d_loss: 1.14380026, g_loss: 0.67143965\n",
      "Epoch: [ 0] [  78/1582] time: 101.7749, d_loss: 1.15544283, g_loss: 0.67013472\n",
      "Epoch: [ 0] [  79/1582] time: 103.0259, d_loss: 1.12484145, g_loss: 0.66344047\n",
      "Epoch: [ 0] [  80/1582] time: 104.2719, d_loss: 1.16474271, g_loss: 0.67341697\n",
      "Epoch: [ 0] [  81/1582] time: 105.5138, d_loss: 1.15031171, g_loss: 0.67176527\n",
      "Epoch: [ 0] [  82/1582] time: 106.7529, d_loss: 1.16527891, g_loss: 0.66897023\n",
      "Epoch: [ 0] [  83/1582] time: 107.9928, d_loss: 1.14541197, g_loss: 0.67070854\n",
      "Epoch: [ 0] [  84/1582] time: 109.2327, d_loss: 1.16145527, g_loss: 0.66572881\n",
      "Epoch: [ 0] [  85/1582] time: 110.4738, d_loss: 1.12954021, g_loss: 0.66808021\n",
      "Epoch: [ 0] [  86/1582] time: 111.7157, d_loss: 1.15754652, g_loss: 0.67758107\n",
      "Epoch: [ 0] [  87/1582] time: 112.9558, d_loss: 1.14583433, g_loss: 0.66303694\n",
      "Epoch: [ 0] [  88/1582] time: 114.1978, d_loss: 1.12033308, g_loss: 0.67119861\n",
      "Epoch: [ 0] [  89/1582] time: 115.4407, d_loss: 1.16412568, g_loss: 0.67291093\n",
      "Epoch: [ 0] [  90/1582] time: 116.6817, d_loss: 1.12518930, g_loss: 0.67279798\n",
      "Epoch: [ 0] [  91/1582] time: 117.9246, d_loss: 1.12808681, g_loss: 0.67556435\n",
      "Epoch: [ 0] [  92/1582] time: 119.1675, d_loss: 1.14705253, g_loss: 0.67544711\n",
      "Epoch: [ 0] [  93/1582] time: 120.4085, d_loss: 1.12560296, g_loss: 0.67571294\n",
      "Epoch: [ 0] [  94/1582] time: 121.6526, d_loss: 1.14355183, g_loss: 0.68049502\n",
      "Epoch: [ 0] [  95/1582] time: 122.8951, d_loss: 1.17810881, g_loss: 0.68254346\n",
      "Epoch: [ 0] [  96/1582] time: 124.1381, d_loss: 1.16556787, g_loss: 0.67850029\n",
      "Epoch: [ 0] [  97/1582] time: 125.3770, d_loss: 1.13486540, g_loss: 0.68068081\n",
      "Epoch: [ 0] [  98/1582] time: 126.6160, d_loss: 1.14796710, g_loss: 0.68220663\n",
      "Epoch: [ 0] [  99/1582] time: 127.8599, d_loss: 1.12725139, g_loss: 0.67648399\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 0] [ 100/1582] time: 136.6489, d_loss: 1.14166081, g_loss: 0.68086928\n",
      "Epoch: [ 0] [ 101/1582] time: 137.8888, d_loss: 1.11329961, g_loss: 0.67638612\n",
      "Epoch: [ 0] [ 102/1582] time: 139.1289, d_loss: 1.15666866, g_loss: 0.68433464\n",
      "Epoch: [ 0] [ 103/1582] time: 140.3669, d_loss: 1.12828064, g_loss: 0.67759150\n",
      "Epoch: [ 0] [ 104/1582] time: 141.6048, d_loss: 1.11907244, g_loss: 0.68527186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [ 105/1582] time: 142.8428, d_loss: 1.10346270, g_loss: 0.68385148\n",
      "Epoch: [ 0] [ 106/1582] time: 144.0837, d_loss: 1.15531361, g_loss: 0.68581414\n",
      "Epoch: [ 0] [ 107/1582] time: 145.3207, d_loss: 1.15534449, g_loss: 0.68559927\n",
      "Epoch: [ 0] [ 108/1582] time: 146.5577, d_loss: 1.14943707, g_loss: 0.68375796\n",
      "Epoch: [ 0] [ 109/1582] time: 147.7956, d_loss: 1.13648915, g_loss: 0.68419731\n",
      "Epoch: [ 0] [ 110/1582] time: 149.0346, d_loss: 1.15031648, g_loss: 0.68516284\n",
      "Epoch: [ 0] [ 111/1582] time: 150.2745, d_loss: 1.12051630, g_loss: 0.68048072\n",
      "Epoch: [ 0] [ 112/1582] time: 151.5135, d_loss: 1.12262523, g_loss: 0.68476593\n",
      "Epoch: [ 0] [ 113/1582] time: 152.7534, d_loss: 1.13052702, g_loss: 0.68237877\n",
      "Epoch: [ 0] [ 114/1582] time: 153.9914, d_loss: 1.13912201, g_loss: 0.69074619\n",
      "Epoch: [ 0] [ 115/1582] time: 155.2341, d_loss: 1.12456012, g_loss: 0.68456072\n",
      "Epoch: [ 0] [ 116/1582] time: 156.4731, d_loss: 1.13979304, g_loss: 0.69260812\n",
      "Epoch: [ 0] [ 117/1582] time: 157.7090, d_loss: 1.13883364, g_loss: 0.68702471\n",
      "Epoch: [ 0] [ 118/1582] time: 158.9461, d_loss: 1.15295124, g_loss: 0.68774164\n",
      "Epoch: [ 0] [ 119/1582] time: 160.1851, d_loss: 1.13078523, g_loss: 0.68581706\n",
      "Epoch: [ 0] [ 120/1582] time: 161.4250, d_loss: 1.12036896, g_loss: 0.69677985\n",
      "Epoch: [ 0] [ 121/1582] time: 162.6636, d_loss: 1.14304590, g_loss: 0.68571943\n",
      "Epoch: [ 0] [ 122/1582] time: 163.9019, d_loss: 1.17757201, g_loss: 0.68896204\n",
      "Epoch: [ 0] [ 123/1582] time: 165.1398, d_loss: 1.16036797, g_loss: 0.68308938\n",
      "Epoch: [ 0] [ 124/1582] time: 166.3758, d_loss: 1.07976985, g_loss: 0.68863672\n",
      "Epoch: [ 0] [ 125/1582] time: 167.6137, d_loss: 1.15927422, g_loss: 0.68290436\n",
      "Epoch: [ 0] [ 126/1582] time: 168.8557, d_loss: 1.16663921, g_loss: 0.68411827\n",
      "Epoch: [ 0] [ 127/1582] time: 170.0936, d_loss: 1.13053143, g_loss: 0.68700343\n",
      "Epoch: [ 0] [ 128/1582] time: 171.3321, d_loss: 1.13639045, g_loss: 0.68455392\n",
      "Epoch: [ 0] [ 129/1582] time: 172.5711, d_loss: 1.09518337, g_loss: 0.68041945\n",
      "Epoch: [ 0] [ 130/1582] time: 173.8111, d_loss: 1.15279317, g_loss: 0.68826652\n",
      "Epoch: [ 0] [ 131/1582] time: 175.0484, d_loss: 1.13533080, g_loss: 0.68475884\n",
      "Epoch: [ 0] [ 132/1582] time: 176.2853, d_loss: 1.12961650, g_loss: 0.67709649\n",
      "Epoch: [ 0] [ 133/1582] time: 177.5213, d_loss: 1.13774300, g_loss: 0.68214297\n",
      "Epoch: [ 0] [ 134/1582] time: 178.7574, d_loss: 1.13990450, g_loss: 0.68344826\n",
      "Epoch: [ 0] [ 135/1582] time: 179.9983, d_loss: 1.14646506, g_loss: 0.67848051\n",
      "Epoch: [ 0] [ 136/1582] time: 181.2354, d_loss: 1.13910961, g_loss: 0.67893922\n",
      "Epoch: [ 0] [ 137/1582] time: 182.4746, d_loss: 1.17174220, g_loss: 0.67986596\n",
      "Epoch: [ 0] [ 138/1582] time: 183.7165, d_loss: 1.13361859, g_loss: 0.67821085\n",
      "Epoch: [ 0] [ 139/1582] time: 184.9605, d_loss: 1.12423825, g_loss: 0.67844200\n",
      "Epoch: [ 0] [ 140/1582] time: 186.2005, d_loss: 1.16208959, g_loss: 0.67940396\n",
      "Epoch: [ 0] [ 141/1582] time: 187.4414, d_loss: 1.15279031, g_loss: 0.68010807\n",
      "Epoch: [ 0] [ 142/1582] time: 188.6794, d_loss: 1.14604330, g_loss: 0.67735368\n",
      "Epoch: [ 0] [ 143/1582] time: 189.9227, d_loss: 1.17544150, g_loss: 0.67633557\n",
      "Epoch: [ 0] [ 144/1582] time: 191.1607, d_loss: 1.13424397, g_loss: 0.67500055\n",
      "Epoch: [ 0] [ 145/1582] time: 192.3991, d_loss: 1.14789677, g_loss: 0.67431486\n",
      "Epoch: [ 0] [ 146/1582] time: 193.6311, d_loss: 1.14845586, g_loss: 0.67921865\n",
      "Epoch: [ 0] [ 147/1582] time: 194.8670, d_loss: 1.15130031, g_loss: 0.67498976\n",
      "Epoch: [ 0] [ 148/1582] time: 196.1050, d_loss: 1.19137001, g_loss: 0.67542863\n",
      "Epoch: [ 0] [ 149/1582] time: 197.3409, d_loss: 1.15815365, g_loss: 0.67507875\n",
      "Epoch: [ 0] [ 150/1582] time: 198.5769, d_loss: 1.15553558, g_loss: 0.67275459\n",
      "Epoch: [ 0] [ 151/1582] time: 199.8077, d_loss: 1.14329910, g_loss: 0.67196262\n",
      "Epoch: [ 0] [ 152/1582] time: 201.0487, d_loss: 1.15624917, g_loss: 0.67315662\n",
      "Epoch: [ 0] [ 153/1582] time: 202.2904, d_loss: 1.18989587, g_loss: 0.66933310\n",
      "Epoch: [ 0] [ 154/1582] time: 203.5304, d_loss: 1.14861560, g_loss: 0.67683315\n",
      "Epoch: [ 0] [ 155/1582] time: 204.7713, d_loss: 1.20107198, g_loss: 0.67463684\n",
      "Epoch: [ 0] [ 156/1582] time: 206.0103, d_loss: 1.14788270, g_loss: 0.67720163\n",
      "Epoch: [ 0] [ 157/1582] time: 207.2562, d_loss: 1.17782521, g_loss: 0.67415154\n",
      "Epoch: [ 0] [ 158/1582] time: 208.4964, d_loss: 1.17109227, g_loss: 0.67716497\n",
      "Epoch: [ 0] [ 159/1582] time: 209.7328, d_loss: 1.17742252, g_loss: 0.67167819\n",
      "Epoch: [ 0] [ 160/1582] time: 210.9700, d_loss: 1.15378702, g_loss: 0.67565513\n",
      "Epoch: [ 0] [ 161/1582] time: 212.2099, d_loss: 1.17668891, g_loss: 0.66892618\n",
      "Epoch: [ 0] [ 162/1582] time: 213.4499, d_loss: 1.11905980, g_loss: 0.67461300\n",
      "Epoch: [ 0] [ 163/1582] time: 214.6916, d_loss: 1.14818108, g_loss: 0.66797733\n",
      "Epoch: [ 0] [ 164/1582] time: 215.9306, d_loss: 1.15063524, g_loss: 0.67784423\n",
      "Epoch: [ 0] [ 165/1582] time: 217.1725, d_loss: 1.18685794, g_loss: 0.67571175\n",
      "Epoch: [ 0] [ 166/1582] time: 218.4115, d_loss: 1.18290687, g_loss: 0.67440140\n",
      "Epoch: [ 0] [ 167/1582] time: 219.6464, d_loss: 1.14557958, g_loss: 0.66909325\n",
      "Epoch: [ 0] [ 168/1582] time: 220.8844, d_loss: 1.14557445, g_loss: 0.67205769\n",
      "Epoch: [ 0] [ 169/1582] time: 222.1244, d_loss: 1.16427326, g_loss: 0.67766416\n",
      "Epoch: [ 0] [ 170/1582] time: 223.3763, d_loss: 1.18744040, g_loss: 0.67468965\n",
      "Epoch: [ 0] [ 171/1582] time: 224.6212, d_loss: 1.18697023, g_loss: 0.67409444\n",
      "Epoch: [ 0] [ 172/1582] time: 225.8682, d_loss: 1.18579412, g_loss: 0.67273968\n",
      "Epoch: [ 0] [ 173/1582] time: 227.1087, d_loss: 1.16770291, g_loss: 0.67071545\n",
      "Epoch: [ 0] [ 174/1582] time: 228.3416, d_loss: 1.15915811, g_loss: 0.67067981\n",
      "Epoch: [ 0] [ 175/1582] time: 229.5816, d_loss: 1.16782427, g_loss: 0.67222029\n",
      "Epoch: [ 0] [ 176/1582] time: 230.8215, d_loss: 1.17552042, g_loss: 0.67029202\n",
      "Epoch: [ 0] [ 177/1582] time: 232.0635, d_loss: 1.13693583, g_loss: 0.66882443\n",
      "Epoch: [ 0] [ 178/1582] time: 233.3024, d_loss: 1.17877591, g_loss: 0.67240560\n",
      "Epoch: [ 0] [ 179/1582] time: 234.5414, d_loss: 1.18122375, g_loss: 0.66553152\n",
      "Epoch: [ 0] [ 180/1582] time: 235.7814, d_loss: 1.17621708, g_loss: 0.66995341\n",
      "Epoch: [ 0] [ 181/1582] time: 237.0213, d_loss: 1.11930943, g_loss: 0.66527736\n",
      "Epoch: [ 0] [ 182/1582] time: 238.2565, d_loss: 1.16865432, g_loss: 0.66756427\n",
      "Epoch: [ 0] [ 183/1582] time: 239.4934, d_loss: 1.17459249, g_loss: 0.66780508\n",
      "Epoch: [ 0] [ 184/1582] time: 240.7308, d_loss: 1.14872718, g_loss: 0.67098826\n",
      "Epoch: [ 0] [ 185/1582] time: 241.9669, d_loss: 1.18013120, g_loss: 0.66929555\n",
      "Epoch: [ 0] [ 186/1582] time: 243.2088, d_loss: 1.17888284, g_loss: 0.66846955\n",
      "Epoch: [ 0] [ 187/1582] time: 244.4468, d_loss: 1.14917195, g_loss: 0.66929352\n",
      "Epoch: [ 0] [ 188/1582] time: 245.6904, d_loss: 1.17444658, g_loss: 0.66573918\n",
      "Epoch: [ 0] [ 189/1582] time: 246.9323, d_loss: 1.19000316, g_loss: 0.67085063\n",
      "Epoch: [ 0] [ 190/1582] time: 248.1716, d_loss: 1.14473915, g_loss: 0.66697782\n",
      "Epoch: [ 0] [ 191/1582] time: 249.4105, d_loss: 1.16610813, g_loss: 0.66823316\n",
      "Epoch: [ 0] [ 192/1582] time: 250.6485, d_loss: 1.17438412, g_loss: 0.66676825\n",
      "Epoch: [ 0] [ 193/1582] time: 251.8886, d_loss: 1.19728220, g_loss: 0.66469181\n",
      "Epoch: [ 0] [ 194/1582] time: 253.1295, d_loss: 1.14582038, g_loss: 0.67120337\n",
      "Epoch: [ 0] [ 195/1582] time: 254.3715, d_loss: 1.18102098, g_loss: 0.66556340\n",
      "Epoch: [ 0] [ 196/1582] time: 255.6105, d_loss: 1.18192196, g_loss: 0.67179763\n",
      "Epoch: [ 0] [ 197/1582] time: 256.8444, d_loss: 1.18350697, g_loss: 0.67363918\n",
      "Epoch: [ 0] [ 198/1582] time: 258.0834, d_loss: 1.18241763, g_loss: 0.67031217\n",
      "Epoch: [ 0] [ 199/1582] time: 259.3269, d_loss: 1.16786492, g_loss: 0.66811311\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 0] [ 200/1582] time: 267.3050, d_loss: 1.15702939, g_loss: 0.67563403\n",
      "Epoch: [ 0] [ 201/1582] time: 268.5440, d_loss: 1.17907727, g_loss: 0.67108285\n",
      "Epoch: [ 0] [ 202/1582] time: 269.7860, d_loss: 1.15258670, g_loss: 0.67162997\n",
      "Epoch: [ 0] [ 203/1582] time: 271.0216, d_loss: 1.17533016, g_loss: 0.67167157\n",
      "Epoch: [ 0] [ 204/1582] time: 272.2585, d_loss: 1.18963456, g_loss: 0.67443460\n",
      "Epoch: [ 0] [ 205/1582] time: 273.4983, d_loss: 1.15412211, g_loss: 0.67648852\n",
      "Epoch: [ 0] [ 206/1582] time: 274.7403, d_loss: 1.16696310, g_loss: 0.67195666\n",
      "Epoch: [ 0] [ 207/1582] time: 275.9803, d_loss: 1.20658016, g_loss: 0.68103915\n",
      "Epoch: [ 0] [ 208/1582] time: 277.2202, d_loss: 1.14050198, g_loss: 0.67858505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [ 209/1582] time: 278.4596, d_loss: 1.16597998, g_loss: 0.67679107\n",
      "Epoch: [ 0] [ 210/1582] time: 279.6986, d_loss: 1.17853451, g_loss: 0.68434989\n",
      "Epoch: [ 0] [ 211/1582] time: 280.9391, d_loss: 1.18922830, g_loss: 0.68101978\n",
      "Epoch: [ 0] [ 212/1582] time: 282.1784, d_loss: 1.17867196, g_loss: 0.68034935\n",
      "Epoch: [ 0] [ 213/1582] time: 283.4166, d_loss: 1.16827607, g_loss: 0.67939562\n",
      "Epoch: [ 0] [ 214/1582] time: 284.6565, d_loss: 1.19244826, g_loss: 0.67670089\n",
      "Epoch: [ 0] [ 215/1582] time: 285.8937, d_loss: 1.17092586, g_loss: 0.68494320\n",
      "Epoch: [ 0] [ 216/1582] time: 287.1327, d_loss: 1.17224264, g_loss: 0.68044376\n",
      "Epoch: [ 0] [ 217/1582] time: 288.3718, d_loss: 1.17704058, g_loss: 0.68701273\n",
      "Epoch: [ 0] [ 218/1582] time: 289.6097, d_loss: 1.16248417, g_loss: 0.68111432\n",
      "Epoch: [ 0] [ 219/1582] time: 290.8452, d_loss: 1.17824864, g_loss: 0.68536806\n",
      "Epoch: [ 0] [ 220/1582] time: 292.0842, d_loss: 1.14083695, g_loss: 0.68459260\n",
      "Epoch: [ 0] [ 221/1582] time: 293.3221, d_loss: 1.17502356, g_loss: 0.68335330\n",
      "Epoch: [ 0] [ 222/1582] time: 294.5590, d_loss: 1.17738223, g_loss: 0.68480253\n",
      "Epoch: [ 0] [ 223/1582] time: 295.7967, d_loss: 1.21443653, g_loss: 0.68843132\n",
      "Epoch: [ 0] [ 224/1582] time: 297.0329, d_loss: 1.19677699, g_loss: 0.68594396\n",
      "Epoch: [ 0] [ 225/1582] time: 298.2721, d_loss: 1.20307255, g_loss: 0.68562782\n",
      "Epoch: [ 0] [ 226/1582] time: 299.5111, d_loss: 1.16827571, g_loss: 0.68331206\n",
      "Epoch: [ 0] [ 227/1582] time: 300.7486, d_loss: 1.15341198, g_loss: 0.68423998\n",
      "Epoch: [ 0] [ 228/1582] time: 301.9826, d_loss: 1.18814516, g_loss: 0.68460184\n",
      "Epoch: [ 0] [ 229/1582] time: 303.2235, d_loss: 1.16174567, g_loss: 0.68954986\n",
      "Epoch: [ 0] [ 230/1582] time: 304.4625, d_loss: 1.15834832, g_loss: 0.68305129\n",
      "Epoch: [ 0] [ 231/1582] time: 305.7005, d_loss: 1.14304066, g_loss: 0.68173361\n",
      "Epoch: [ 0] [ 232/1582] time: 306.9364, d_loss: 1.16579235, g_loss: 0.68047047\n",
      "Epoch: [ 0] [ 233/1582] time: 308.1734, d_loss: 1.17858958, g_loss: 0.68636751\n",
      "Epoch: [ 0] [ 234/1582] time: 309.4084, d_loss: 1.18296671, g_loss: 0.67730039\n",
      "Epoch: [ 0] [ 235/1582] time: 310.6452, d_loss: 1.18500185, g_loss: 0.68252802\n",
      "Epoch: [ 0] [ 236/1582] time: 311.8831, d_loss: 1.15883851, g_loss: 0.68310148\n",
      "Epoch: [ 0] [ 237/1582] time: 313.1231, d_loss: 1.15488958, g_loss: 0.67888618\n",
      "Epoch: [ 0] [ 238/1582] time: 314.3612, d_loss: 1.15066648, g_loss: 0.68078208\n",
      "Epoch: [ 0] [ 239/1582] time: 315.5982, d_loss: 1.17615879, g_loss: 0.68146390\n",
      "Epoch: [ 0] [ 240/1582] time: 316.8361, d_loss: 1.14782369, g_loss: 0.68100983\n",
      "Epoch: [ 0] [ 241/1582] time: 318.0783, d_loss: 1.13229811, g_loss: 0.68075454\n",
      "Epoch: [ 0] [ 242/1582] time: 319.3162, d_loss: 1.15551817, g_loss: 0.67698234\n",
      "Epoch: [ 0] [ 243/1582] time: 320.5562, d_loss: 1.17830563, g_loss: 0.67652750\n",
      "Epoch: [ 0] [ 244/1582] time: 321.8051, d_loss: 1.14041531, g_loss: 0.67712492\n",
      "Epoch: [ 0] [ 245/1582] time: 323.0951, d_loss: 1.16836989, g_loss: 0.68376243\n",
      "Epoch: [ 0] [ 246/1582] time: 324.3341, d_loss: 1.18373811, g_loss: 0.67922711\n",
      "Epoch: [ 0] [ 247/1582] time: 325.5720, d_loss: 1.18752146, g_loss: 0.68054324\n",
      "Epoch: [ 0] [ 248/1582] time: 326.8079, d_loss: 1.18930244, g_loss: 0.67509830\n",
      "Epoch: [ 0] [ 249/1582] time: 328.0469, d_loss: 1.17546511, g_loss: 0.67342198\n",
      "Epoch: [ 0] [ 250/1582] time: 329.2879, d_loss: 1.13003302, g_loss: 0.67918646\n",
      "Epoch: [ 0] [ 251/1582] time: 330.5298, d_loss: 1.16910267, g_loss: 0.67476493\n",
      "Epoch: [ 0] [ 252/1582] time: 331.7695, d_loss: 1.19007444, g_loss: 0.67446172\n",
      "Epoch: [ 0] [ 253/1582] time: 333.0065, d_loss: 1.13834250, g_loss: 0.67126995\n",
      "Epoch: [ 0] [ 254/1582] time: 334.2454, d_loss: 1.18100953, g_loss: 0.67130864\n",
      "Epoch: [ 0] [ 255/1582] time: 335.4874, d_loss: 1.17946148, g_loss: 0.67351472\n",
      "Epoch: [ 0] [ 256/1582] time: 336.7273, d_loss: 1.18282723, g_loss: 0.67190313\n",
      "Epoch: [ 0] [ 257/1582] time: 337.9643, d_loss: 1.15919662, g_loss: 0.67547941\n",
      "Epoch: [ 0] [ 258/1582] time: 339.2033, d_loss: 1.17650747, g_loss: 0.67461741\n",
      "Epoch: [ 0] [ 259/1582] time: 340.4402, d_loss: 1.14553857, g_loss: 0.67471504\n",
      "Epoch: [ 0] [ 260/1582] time: 341.6802, d_loss: 1.15722442, g_loss: 0.67903781\n",
      "Epoch: [ 0] [ 261/1582] time: 342.9301, d_loss: 1.16472220, g_loss: 0.68119979\n",
      "Epoch: [ 0] [ 262/1582] time: 344.1785, d_loss: 1.15814829, g_loss: 0.67933893\n",
      "Epoch: [ 0] [ 263/1582] time: 345.4285, d_loss: 1.15089154, g_loss: 0.68074244\n",
      "Epoch: [ 0] [ 264/1582] time: 346.6664, d_loss: 1.16933870, g_loss: 0.68342710\n",
      "Epoch: [ 0] [ 265/1582] time: 347.9064, d_loss: 1.14979923, g_loss: 0.68102819\n",
      "Epoch: [ 0] [ 266/1582] time: 349.1490, d_loss: 1.19978905, g_loss: 0.68446696\n",
      "Epoch: [ 0] [ 267/1582] time: 350.3880, d_loss: 1.14741468, g_loss: 0.68210578\n",
      "Epoch: [ 0] [ 268/1582] time: 351.6279, d_loss: 1.16618216, g_loss: 0.68759429\n",
      "Epoch: [ 0] [ 269/1582] time: 352.8699, d_loss: 1.17795753, g_loss: 0.68281174\n",
      "Epoch: [ 0] [ 270/1582] time: 354.1114, d_loss: 1.15523171, g_loss: 0.68299079\n",
      "Epoch: [ 0] [ 271/1582] time: 355.3493, d_loss: 1.15141225, g_loss: 0.68349761\n",
      "Epoch: [ 0] [ 272/1582] time: 356.5873, d_loss: 1.14583886, g_loss: 0.68761438\n",
      "Epoch: [ 0] [ 273/1582] time: 357.8262, d_loss: 1.17621636, g_loss: 0.68264008\n",
      "Epoch: [ 0] [ 274/1582] time: 359.0632, d_loss: 1.17266071, g_loss: 0.68816864\n",
      "Epoch: [ 0] [ 275/1582] time: 360.3002, d_loss: 1.19227099, g_loss: 0.68642533\n",
      "Epoch: [ 0] [ 276/1582] time: 361.5401, d_loss: 1.16035712, g_loss: 0.68524134\n",
      "Epoch: [ 0] [ 277/1582] time: 362.7769, d_loss: 1.14143419, g_loss: 0.68467832\n",
      "Epoch: [ 0] [ 278/1582] time: 364.0168, d_loss: 1.15773392, g_loss: 0.68066919\n",
      "Epoch: [ 0] [ 279/1582] time: 365.2586, d_loss: 1.15527344, g_loss: 0.68654078\n",
      "Epoch: [ 0] [ 280/1582] time: 366.4984, d_loss: 1.15640914, g_loss: 0.68498647\n",
      "Epoch: [ 0] [ 281/1582] time: 367.7384, d_loss: 1.18237877, g_loss: 0.68113828\n",
      "Epoch: [ 0] [ 282/1582] time: 368.9769, d_loss: 1.17260480, g_loss: 0.68105876\n",
      "Epoch: [ 0] [ 283/1582] time: 370.2211, d_loss: 1.19019246, g_loss: 0.68135536\n",
      "Epoch: [ 0] [ 284/1582] time: 371.4565, d_loss: 1.14760780, g_loss: 0.67690337\n",
      "Epoch: [ 0] [ 285/1582] time: 372.6935, d_loss: 1.14220762, g_loss: 0.67766345\n",
      "Epoch: [ 0] [ 286/1582] time: 373.9294, d_loss: 1.15964174, g_loss: 0.67750978\n",
      "Epoch: [ 0] [ 287/1582] time: 375.1694, d_loss: 1.16895378, g_loss: 0.67317027\n",
      "Epoch: [ 0] [ 288/1582] time: 376.4093, d_loss: 1.18124628, g_loss: 0.67641842\n",
      "Epoch: [ 0] [ 289/1582] time: 377.6473, d_loss: 1.19428873, g_loss: 0.67461300\n",
      "Epoch: [ 0] [ 290/1582] time: 378.8833, d_loss: 1.16448176, g_loss: 0.67459595\n",
      "Epoch: [ 0] [ 291/1582] time: 380.1213, d_loss: 1.17997396, g_loss: 0.67293799\n",
      "Epoch: [ 0] [ 292/1582] time: 381.3593, d_loss: 1.16401315, g_loss: 0.67404270\n",
      "Epoch: [ 0] [ 293/1582] time: 382.5993, d_loss: 1.16371357, g_loss: 0.67700619\n",
      "Epoch: [ 0] [ 294/1582] time: 383.8381, d_loss: 1.16416609, g_loss: 0.67194659\n",
      "Epoch: [ 0] [ 295/1582] time: 385.0775, d_loss: 1.17871451, g_loss: 0.67049503\n",
      "Epoch: [ 0] [ 296/1582] time: 386.3151, d_loss: 1.19473219, g_loss: 0.67447680\n",
      "Epoch: [ 0] [ 297/1582] time: 387.5540, d_loss: 1.20826030, g_loss: 0.67357343\n",
      "Epoch: [ 0] [ 298/1582] time: 388.7950, d_loss: 1.18093550, g_loss: 0.67443824\n",
      "Epoch: [ 0] [ 299/1582] time: 390.0333, d_loss: 1.20792723, g_loss: 0.67451274\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 0] [ 300/1582] time: 398.0769, d_loss: 1.16584337, g_loss: 0.67820352\n",
      "Epoch: [ 0] [ 301/1582] time: 399.3229, d_loss: 1.19542098, g_loss: 0.67246938\n",
      "Epoch: [ 0] [ 302/1582] time: 400.5658, d_loss: 1.17033863, g_loss: 0.67230201\n",
      "Epoch: [ 0] [ 303/1582] time: 401.8048, d_loss: 1.21097744, g_loss: 0.67888188\n",
      "Epoch: [ 0] [ 304/1582] time: 403.0482, d_loss: 1.20397282, g_loss: 0.67450565\n",
      "Epoch: [ 0] [ 305/1582] time: 404.2871, d_loss: 1.20746684, g_loss: 0.67986697\n",
      "Epoch: [ 0] [ 306/1582] time: 405.5231, d_loss: 1.14697146, g_loss: 0.68043911\n",
      "Epoch: [ 0] [ 307/1582] time: 406.7630, d_loss: 1.20433855, g_loss: 0.68074262\n",
      "Epoch: [ 0] [ 308/1582] time: 408.0030, d_loss: 1.18923211, g_loss: 0.68170106\n",
      "Epoch: [ 0] [ 309/1582] time: 409.2460, d_loss: 1.19284248, g_loss: 0.68340963\n",
      "Epoch: [ 0] [ 310/1582] time: 410.4859, d_loss: 1.17164779, g_loss: 0.68698072\n",
      "Epoch: [ 0] [ 311/1582] time: 411.7273, d_loss: 1.18592072, g_loss: 0.68391430\n",
      "Epoch: [ 0] [ 312/1582] time: 412.9672, d_loss: 1.15385604, g_loss: 0.68593067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [ 313/1582] time: 414.2115, d_loss: 1.16962898, g_loss: 0.68647897\n",
      "Epoch: [ 0] [ 314/1582] time: 415.4505, d_loss: 1.17716646, g_loss: 0.68762982\n",
      "Epoch: [ 0] [ 315/1582] time: 416.6896, d_loss: 1.18406296, g_loss: 0.68686986\n",
      "Epoch: [ 0] [ 316/1582] time: 417.9306, d_loss: 1.18184662, g_loss: 0.68964267\n",
      "Epoch: [ 0] [ 317/1582] time: 419.1725, d_loss: 1.19265473, g_loss: 0.69316924\n",
      "Epoch: [ 0] [ 318/1582] time: 420.4135, d_loss: 1.20084918, g_loss: 0.69109935\n",
      "Epoch: [ 0] [ 319/1582] time: 421.6534, d_loss: 1.17292380, g_loss: 0.69171715\n",
      "Epoch: [ 0] [ 320/1582] time: 422.8914, d_loss: 1.17195320, g_loss: 0.68803155\n",
      "Epoch: [ 0] [ 321/1582] time: 424.1333, d_loss: 1.15764940, g_loss: 0.69213128\n",
      "Epoch: [ 0] [ 322/1582] time: 425.3713, d_loss: 1.16969275, g_loss: 0.69311112\n",
      "Epoch: [ 0] [ 323/1582] time: 426.6092, d_loss: 1.18747997, g_loss: 0.69001859\n",
      "Epoch: [ 0] [ 324/1582] time: 427.8512, d_loss: 1.16290474, g_loss: 0.69105291\n",
      "Epoch: [ 0] [ 325/1582] time: 429.0912, d_loss: 1.14428031, g_loss: 0.69187772\n",
      "Epoch: [ 0] [ 326/1582] time: 430.3312, d_loss: 1.16805506, g_loss: 0.69070846\n",
      "Epoch: [ 0] [ 327/1582] time: 431.5708, d_loss: 1.15619814, g_loss: 0.69157177\n",
      "Epoch: [ 0] [ 328/1582] time: 432.8094, d_loss: 1.16712022, g_loss: 0.68714619\n",
      "Epoch: [ 0] [ 329/1582] time: 434.0513, d_loss: 1.18442404, g_loss: 0.69054043\n",
      "Epoch: [ 0] [ 330/1582] time: 435.2923, d_loss: 1.16260922, g_loss: 0.68330604\n",
      "Epoch: [ 0] [ 331/1582] time: 436.5315, d_loss: 1.15306985, g_loss: 0.68695545\n",
      "Epoch: [ 0] [ 332/1582] time: 437.7721, d_loss: 1.14585829, g_loss: 0.68584335\n",
      "Epoch: [ 0] [ 333/1582] time: 439.0140, d_loss: 1.15303588, g_loss: 0.68546426\n",
      "Epoch: [ 0] [ 334/1582] time: 440.2523, d_loss: 1.17143416, g_loss: 0.68057108\n",
      "Epoch: [ 0] [ 335/1582] time: 441.4931, d_loss: 1.14871979, g_loss: 0.68243986\n",
      "Epoch: [ 0] [ 336/1582] time: 442.7300, d_loss: 1.18340755, g_loss: 0.68210918\n",
      "Epoch: [ 0] [ 337/1582] time: 443.9694, d_loss: 1.18233824, g_loss: 0.68115574\n",
      "Epoch: [ 0] [ 338/1582] time: 445.2093, d_loss: 1.18763304, g_loss: 0.67956305\n",
      "Epoch: [ 0] [ 339/1582] time: 446.4513, d_loss: 1.15518451, g_loss: 0.68057501\n",
      "Epoch: [ 0] [ 340/1582] time: 447.6883, d_loss: 1.18200624, g_loss: 0.67884302\n",
      "Epoch: [ 0] [ 341/1582] time: 448.9272, d_loss: 1.15843606, g_loss: 0.67122293\n",
      "Epoch: [ 0] [ 342/1582] time: 450.1682, d_loss: 1.19870591, g_loss: 0.67166841\n",
      "Epoch: [ 0] [ 343/1582] time: 451.4071, d_loss: 1.19634938, g_loss: 0.67289120\n",
      "Epoch: [ 0] [ 344/1582] time: 452.6431, d_loss: 1.19160771, g_loss: 0.66633499\n",
      "Epoch: [ 0] [ 345/1582] time: 453.8811, d_loss: 1.17447519, g_loss: 0.67096496\n",
      "Epoch: [ 0] [ 346/1582] time: 455.1210, d_loss: 1.17239892, g_loss: 0.66879106\n",
      "Epoch: [ 0] [ 347/1582] time: 456.3619, d_loss: 1.18389606, g_loss: 0.66528207\n",
      "Epoch: [ 0] [ 348/1582] time: 457.6028, d_loss: 1.17830968, g_loss: 0.66580725\n",
      "Epoch: [ 0] [ 349/1582] time: 458.8418, d_loss: 1.16982269, g_loss: 0.66708273\n",
      "Epoch: [ 0] [ 350/1582] time: 460.0848, d_loss: 1.15858376, g_loss: 0.66449624\n",
      "Epoch: [ 0] [ 351/1582] time: 461.3265, d_loss: 1.19120514, g_loss: 0.66689062\n",
      "Epoch: [ 0] [ 352/1582] time: 462.5690, d_loss: 1.13679910, g_loss: 0.66796851\n",
      "Epoch: [ 0] [ 353/1582] time: 463.8209, d_loss: 1.14945054, g_loss: 0.66543210\n",
      "Epoch: [ 0] [ 354/1582] time: 465.0739, d_loss: 1.20997858, g_loss: 0.66487992\n",
      "Epoch: [ 0] [ 355/1582] time: 466.3144, d_loss: 1.14483809, g_loss: 0.66234815\n",
      "Epoch: [ 0] [ 356/1582] time: 467.5553, d_loss: 1.15847504, g_loss: 0.66799706\n",
      "Epoch: [ 0] [ 357/1582] time: 468.7934, d_loss: 1.17272091, g_loss: 0.66950375\n",
      "Epoch: [ 0] [ 358/1582] time: 470.0324, d_loss: 1.16194701, g_loss: 0.67231315\n",
      "Epoch: [ 0] [ 359/1582] time: 471.2708, d_loss: 1.16798270, g_loss: 0.66783464\n",
      "Epoch: [ 0] [ 360/1582] time: 472.5088, d_loss: 1.14126945, g_loss: 0.66995430\n",
      "Epoch: [ 0] [ 361/1582] time: 473.7507, d_loss: 1.15269423, g_loss: 0.67080164\n",
      "Epoch: [ 0] [ 362/1582] time: 474.9897, d_loss: 1.14732981, g_loss: 0.67443770\n",
      "Epoch: [ 0] [ 363/1582] time: 476.2306, d_loss: 1.15556371, g_loss: 0.67714393\n",
      "Epoch: [ 0] [ 364/1582] time: 477.4706, d_loss: 1.15700316, g_loss: 0.67723465\n",
      "Epoch: [ 0] [ 365/1582] time: 478.7075, d_loss: 1.15801430, g_loss: 0.67304170\n",
      "Epoch: [ 0] [ 366/1582] time: 479.9455, d_loss: 1.17624891, g_loss: 0.67771292\n",
      "Epoch: [ 0] [ 367/1582] time: 481.1865, d_loss: 1.16404581, g_loss: 0.67966199\n",
      "Epoch: [ 0] [ 368/1582] time: 482.4264, d_loss: 1.14226961, g_loss: 0.68604314\n",
      "Epoch: [ 0] [ 369/1582] time: 483.6694, d_loss: 1.16296554, g_loss: 0.68479824\n",
      "Epoch: [ 0] [ 370/1582] time: 484.9133, d_loss: 1.14280438, g_loss: 0.68145192\n",
      "Epoch: [ 0] [ 371/1582] time: 486.1533, d_loss: 1.14493454, g_loss: 0.68139601\n",
      "Epoch: [ 0] [ 372/1582] time: 487.3942, d_loss: 1.14774883, g_loss: 0.68405932\n",
      "Epoch: [ 0] [ 373/1582] time: 488.6332, d_loss: 1.14290905, g_loss: 0.68410891\n",
      "Epoch: [ 0] [ 374/1582] time: 489.8771, d_loss: 1.14410830, g_loss: 0.68419313\n",
      "Epoch: [ 0] [ 375/1582] time: 491.1204, d_loss: 1.16562939, g_loss: 0.68770969\n",
      "Epoch: [ 0] [ 376/1582] time: 492.3637, d_loss: 1.17613482, g_loss: 0.68353820\n",
      "Epoch: [ 0] [ 377/1582] time: 493.6032, d_loss: 1.16296053, g_loss: 0.68346012\n",
      "Epoch: [ 0] [ 378/1582] time: 494.8445, d_loss: 1.17009032, g_loss: 0.68487972\n",
      "Epoch: [ 0] [ 379/1582] time: 496.0835, d_loss: 1.13733101, g_loss: 0.68508160\n",
      "Epoch: [ 0] [ 380/1582] time: 497.3224, d_loss: 1.14510465, g_loss: 0.68229568\n",
      "Epoch: [ 0] [ 381/1582] time: 498.5584, d_loss: 1.15430737, g_loss: 0.68283010\n",
      "Epoch: [ 0] [ 382/1582] time: 499.7953, d_loss: 1.17378092, g_loss: 0.67735285\n",
      "Epoch: [ 0] [ 383/1582] time: 501.0333, d_loss: 1.15201879, g_loss: 0.68084824\n",
      "Epoch: [ 0] [ 384/1582] time: 502.2762, d_loss: 1.13758516, g_loss: 0.67908049\n",
      "Epoch: [ 0] [ 385/1582] time: 503.5132, d_loss: 1.14678228, g_loss: 0.67727607\n",
      "Epoch: [ 0] [ 386/1582] time: 504.7532, d_loss: 1.12758350, g_loss: 0.67341810\n",
      "Epoch: [ 0] [ 387/1582] time: 505.9921, d_loss: 1.14548516, g_loss: 0.67383778\n",
      "Epoch: [ 0] [ 388/1582] time: 507.2301, d_loss: 1.14538872, g_loss: 0.66650271\n",
      "Epoch: [ 0] [ 389/1582] time: 508.4710, d_loss: 1.15477455, g_loss: 0.66612619\n",
      "Epoch: [ 0] [ 390/1582] time: 509.7117, d_loss: 1.16098714, g_loss: 0.66741717\n",
      "Epoch: [ 0] [ 391/1582] time: 510.9527, d_loss: 1.19370413, g_loss: 0.66577238\n",
      "Epoch: [ 0] [ 392/1582] time: 512.1931, d_loss: 1.19241500, g_loss: 0.66290325\n",
      "Epoch: [ 0] [ 393/1582] time: 513.4331, d_loss: 1.19866872, g_loss: 0.66290951\n",
      "Epoch: [ 0] [ 394/1582] time: 514.6720, d_loss: 1.18167734, g_loss: 0.65777516\n",
      "Epoch: [ 0] [ 395/1582] time: 515.9120, d_loss: 1.20211339, g_loss: 0.65957421\n",
      "Epoch: [ 0] [ 396/1582] time: 517.1510, d_loss: 1.18941176, g_loss: 0.65589863\n",
      "Epoch: [ 0] [ 397/1582] time: 518.3929, d_loss: 1.15976834, g_loss: 0.65628612\n",
      "Epoch: [ 0] [ 398/1582] time: 519.6339, d_loss: 1.16323936, g_loss: 0.66146076\n",
      "Epoch: [ 0] [ 399/1582] time: 520.8728, d_loss: 1.17750025, g_loss: 0.66169387\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 0] [ 400/1582] time: 528.6996, d_loss: 1.18043947, g_loss: 0.66073757\n",
      "Epoch: [ 0] [ 401/1582] time: 529.9396, d_loss: 1.17099738, g_loss: 0.66339952\n",
      "Epoch: [ 0] [ 402/1582] time: 531.1825, d_loss: 1.20368886, g_loss: 0.66656321\n",
      "Epoch: [ 0] [ 403/1582] time: 532.4235, d_loss: 1.19456530, g_loss: 0.66636378\n",
      "Epoch: [ 0] [ 404/1582] time: 533.6644, d_loss: 1.19210243, g_loss: 0.67036843\n",
      "Epoch: [ 0] [ 405/1582] time: 534.9085, d_loss: 1.22171271, g_loss: 0.67148954\n",
      "Epoch: [ 0] [ 406/1582] time: 536.1505, d_loss: 1.21308231, g_loss: 0.68266845\n",
      "Epoch: [ 0] [ 407/1582] time: 537.3904, d_loss: 1.22011173, g_loss: 0.68423623\n",
      "Epoch: [ 0] [ 408/1582] time: 538.6323, d_loss: 1.17469215, g_loss: 0.68485725\n",
      "Epoch: [ 0] [ 409/1582] time: 539.8763, d_loss: 1.20180345, g_loss: 0.68913573\n",
      "Epoch: [ 0] [ 410/1582] time: 541.1194, d_loss: 1.20834422, g_loss: 0.69466364\n",
      "Epoch: [ 0] [ 411/1582] time: 542.3653, d_loss: 1.20111430, g_loss: 0.69577146\n",
      "Epoch: [ 0] [ 412/1582] time: 543.6153, d_loss: 1.19784367, g_loss: 0.70225096\n",
      "Epoch: [ 0] [ 413/1582] time: 544.8612, d_loss: 1.17188644, g_loss: 0.70289654\n",
      "Epoch: [ 0] [ 414/1582] time: 546.1072, d_loss: 1.18796754, g_loss: 0.70706427\n",
      "Epoch: [ 0] [ 415/1582] time: 547.3534, d_loss: 1.16936529, g_loss: 0.70730007\n",
      "Epoch: [ 0] [ 416/1582] time: 548.5994, d_loss: 1.15933895, g_loss: 0.71727604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [ 417/1582] time: 549.8463, d_loss: 1.15876818, g_loss: 0.72207701\n",
      "Epoch: [ 0] [ 418/1582] time: 551.0923, d_loss: 1.13278675, g_loss: 0.71913660\n",
      "Epoch: [ 0] [ 419/1582] time: 552.3343, d_loss: 1.13455820, g_loss: 0.72510189\n",
      "Epoch: [ 0] [ 420/1582] time: 553.5762, d_loss: 1.15108991, g_loss: 0.72917193\n",
      "Epoch: [ 0] [ 421/1582] time: 554.8201, d_loss: 1.17113924, g_loss: 0.73256224\n",
      "Epoch: [ 0] [ 422/1582] time: 556.0611, d_loss: 1.15244293, g_loss: 0.73239183\n",
      "Epoch: [ 0] [ 423/1582] time: 557.3051, d_loss: 1.11824298, g_loss: 0.73457313\n",
      "Epoch: [ 0] [ 424/1582] time: 558.5470, d_loss: 1.17888379, g_loss: 0.73269540\n",
      "Epoch: [ 0] [ 425/1582] time: 559.7895, d_loss: 1.16652548, g_loss: 0.73746675\n",
      "Epoch: [ 0] [ 426/1582] time: 561.0314, d_loss: 1.18069220, g_loss: 0.73090023\n",
      "Epoch: [ 0] [ 427/1582] time: 562.2724, d_loss: 1.15992546, g_loss: 0.73405999\n",
      "Epoch: [ 0] [ 428/1582] time: 563.5143, d_loss: 1.15455842, g_loss: 0.73208594\n",
      "Epoch: [ 0] [ 429/1582] time: 564.7573, d_loss: 1.16448951, g_loss: 0.73103768\n",
      "Epoch: [ 0] [ 430/1582] time: 565.9958, d_loss: 1.16207385, g_loss: 0.72108877\n",
      "Epoch: [ 0] [ 431/1582] time: 567.2379, d_loss: 1.15669286, g_loss: 0.72334164\n",
      "Epoch: [ 0] [ 432/1582] time: 568.4809, d_loss: 1.15735602, g_loss: 0.71612597\n",
      "Epoch: [ 0] [ 433/1582] time: 569.7209, d_loss: 1.16251135, g_loss: 0.71226078\n",
      "Epoch: [ 0] [ 434/1582] time: 570.9638, d_loss: 1.17071939, g_loss: 0.71005672\n",
      "Epoch: [ 0] [ 435/1582] time: 572.2065, d_loss: 1.15961409, g_loss: 0.70370805\n",
      "Epoch: [ 0] [ 436/1582] time: 573.4495, d_loss: 1.15694678, g_loss: 0.69585139\n",
      "Epoch: [ 0] [ 437/1582] time: 574.6890, d_loss: 1.15736222, g_loss: 0.69360751\n",
      "Epoch: [ 0] [ 438/1582] time: 575.9259, d_loss: 1.17803931, g_loss: 0.68907833\n",
      "Epoch: [ 0] [ 439/1582] time: 577.1639, d_loss: 1.14794743, g_loss: 0.68075240\n",
      "Epoch: [ 0] [ 440/1582] time: 578.4040, d_loss: 1.18195128, g_loss: 0.67358565\n",
      "Epoch: [ 0] [ 441/1582] time: 579.6459, d_loss: 1.17738438, g_loss: 0.67104906\n",
      "Epoch: [ 0] [ 442/1582] time: 580.8899, d_loss: 1.18883073, g_loss: 0.66284198\n",
      "Epoch: [ 0] [ 443/1582] time: 582.1319, d_loss: 1.19372678, g_loss: 0.66205263\n",
      "Epoch: [ 0] [ 444/1582] time: 583.3858, d_loss: 1.18575823, g_loss: 0.65788472\n",
      "Epoch: [ 0] [ 445/1582] time: 584.6318, d_loss: 1.16992056, g_loss: 0.65172529\n",
      "Epoch: [ 0] [ 446/1582] time: 585.8808, d_loss: 1.16698122, g_loss: 0.64689004\n",
      "Epoch: [ 0] [ 447/1582] time: 587.1253, d_loss: 1.18828034, g_loss: 0.64315212\n",
      "Epoch: [ 0] [ 448/1582] time: 588.3647, d_loss: 1.21526515, g_loss: 0.64685512\n",
      "Epoch: [ 0] [ 449/1582] time: 589.6068, d_loss: 1.22421098, g_loss: 0.64708000\n",
      "Epoch: [ 0] [ 450/1582] time: 590.8468, d_loss: 1.21735382, g_loss: 0.64629441\n",
      "Epoch: [ 0] [ 451/1582] time: 592.0897, d_loss: 1.18094182, g_loss: 0.64258289\n",
      "Epoch: [ 0] [ 452/1582] time: 593.3303, d_loss: 1.17468405, g_loss: 0.64287913\n",
      "Epoch: [ 0] [ 453/1582] time: 594.5692, d_loss: 1.21076512, g_loss: 0.64114761\n",
      "Epoch: [ 0] [ 454/1582] time: 595.8112, d_loss: 1.19413829, g_loss: 0.64510667\n",
      "Epoch: [ 0] [ 455/1582] time: 597.0543, d_loss: 1.19553900, g_loss: 0.64945006\n",
      "Epoch: [ 0] [ 456/1582] time: 598.2932, d_loss: 1.17667997, g_loss: 0.64835662\n",
      "Epoch: [ 0] [ 457/1582] time: 599.5322, d_loss: 1.16517258, g_loss: 0.65145695\n",
      "Epoch: [ 0] [ 458/1582] time: 600.7721, d_loss: 1.17618728, g_loss: 0.65339732\n",
      "Epoch: [ 0] [ 459/1582] time: 602.0131, d_loss: 1.18452477, g_loss: 0.65842152\n",
      "Epoch: [ 0] [ 460/1582] time: 603.2576, d_loss: 1.20226145, g_loss: 0.66028440\n",
      "Epoch: [ 0] [ 461/1582] time: 604.4984, d_loss: 1.21503532, g_loss: 0.66278005\n",
      "Epoch: [ 0] [ 462/1582] time: 605.7404, d_loss: 1.19355297, g_loss: 0.66190875\n",
      "Epoch: [ 0] [ 463/1582] time: 606.9828, d_loss: 1.15160441, g_loss: 0.66803229\n",
      "Epoch: [ 0] [ 464/1582] time: 608.2238, d_loss: 1.16192460, g_loss: 0.67337370\n",
      "Epoch: [ 0] [ 465/1582] time: 609.4637, d_loss: 1.15267658, g_loss: 0.67147565\n",
      "Epoch: [ 0] [ 466/1582] time: 610.7077, d_loss: 1.17266798, g_loss: 0.67553103\n",
      "Epoch: [ 0] [ 467/1582] time: 611.9477, d_loss: 1.17124963, g_loss: 0.67927241\n",
      "Epoch: [ 0] [ 468/1582] time: 613.1946, d_loss: 1.13531971, g_loss: 0.68395287\n",
      "Epoch: [ 0] [ 469/1582] time: 614.4396, d_loss: 1.17992365, g_loss: 0.68187881\n",
      "Epoch: [ 0] [ 470/1582] time: 615.6830, d_loss: 1.15392685, g_loss: 0.68832946\n",
      "Epoch: [ 0] [ 471/1582] time: 616.9250, d_loss: 1.15846241, g_loss: 0.68951511\n",
      "Epoch: [ 0] [ 472/1582] time: 618.1690, d_loss: 1.18538690, g_loss: 0.69250864\n",
      "Epoch: [ 0] [ 473/1582] time: 619.4124, d_loss: 1.13700092, g_loss: 0.69654334\n",
      "Epoch: [ 0] [ 474/1582] time: 620.6524, d_loss: 1.12419367, g_loss: 0.69685781\n",
      "Epoch: [ 0] [ 475/1582] time: 621.8943, d_loss: 1.18699360, g_loss: 0.69687438\n",
      "Epoch: [ 0] [ 476/1582] time: 623.1368, d_loss: 1.16484666, g_loss: 0.70107424\n",
      "Epoch: [ 0] [ 477/1582] time: 624.3797, d_loss: 1.17667007, g_loss: 0.70009011\n",
      "Epoch: [ 0] [ 478/1582] time: 625.6206, d_loss: 1.16730189, g_loss: 0.70138049\n",
      "Epoch: [ 0] [ 479/1582] time: 626.8606, d_loss: 1.11678016, g_loss: 0.70157313\n",
      "Epoch: [ 0] [ 480/1582] time: 628.1016, d_loss: 1.11288404, g_loss: 0.69822013\n",
      "Epoch: [ 0] [ 481/1582] time: 629.3425, d_loss: 1.19158459, g_loss: 0.69915676\n",
      "Epoch: [ 0] [ 482/1582] time: 630.5845, d_loss: 1.11807132, g_loss: 0.70013613\n",
      "Epoch: [ 0] [ 483/1582] time: 631.8244, d_loss: 1.14565706, g_loss: 0.70080769\n",
      "Epoch: [ 0] [ 484/1582] time: 633.0664, d_loss: 1.15162468, g_loss: 0.70023733\n",
      "Epoch: [ 0] [ 485/1582] time: 634.3103, d_loss: 1.15812922, g_loss: 0.69814110\n",
      "Epoch: [ 0] [ 486/1582] time: 635.5513, d_loss: 1.10243344, g_loss: 0.69836324\n",
      "Epoch: [ 0] [ 487/1582] time: 636.7933, d_loss: 1.14129639, g_loss: 0.69698602\n",
      "Epoch: [ 0] [ 488/1582] time: 638.0357, d_loss: 1.16747379, g_loss: 0.69375867\n",
      "Epoch: [ 0] [ 489/1582] time: 639.2766, d_loss: 1.17015767, g_loss: 0.68593252\n",
      "Epoch: [ 0] [ 490/1582] time: 640.5186, d_loss: 1.13586164, g_loss: 0.69000226\n",
      "Epoch: [ 0] [ 491/1582] time: 641.7576, d_loss: 1.16020501, g_loss: 0.68222439\n",
      "Epoch: [ 0] [ 492/1582] time: 642.9985, d_loss: 1.18177414, g_loss: 0.67723739\n",
      "Epoch: [ 0] [ 493/1582] time: 644.2400, d_loss: 1.15977848, g_loss: 0.67399460\n",
      "Epoch: [ 0] [ 494/1582] time: 645.4830, d_loss: 1.19262719, g_loss: 0.66967404\n",
      "Epoch: [ 0] [ 495/1582] time: 646.7239, d_loss: 1.14708972, g_loss: 0.66670656\n",
      "Epoch: [ 0] [ 496/1582] time: 647.9627, d_loss: 1.19224107, g_loss: 0.66349298\n",
      "Epoch: [ 0] [ 497/1582] time: 649.2036, d_loss: 1.14412391, g_loss: 0.66342163\n",
      "Epoch: [ 0] [ 498/1582] time: 650.4426, d_loss: 1.17151904, g_loss: 0.66300416\n",
      "Epoch: [ 0] [ 499/1582] time: 651.6837, d_loss: 1.19556522, g_loss: 0.65671295\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 0] [ 500/1582] time: 659.6050, d_loss: 1.21279693, g_loss: 0.65675223\n",
      "Epoch: [ 0] [ 501/1582] time: 660.8449, d_loss: 1.19013381, g_loss: 0.65632433\n",
      "Epoch: [ 0] [ 502/1582] time: 662.0869, d_loss: 1.21151710, g_loss: 0.65552950\n",
      "Epoch: [ 0] [ 503/1582] time: 663.3312, d_loss: 1.20641887, g_loss: 0.65333885\n",
      "Epoch: [ 0] [ 504/1582] time: 664.5742, d_loss: 1.17866087, g_loss: 0.65600026\n",
      "Epoch: [ 0] [ 505/1582] time: 665.8141, d_loss: 1.20898795, g_loss: 0.65954238\n",
      "Epoch: [ 0] [ 506/1582] time: 667.0571, d_loss: 1.24613547, g_loss: 0.66321164\n",
      "Epoch: [ 0] [ 507/1582] time: 668.3030, d_loss: 1.17149639, g_loss: 0.66449869\n",
      "Epoch: [ 0] [ 508/1582] time: 669.5480, d_loss: 1.20377326, g_loss: 0.66905427\n",
      "Epoch: [ 0] [ 509/1582] time: 670.7920, d_loss: 1.21817255, g_loss: 0.67211258\n",
      "Epoch: [ 0] [ 510/1582] time: 672.0369, d_loss: 1.20177794, g_loss: 0.67386317\n",
      "Epoch: [ 0] [ 511/1582] time: 673.2799, d_loss: 1.19930744, g_loss: 0.67988223\n",
      "Epoch: [ 0] [ 512/1582] time: 674.5248, d_loss: 1.18416357, g_loss: 0.68333995\n",
      "Epoch: [ 0] [ 513/1582] time: 675.7698, d_loss: 1.19559765, g_loss: 0.68469977\n",
      "Epoch: [ 0] [ 514/1582] time: 677.0118, d_loss: 1.19919157, g_loss: 0.68668461\n",
      "Epoch: [ 0] [ 515/1582] time: 678.2541, d_loss: 1.22437954, g_loss: 0.69411707\n",
      "Epoch: [ 0] [ 516/1582] time: 679.4971, d_loss: 1.20323205, g_loss: 0.69607967\n",
      "Epoch: [ 0] [ 517/1582] time: 680.7382, d_loss: 1.13289559, g_loss: 0.70222163\n",
      "Epoch: [ 0] [ 518/1582] time: 681.9788, d_loss: 1.18885088, g_loss: 0.70626599\n",
      "Epoch: [ 0] [ 519/1582] time: 683.2208, d_loss: 1.18325400, g_loss: 0.70821011\n",
      "Epoch: [ 0] [ 520/1582] time: 684.4647, d_loss: 1.15843511, g_loss: 0.71522552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [ 521/1582] time: 685.7057, d_loss: 1.18248010, g_loss: 0.71427149\n",
      "Epoch: [ 0] [ 522/1582] time: 686.9466, d_loss: 1.15630269, g_loss: 0.71567953\n",
      "Epoch: [ 0] [ 523/1582] time: 688.1886, d_loss: 1.17857552, g_loss: 0.72160941\n",
      "Epoch: [ 0] [ 524/1582] time: 689.4315, d_loss: 1.18265200, g_loss: 0.72718877\n",
      "Epoch: [ 0] [ 525/1582] time: 690.6775, d_loss: 1.14309955, g_loss: 0.73077095\n",
      "Epoch: [ 0] [ 526/1582] time: 691.9202, d_loss: 1.16378307, g_loss: 0.73178470\n",
      "Epoch: [ 0] [ 527/1582] time: 693.1644, d_loss: 1.17593813, g_loss: 0.73690110\n",
      "Epoch: [ 0] [ 528/1582] time: 694.4063, d_loss: 1.15751767, g_loss: 0.73602206\n",
      "Epoch: [ 0] [ 529/1582] time: 695.6503, d_loss: 1.15647388, g_loss: 0.73616344\n",
      "Epoch: [ 0] [ 530/1582] time: 696.8943, d_loss: 1.15356278, g_loss: 0.73769283\n",
      "Epoch: [ 0] [ 531/1582] time: 698.1392, d_loss: 1.13941097, g_loss: 0.73929632\n",
      "Epoch: [ 0] [ 532/1582] time: 699.3812, d_loss: 1.15341079, g_loss: 0.73690200\n",
      "Epoch: [ 0] [ 533/1582] time: 700.6269, d_loss: 1.19153714, g_loss: 0.74201268\n",
      "Epoch: [ 0] [ 534/1582] time: 701.8729, d_loss: 1.13734102, g_loss: 0.73916507\n",
      "Epoch: [ 0] [ 535/1582] time: 703.1308, d_loss: 1.18392181, g_loss: 0.73535717\n",
      "Epoch: [ 0] [ 536/1582] time: 704.3798, d_loss: 1.15481246, g_loss: 0.73353750\n",
      "Epoch: [ 0] [ 537/1582] time: 705.6297, d_loss: 1.12301528, g_loss: 0.73186076\n",
      "Epoch: [ 0] [ 538/1582] time: 706.8757, d_loss: 1.16246033, g_loss: 0.72642922\n",
      "Epoch: [ 0] [ 539/1582] time: 708.1223, d_loss: 1.14969146, g_loss: 0.72304201\n",
      "Epoch: [ 0] [ 540/1582] time: 709.3653, d_loss: 1.16022170, g_loss: 0.71349365\n",
      "Epoch: [ 0] [ 541/1582] time: 710.6073, d_loss: 1.15025115, g_loss: 0.71181381\n",
      "Epoch: [ 0] [ 542/1582] time: 711.8500, d_loss: 1.16768479, g_loss: 0.70321071\n",
      "Epoch: [ 0] [ 543/1582] time: 713.0939, d_loss: 1.17314148, g_loss: 0.69877839\n",
      "Epoch: [ 0] [ 544/1582] time: 714.3348, d_loss: 1.14708090, g_loss: 0.69172066\n",
      "Epoch: [ 0] [ 545/1582] time: 715.5788, d_loss: 1.17135990, g_loss: 0.68674862\n",
      "Epoch: [ 0] [ 546/1582] time: 716.8228, d_loss: 1.13990974, g_loss: 0.68058312\n",
      "Epoch: [ 0] [ 547/1582] time: 718.0677, d_loss: 1.15968204, g_loss: 0.67340374\n",
      "Epoch: [ 0] [ 548/1582] time: 719.3101, d_loss: 1.17822838, g_loss: 0.66892481\n",
      "Epoch: [ 0] [ 549/1582] time: 720.5531, d_loss: 1.16687191, g_loss: 0.66684979\n",
      "Epoch: [ 0] [ 550/1582] time: 721.7950, d_loss: 1.18861675, g_loss: 0.65816647\n",
      "Epoch: [ 0] [ 551/1582] time: 723.0400, d_loss: 1.19788420, g_loss: 0.65694892\n",
      "Epoch: [ 0] [ 552/1582] time: 724.2822, d_loss: 1.22009325, g_loss: 0.65481460\n",
      "Epoch: [ 0] [ 553/1582] time: 725.5251, d_loss: 1.18062401, g_loss: 0.65060413\n",
      "Epoch: [ 0] [ 554/1582] time: 726.7691, d_loss: 1.16761100, g_loss: 0.65047014\n",
      "Epoch: [ 0] [ 555/1582] time: 728.0150, d_loss: 1.21849751, g_loss: 0.64840376\n",
      "Epoch: [ 0] [ 556/1582] time: 729.2601, d_loss: 1.16598058, g_loss: 0.64675725\n",
      "Epoch: [ 0] [ 557/1582] time: 730.5061, d_loss: 1.20324934, g_loss: 0.64815509\n",
      "Epoch: [ 0] [ 558/1582] time: 731.7492, d_loss: 1.17590177, g_loss: 0.64849627\n",
      "Epoch: [ 0] [ 559/1582] time: 732.9889, d_loss: 1.19990027, g_loss: 0.64709866\n",
      "Epoch: [ 0] [ 560/1582] time: 734.2341, d_loss: 1.22641349, g_loss: 0.64968759\n",
      "Epoch: [ 0] [ 561/1582] time: 735.4801, d_loss: 1.22188139, g_loss: 0.65363276\n",
      "Epoch: [ 0] [ 562/1582] time: 736.7226, d_loss: 1.19623399, g_loss: 0.65397978\n",
      "Epoch: [ 0] [ 563/1582] time: 737.9695, d_loss: 1.18318033, g_loss: 0.65417588\n",
      "Epoch: [ 0] [ 564/1582] time: 739.2175, d_loss: 1.21943164, g_loss: 0.65423155\n",
      "Epoch: [ 0] [ 565/1582] time: 740.4624, d_loss: 1.20429397, g_loss: 0.65307534\n",
      "Epoch: [ 0] [ 566/1582] time: 741.7082, d_loss: 1.17241955, g_loss: 0.65675867\n",
      "Epoch: [ 0] [ 567/1582] time: 742.9548, d_loss: 1.17616224, g_loss: 0.66068721\n",
      "Epoch: [ 0] [ 568/1582] time: 744.1977, d_loss: 1.20107484, g_loss: 0.66412830\n",
      "Epoch: [ 0] [ 569/1582] time: 745.4417, d_loss: 1.20869029, g_loss: 0.66584408\n",
      "Epoch: [ 0] [ 570/1582] time: 746.6856, d_loss: 1.19547129, g_loss: 0.66585368\n",
      "Epoch: [ 0] [ 571/1582] time: 747.9356, d_loss: 1.17855239, g_loss: 0.67054397\n",
      "Epoch: [ 0] [ 572/1582] time: 749.1825, d_loss: 1.16649497, g_loss: 0.67140758\n",
      "Epoch: [ 0] [ 573/1582] time: 750.4255, d_loss: 1.19538414, g_loss: 0.67516142\n",
      "Epoch: [ 0] [ 574/1582] time: 751.6704, d_loss: 1.14014363, g_loss: 0.67779815\n",
      "Epoch: [ 0] [ 575/1582] time: 752.9154, d_loss: 1.19950366, g_loss: 0.67840892\n",
      "Epoch: [ 0] [ 576/1582] time: 754.1604, d_loss: 1.21393812, g_loss: 0.67863107\n",
      "Epoch: [ 0] [ 577/1582] time: 755.4052, d_loss: 1.15602946, g_loss: 0.68166053\n",
      "Epoch: [ 0] [ 578/1582] time: 756.6452, d_loss: 1.17156065, g_loss: 0.68192166\n",
      "Epoch: [ 0] [ 579/1582] time: 757.8886, d_loss: 1.18328691, g_loss: 0.68252778\n",
      "Epoch: [ 0] [ 580/1582] time: 759.1335, d_loss: 1.16857135, g_loss: 0.68758380\n",
      "Epoch: [ 0] [ 581/1582] time: 760.3755, d_loss: 1.17960811, g_loss: 0.69043410\n",
      "Epoch: [ 0] [ 582/1582] time: 761.6204, d_loss: 1.16912818, g_loss: 0.69006824\n",
      "Epoch: [ 0] [ 583/1582] time: 762.8634, d_loss: 1.18264484, g_loss: 0.68929887\n",
      "Epoch: [ 0] [ 584/1582] time: 764.1064, d_loss: 1.16353011, g_loss: 0.69014037\n",
      "Epoch: [ 0] [ 585/1582] time: 765.3503, d_loss: 1.14872956, g_loss: 0.69327796\n",
      "Epoch: [ 0] [ 586/1582] time: 766.5933, d_loss: 1.13862729, g_loss: 0.69217771\n",
      "Epoch: [ 0] [ 587/1582] time: 767.8371, d_loss: 1.17137456, g_loss: 0.69152361\n",
      "Epoch: [ 0] [ 588/1582] time: 769.0801, d_loss: 1.13230550, g_loss: 0.69690508\n",
      "Epoch: [ 0] [ 589/1582] time: 770.3219, d_loss: 1.12720895, g_loss: 0.69396734\n",
      "Epoch: [ 0] [ 590/1582] time: 771.5669, d_loss: 1.16496372, g_loss: 0.69620621\n",
      "Epoch: [ 0] [ 591/1582] time: 772.8099, d_loss: 1.13304448, g_loss: 0.69067931\n",
      "Epoch: [ 0] [ 592/1582] time: 774.0558, d_loss: 1.14581299, g_loss: 0.69359553\n",
      "Epoch: [ 0] [ 593/1582] time: 775.2998, d_loss: 1.12209034, g_loss: 0.69599664\n",
      "Epoch: [ 0] [ 594/1582] time: 776.5426, d_loss: 1.15390611, g_loss: 0.69339311\n",
      "Epoch: [ 0] [ 595/1582] time: 777.7867, d_loss: 1.13408089, g_loss: 0.69455528\n",
      "Epoch: [ 0] [ 596/1582] time: 779.0317, d_loss: 1.15157485, g_loss: 0.68910742\n",
      "Epoch: [ 0] [ 597/1582] time: 780.2751, d_loss: 1.14632607, g_loss: 0.69108641\n",
      "Epoch: [ 0] [ 598/1582] time: 781.5180, d_loss: 1.15683126, g_loss: 0.69206262\n",
      "Epoch: [ 0] [ 599/1582] time: 782.7590, d_loss: 1.17390823, g_loss: 0.68993342\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 0] [ 600/1582] time: 790.5445, d_loss: 1.14310050, g_loss: 0.68707067\n",
      "Epoch: [ 0] [ 601/1582] time: 791.7870, d_loss: 1.20482779, g_loss: 0.68348926\n",
      "Epoch: [ 0] [ 602/1582] time: 793.0299, d_loss: 1.17268980, g_loss: 0.68369472\n",
      "Epoch: [ 0] [ 603/1582] time: 794.2721, d_loss: 1.15391600, g_loss: 0.68050277\n",
      "Epoch: [ 0] [ 604/1582] time: 795.5161, d_loss: 1.13360596, g_loss: 0.67695367\n",
      "Epoch: [ 0] [ 605/1582] time: 796.7571, d_loss: 1.16855431, g_loss: 0.67404056\n",
      "Epoch: [ 0] [ 606/1582] time: 798.0022, d_loss: 1.14819551, g_loss: 0.67527550\n",
      "Epoch: [ 0] [ 607/1582] time: 799.2435, d_loss: 1.19641805, g_loss: 0.66877651\n",
      "Epoch: [ 0] [ 608/1582] time: 800.4868, d_loss: 1.17909002, g_loss: 0.67106152\n",
      "Epoch: [ 0] [ 609/1582] time: 801.7300, d_loss: 1.18734264, g_loss: 0.66682875\n",
      "Epoch: [ 0] [ 610/1582] time: 802.9759, d_loss: 1.21041656, g_loss: 0.66753638\n",
      "Epoch: [ 0] [ 611/1582] time: 804.2199, d_loss: 1.21169889, g_loss: 0.66630960\n",
      "Epoch: [ 0] [ 612/1582] time: 805.4613, d_loss: 1.22210956, g_loss: 0.66618425\n",
      "Epoch: [ 0] [ 613/1582] time: 806.7055, d_loss: 1.20164645, g_loss: 0.66269004\n",
      "Epoch: [ 0] [ 614/1582] time: 807.9514, d_loss: 1.21825540, g_loss: 0.66103661\n",
      "Epoch: [ 0] [ 615/1582] time: 809.1981, d_loss: 1.21216619, g_loss: 0.66673142\n",
      "Epoch: [ 0] [ 616/1582] time: 810.4441, d_loss: 1.20585096, g_loss: 0.66410643\n",
      "Epoch: [ 0] [ 617/1582] time: 811.6871, d_loss: 1.21201873, g_loss: 0.66902316\n",
      "Epoch: [ 0] [ 618/1582] time: 812.9320, d_loss: 1.20719981, g_loss: 0.66508019\n",
      "Epoch: [ 0] [ 619/1582] time: 814.1760, d_loss: 1.22783220, g_loss: 0.67656291\n",
      "Epoch: [ 0] [ 620/1582] time: 815.4199, d_loss: 1.17340279, g_loss: 0.67405802\n",
      "Epoch: [ 0] [ 621/1582] time: 816.6629, d_loss: 1.18424034, g_loss: 0.67916751\n",
      "Epoch: [ 0] [ 622/1582] time: 817.9088, d_loss: 1.17900848, g_loss: 0.68094671\n",
      "Epoch: [ 0] [ 623/1582] time: 819.1548, d_loss: 1.19554663, g_loss: 0.68824178\n",
      "Epoch: [ 0] [ 624/1582] time: 820.3975, d_loss: 1.18942618, g_loss: 0.68961436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [ 625/1582] time: 821.6395, d_loss: 1.20994544, g_loss: 0.69499451\n",
      "Epoch: [ 0] [ 626/1582] time: 822.8914, d_loss: 1.17601657, g_loss: 0.69939047\n",
      "Epoch: [ 0] [ 627/1582] time: 824.1414, d_loss: 1.16822815, g_loss: 0.69943094\n",
      "Epoch: [ 0] [ 628/1582] time: 825.3984, d_loss: 1.18081617, g_loss: 0.70591170\n",
      "Epoch: [ 0] [ 629/1582] time: 826.6403, d_loss: 1.19175792, g_loss: 0.70791137\n",
      "Epoch: [ 0] [ 630/1582] time: 827.8853, d_loss: 1.19764805, g_loss: 0.71234256\n",
      "Epoch: [ 0] [ 631/1582] time: 829.1299, d_loss: 1.15976119, g_loss: 0.72025484\n",
      "Epoch: [ 0] [ 632/1582] time: 830.3732, d_loss: 1.19322288, g_loss: 0.72304958\n",
      "Epoch: [ 0] [ 633/1582] time: 831.6152, d_loss: 1.18136311, g_loss: 0.72387350\n",
      "Epoch: [ 0] [ 634/1582] time: 832.8601, d_loss: 1.16434002, g_loss: 0.72178710\n",
      "Epoch: [ 0] [ 635/1582] time: 834.1048, d_loss: 1.18514550, g_loss: 0.72709733\n",
      "Epoch: [ 0] [ 636/1582] time: 835.3488, d_loss: 1.16033900, g_loss: 0.72948432\n",
      "Epoch: [ 0] [ 637/1582] time: 836.5947, d_loss: 1.20927441, g_loss: 0.72951812\n",
      "Epoch: [ 0] [ 638/1582] time: 837.8417, d_loss: 1.14458656, g_loss: 0.72928286\n",
      "Epoch: [ 0] [ 639/1582] time: 839.0859, d_loss: 1.13832641, g_loss: 0.73221374\n",
      "Epoch: [ 0] [ 640/1582] time: 840.3289, d_loss: 1.12562168, g_loss: 0.73281622\n",
      "Epoch: [ 0] [ 641/1582] time: 841.5698, d_loss: 1.15480161, g_loss: 0.73533165\n",
      "Epoch: [ 0] [ 642/1582] time: 842.8108, d_loss: 1.17747462, g_loss: 0.73631406\n",
      "Epoch: [ 0] [ 643/1582] time: 844.0557, d_loss: 1.15705669, g_loss: 0.73082614\n",
      "Epoch: [ 0] [ 644/1582] time: 845.2978, d_loss: 1.14162350, g_loss: 0.72650641\n",
      "Epoch: [ 0] [ 645/1582] time: 846.5427, d_loss: 1.14069605, g_loss: 0.72528982\n",
      "Epoch: [ 0] [ 646/1582] time: 847.7857, d_loss: 1.17309046, g_loss: 0.71882135\n",
      "Epoch: [ 0] [ 647/1582] time: 849.0286, d_loss: 1.14378738, g_loss: 0.71536392\n",
      "Epoch: [ 0] [ 648/1582] time: 850.2766, d_loss: 1.20582688, g_loss: 0.70850658\n",
      "Epoch: [ 0] [ 649/1582] time: 851.5206, d_loss: 1.19619620, g_loss: 0.70128411\n",
      "Epoch: [ 0] [ 650/1582] time: 852.7645, d_loss: 1.16264439, g_loss: 0.69623613\n",
      "Epoch: [ 0] [ 651/1582] time: 854.0075, d_loss: 1.16353464, g_loss: 0.68746245\n",
      "Epoch: [ 0] [ 652/1582] time: 855.2539, d_loss: 1.19461131, g_loss: 0.68399072\n",
      "Epoch: [ 0] [ 653/1582] time: 856.4958, d_loss: 1.18276250, g_loss: 0.67589414\n",
      "Epoch: [ 0] [ 654/1582] time: 857.7418, d_loss: 1.19285846, g_loss: 0.67159677\n",
      "Epoch: [ 0] [ 655/1582] time: 858.9884, d_loss: 1.21977282, g_loss: 0.66411042\n",
      "Epoch: [ 0] [ 656/1582] time: 860.2344, d_loss: 1.20769942, g_loss: 0.66222876\n",
      "Epoch: [ 0] [ 657/1582] time: 861.4803, d_loss: 1.19666815, g_loss: 0.65476656\n",
      "Epoch: [ 0] [ 658/1582] time: 862.7256, d_loss: 1.19997859, g_loss: 0.65042210\n",
      "Epoch: [ 0] [ 659/1582] time: 863.9696, d_loss: 1.18325710, g_loss: 0.64725953\n",
      "Epoch: [ 0] [ 660/1582] time: 865.2186, d_loss: 1.20033944, g_loss: 0.64578044\n",
      "Epoch: [ 0] [ 661/1582] time: 866.4636, d_loss: 1.22057736, g_loss: 0.64690059\n",
      "Epoch: [ 0] [ 662/1582] time: 867.7075, d_loss: 1.17474639, g_loss: 0.64295185\n",
      "Epoch: [ 0] [ 663/1582] time: 868.9520, d_loss: 1.18258810, g_loss: 0.64542329\n",
      "Epoch: [ 0] [ 664/1582] time: 870.1970, d_loss: 1.16108060, g_loss: 0.64436412\n",
      "Epoch: [ 0] [ 665/1582] time: 871.4400, d_loss: 1.19318652, g_loss: 0.64949358\n",
      "Epoch: [ 0] [ 666/1582] time: 872.6819, d_loss: 1.17100906, g_loss: 0.64819062\n",
      "Epoch: [ 0] [ 667/1582] time: 873.9248, d_loss: 1.17461801, g_loss: 0.65192366\n",
      "Epoch: [ 0] [ 668/1582] time: 875.1698, d_loss: 1.20460904, g_loss: 0.65615356\n",
      "Epoch: [ 0] [ 669/1582] time: 876.4128, d_loss: 1.19001317, g_loss: 0.65325934\n",
      "Epoch: [ 0] [ 670/1582] time: 877.6553, d_loss: 1.18966770, g_loss: 0.65743184\n",
      "Epoch: [ 0] [ 671/1582] time: 878.8973, d_loss: 1.15961051, g_loss: 0.65878582\n",
      "Epoch: [ 0] [ 672/1582] time: 880.1402, d_loss: 1.15293038, g_loss: 0.66322786\n",
      "Epoch: [ 0] [ 673/1582] time: 881.3814, d_loss: 1.18033433, g_loss: 0.66863954\n",
      "Epoch: [ 0] [ 674/1582] time: 882.6244, d_loss: 1.17977405, g_loss: 0.66802365\n",
      "Epoch: [ 0] [ 675/1582] time: 883.8663, d_loss: 1.14324307, g_loss: 0.67338544\n",
      "Epoch: [ 0] [ 676/1582] time: 885.1093, d_loss: 1.15039694, g_loss: 0.67874622\n",
      "Epoch: [ 0] [ 677/1582] time: 886.3492, d_loss: 1.18718147, g_loss: 0.67887497\n",
      "Epoch: [ 0] [ 678/1582] time: 887.5922, d_loss: 1.15702343, g_loss: 0.68079495\n",
      "Epoch: [ 0] [ 679/1582] time: 888.8359, d_loss: 1.14779830, g_loss: 0.68388039\n",
      "Epoch: [ 0] [ 680/1582] time: 890.0780, d_loss: 1.17566216, g_loss: 0.68717313\n",
      "Epoch: [ 0] [ 681/1582] time: 891.3195, d_loss: 1.20594788, g_loss: 0.68690407\n",
      "Epoch: [ 0] [ 682/1582] time: 892.5624, d_loss: 1.17420554, g_loss: 0.68387735\n",
      "Epoch: [ 0] [ 683/1582] time: 893.8044, d_loss: 1.15175831, g_loss: 0.68833899\n",
      "Epoch: [ 0] [ 684/1582] time: 895.0493, d_loss: 1.17852342, g_loss: 0.68808246\n",
      "Epoch: [ 0] [ 685/1582] time: 896.2933, d_loss: 1.15172315, g_loss: 0.69077450\n",
      "Epoch: [ 0] [ 686/1582] time: 897.5372, d_loss: 1.14455462, g_loss: 0.68418193\n",
      "Epoch: [ 0] [ 687/1582] time: 898.7832, d_loss: 1.15346849, g_loss: 0.68693507\n",
      "Epoch: [ 0] [ 688/1582] time: 900.0462, d_loss: 1.15251112, g_loss: 0.68553936\n",
      "Epoch: [ 0] [ 689/1582] time: 901.3161, d_loss: 1.14537930, g_loss: 0.68795848\n",
      "Epoch: [ 0] [ 690/1582] time: 902.6021, d_loss: 1.18478715, g_loss: 0.68579447\n",
      "Epoch: [ 0] [ 691/1582] time: 903.8794, d_loss: 1.19435358, g_loss: 0.68040687\n",
      "Epoch: [ 0] [ 692/1582] time: 905.1604, d_loss: 1.13768566, g_loss: 0.67942119\n",
      "Epoch: [ 0] [ 693/1582] time: 906.4094, d_loss: 1.16498137, g_loss: 0.67703158\n",
      "Epoch: [ 0] [ 694/1582] time: 907.6733, d_loss: 1.16892862, g_loss: 0.67284292\n",
      "Epoch: [ 0] [ 695/1582] time: 908.9482, d_loss: 1.19339848, g_loss: 0.66770887\n",
      "Epoch: [ 0] [ 696/1582] time: 910.2232, d_loss: 1.17684579, g_loss: 0.66811293\n",
      "Epoch: [ 0] [ 697/1582] time: 911.5043, d_loss: 1.19643569, g_loss: 0.66149902\n",
      "Epoch: [ 0] [ 698/1582] time: 912.7903, d_loss: 1.18306506, g_loss: 0.66110611\n",
      "Epoch: [ 0] [ 699/1582] time: 914.0723, d_loss: 1.18260264, g_loss: 0.65725476\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 0] [ 700/1582] time: 921.7965, d_loss: 1.21181512, g_loss: 0.65152133\n",
      "Epoch: [ 0] [ 701/1582] time: 923.0324, d_loss: 1.18415093, g_loss: 0.65133047\n",
      "Epoch: [ 0] [ 702/1582] time: 924.2718, d_loss: 1.23259711, g_loss: 0.64698756\n",
      "Epoch: [ 0] [ 703/1582] time: 925.5133, d_loss: 1.19050181, g_loss: 0.65461451\n",
      "Epoch: [ 0] [ 704/1582] time: 926.7542, d_loss: 1.17244232, g_loss: 0.65003955\n",
      "Epoch: [ 0] [ 705/1582] time: 927.9932, d_loss: 1.18771625, g_loss: 0.65347993\n",
      "Epoch: [ 0] [ 706/1582] time: 929.2358, d_loss: 1.16528881, g_loss: 0.65640432\n",
      "Epoch: [ 0] [ 707/1582] time: 930.4758, d_loss: 1.17557216, g_loss: 0.66040277\n",
      "Epoch: [ 0] [ 708/1582] time: 931.7182, d_loss: 1.20948279, g_loss: 0.66356128\n",
      "Epoch: [ 0] [ 709/1582] time: 932.9591, d_loss: 1.15721512, g_loss: 0.67294103\n",
      "Epoch: [ 0] [ 710/1582] time: 934.2021, d_loss: 1.19715786, g_loss: 0.67694110\n",
      "Epoch: [ 0] [ 711/1582] time: 935.4410, d_loss: 1.16751420, g_loss: 0.68182480\n",
      "Epoch: [ 0] [ 712/1582] time: 936.6814, d_loss: 1.19313717, g_loss: 0.68041307\n",
      "Epoch: [ 0] [ 713/1582] time: 937.9224, d_loss: 1.20108569, g_loss: 0.68950558\n",
      "Epoch: [ 0] [ 714/1582] time: 939.1654, d_loss: 1.20207965, g_loss: 0.69566917\n",
      "Epoch: [ 0] [ 715/1582] time: 940.4073, d_loss: 1.15269911, g_loss: 0.69813371\n",
      "Epoch: [ 0] [ 716/1582] time: 941.6503, d_loss: 1.17924690, g_loss: 0.70043176\n",
      "Epoch: [ 0] [ 717/1582] time: 942.8992, d_loss: 1.18469751, g_loss: 0.70808905\n",
      "Epoch: [ 0] [ 718/1582] time: 944.1412, d_loss: 1.14388359, g_loss: 0.71419233\n",
      "Epoch: [ 0] [ 719/1582] time: 945.3831, d_loss: 1.17481589, g_loss: 0.71936131\n",
      "Epoch: [ 0] [ 720/1582] time: 946.6251, d_loss: 1.17212367, g_loss: 0.72367561\n",
      "Epoch: [ 0] [ 721/1582] time: 947.8671, d_loss: 1.14711666, g_loss: 0.73170131\n",
      "Epoch: [ 0] [ 722/1582] time: 949.1260, d_loss: 1.14568782, g_loss: 0.73624384\n",
      "Epoch: [ 0] [ 723/1582] time: 950.3670, d_loss: 1.15587342, g_loss: 0.73980486\n",
      "Epoch: [ 0] [ 724/1582] time: 951.6079, d_loss: 1.12839210, g_loss: 0.74600023\n",
      "Epoch: [ 0] [ 725/1582] time: 952.8478, d_loss: 1.14071155, g_loss: 0.74662453\n",
      "Epoch: [ 0] [ 726/1582] time: 954.0907, d_loss: 1.13950825, g_loss: 0.74978638\n",
      "Epoch: [ 0] [ 727/1582] time: 955.3317, d_loss: 1.16307116, g_loss: 0.75150931\n",
      "Epoch: [ 0] [ 728/1582] time: 956.5757, d_loss: 1.13502228, g_loss: 0.75346506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [ 729/1582] time: 957.8179, d_loss: 1.14875400, g_loss: 0.74842656\n",
      "Epoch: [ 0] [ 730/1582] time: 959.0609, d_loss: 1.15116405, g_loss: 0.74996829\n",
      "Epoch: [ 0] [ 731/1582] time: 960.3010, d_loss: 1.17843294, g_loss: 0.74398911\n",
      "Epoch: [ 0] [ 732/1582] time: 961.5469, d_loss: 1.15485024, g_loss: 0.73957086\n",
      "Epoch: [ 0] [ 733/1582] time: 962.7838, d_loss: 1.16949356, g_loss: 0.73588079\n",
      "Epoch: [ 0] [ 734/1582] time: 964.0273, d_loss: 1.18173099, g_loss: 0.72793257\n",
      "Epoch: [ 0] [ 735/1582] time: 965.2726, d_loss: 1.17899561, g_loss: 0.72202998\n",
      "Epoch: [ 0] [ 736/1582] time: 966.5166, d_loss: 1.20550656, g_loss: 0.71499616\n",
      "Epoch: [ 0] [ 737/1582] time: 967.7616, d_loss: 1.19153512, g_loss: 0.70246500\n",
      "Epoch: [ 0] [ 738/1582] time: 969.0055, d_loss: 1.20596600, g_loss: 0.69568568\n",
      "Epoch: [ 0] [ 739/1582] time: 970.2524, d_loss: 1.16849172, g_loss: 0.68576384\n",
      "Epoch: [ 0] [ 740/1582] time: 971.4974, d_loss: 1.16471577, g_loss: 0.68157369\n",
      "Epoch: [ 0] [ 741/1582] time: 972.7417, d_loss: 1.19680417, g_loss: 0.67023647\n",
      "Epoch: [ 0] [ 742/1582] time: 973.9857, d_loss: 1.19771600, g_loss: 0.66803694\n",
      "Epoch: [ 0] [ 743/1582] time: 975.2287, d_loss: 1.17921174, g_loss: 0.66404063\n",
      "Epoch: [ 0] [ 744/1582] time: 976.4716, d_loss: 1.13148749, g_loss: 0.66557378\n",
      "Epoch: [ 0] [ 745/1582] time: 977.7126, d_loss: 1.20195055, g_loss: 0.65720880\n",
      "Epoch: [ 0] [ 746/1582] time: 978.9526, d_loss: 1.17349935, g_loss: 0.65888333\n",
      "Epoch: [ 0] [ 747/1582] time: 980.1925, d_loss: 1.19981241, g_loss: 0.65604395\n",
      "Epoch: [ 0] [ 748/1582] time: 981.4346, d_loss: 1.18147492, g_loss: 0.65691918\n",
      "Epoch: [ 0] [ 749/1582] time: 982.6736, d_loss: 1.17337656, g_loss: 0.65569770\n",
      "Epoch: [ 0] [ 750/1582] time: 983.9165, d_loss: 1.13613439, g_loss: 0.65143389\n",
      "Epoch: [ 0] [ 751/1582] time: 985.1572, d_loss: 1.13654351, g_loss: 0.65218699\n",
      "Epoch: [ 0] [ 752/1582] time: 986.3976, d_loss: 1.15223026, g_loss: 0.64917213\n",
      "Epoch: [ 0] [ 753/1582] time: 987.6376, d_loss: 1.15041924, g_loss: 0.64980984\n",
      "Epoch: [ 0] [ 754/1582] time: 988.8773, d_loss: 1.15559447, g_loss: 0.64914536\n",
      "Epoch: [ 0] [ 755/1582] time: 990.1162, d_loss: 1.10196090, g_loss: 0.64820629\n",
      "Epoch: [ 0] [ 756/1582] time: 991.3562, d_loss: 1.10092878, g_loss: 0.64243090\n",
      "Epoch: [ 0] [ 757/1582] time: 992.5971, d_loss: 1.12681663, g_loss: 0.64625674\n",
      "Epoch: [ 0] [ 758/1582] time: 993.8391, d_loss: 1.08218026, g_loss: 0.64513838\n",
      "Epoch: [ 0] [ 759/1582] time: 995.0820, d_loss: 1.12190795, g_loss: 0.64382601\n",
      "Epoch: [ 0] [ 760/1582] time: 996.3233, d_loss: 1.10729980, g_loss: 0.64621162\n",
      "Epoch: [ 0] [ 761/1582] time: 997.5653, d_loss: 1.12536120, g_loss: 0.64848197\n",
      "Epoch: [ 0] [ 762/1582] time: 998.8073, d_loss: 1.12166846, g_loss: 0.64699739\n",
      "Epoch: [ 0] [ 763/1582] time: 1000.0492, d_loss: 1.07151997, g_loss: 0.64895093\n",
      "Epoch: [ 0] [ 764/1582] time: 1001.2902, d_loss: 1.09042084, g_loss: 0.65513867\n",
      "Epoch: [ 0] [ 765/1582] time: 1002.5291, d_loss: 1.06893611, g_loss: 0.65833741\n",
      "Epoch: [ 0] [ 766/1582] time: 1003.7722, d_loss: 1.10841990, g_loss: 0.65848804\n",
      "Epoch: [ 0] [ 767/1582] time: 1005.0132, d_loss: 1.10073185, g_loss: 0.66093981\n",
      "Epoch: [ 0] [ 768/1582] time: 1006.2551, d_loss: 1.09601855, g_loss: 0.66637468\n",
      "Epoch: [ 0] [ 769/1582] time: 1007.4931, d_loss: 1.09604359, g_loss: 0.66273957\n",
      "Epoch: [ 0] [ 770/1582] time: 1008.7350, d_loss: 1.09548056, g_loss: 0.66253966\n",
      "Epoch: [ 0] [ 771/1582] time: 1009.9770, d_loss: 1.14158165, g_loss: 0.66345632\n",
      "Epoch: [ 0] [ 772/1582] time: 1011.2199, d_loss: 1.13433981, g_loss: 0.65464294\n",
      "Epoch: [ 0] [ 773/1582] time: 1012.4619, d_loss: 1.15656757, g_loss: 0.65243328\n",
      "Epoch: [ 0] [ 774/1582] time: 1013.7029, d_loss: 1.18116188, g_loss: 0.64907056\n",
      "Epoch: [ 0] [ 775/1582] time: 1014.9448, d_loss: 1.17174506, g_loss: 0.64511979\n",
      "Epoch: [ 0] [ 776/1582] time: 1016.1888, d_loss: 1.20516658, g_loss: 0.64677525\n",
      "Epoch: [ 0] [ 777/1582] time: 1017.4305, d_loss: 1.19249845, g_loss: 0.64948571\n",
      "Epoch: [ 0] [ 778/1582] time: 1018.6755, d_loss: 1.19243085, g_loss: 0.65584803\n",
      "Epoch: [ 0] [ 779/1582] time: 1019.9155, d_loss: 1.21127701, g_loss: 0.67191792\n",
      "Epoch: [ 0] [ 780/1582] time: 1021.1584, d_loss: 1.17154062, g_loss: 0.67995822\n",
      "Epoch: [ 0] [ 781/1582] time: 1022.4004, d_loss: 1.19112968, g_loss: 0.69093567\n",
      "Epoch: [ 0] [ 782/1582] time: 1023.6448, d_loss: 1.17944479, g_loss: 0.69733334\n",
      "Epoch: [ 0] [ 783/1582] time: 1024.8870, d_loss: 1.13175464, g_loss: 0.70952159\n",
      "Epoch: [ 0] [ 784/1582] time: 1026.1330, d_loss: 1.14590895, g_loss: 0.70627970\n",
      "Epoch: [ 0] [ 785/1582] time: 1027.3728, d_loss: 1.14085484, g_loss: 0.71174502\n",
      "Epoch: [ 0] [ 786/1582] time: 1028.6113, d_loss: 1.11099100, g_loss: 0.70551467\n",
      "Epoch: [ 0] [ 787/1582] time: 1029.8587, d_loss: 1.11295402, g_loss: 0.69236708\n",
      "Epoch: [ 0] [ 788/1582] time: 1031.1007, d_loss: 1.09113848, g_loss: 0.68348849\n",
      "Epoch: [ 0] [ 789/1582] time: 1032.3427, d_loss: 1.07221746, g_loss: 0.67973721\n",
      "Epoch: [ 0] [ 790/1582] time: 1033.5831, d_loss: 1.10532522, g_loss: 0.66510695\n",
      "Epoch: [ 0] [ 791/1582] time: 1034.8290, d_loss: 1.07702231, g_loss: 0.66348898\n",
      "Epoch: [ 0] [ 792/1582] time: 1036.0750, d_loss: 1.08339489, g_loss: 0.66717458\n",
      "Epoch: [ 0] [ 793/1582] time: 1037.3190, d_loss: 1.08512759, g_loss: 0.67574942\n",
      "Epoch: [ 0] [ 794/1582] time: 1038.5649, d_loss: 1.09541953, g_loss: 0.68407822\n",
      "Epoch: [ 0] [ 795/1582] time: 1039.8088, d_loss: 1.09525418, g_loss: 0.68846297\n",
      "Epoch: [ 0] [ 796/1582] time: 1041.0518, d_loss: 1.14086223, g_loss: 0.70137978\n",
      "Epoch: [ 0] [ 797/1582] time: 1042.2931, d_loss: 1.13379037, g_loss: 0.71056736\n",
      "Epoch: [ 0] [ 798/1582] time: 1043.5363, d_loss: 1.14140570, g_loss: 0.72827077\n",
      "Epoch: [ 0] [ 799/1582] time: 1044.7793, d_loss: 1.16324532, g_loss: 0.72774696\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 0] [ 800/1582] time: 1052.8012, d_loss: 1.12455392, g_loss: 0.74129224\n",
      "Epoch: [ 0] [ 801/1582] time: 1054.0422, d_loss: 1.18205285, g_loss: 0.74379516\n",
      "Epoch: [ 0] [ 802/1582] time: 1055.2870, d_loss: 1.14402318, g_loss: 0.74409443\n",
      "Epoch: [ 0] [ 803/1582] time: 1056.5300, d_loss: 1.16557682, g_loss: 0.74722892\n",
      "Epoch: [ 0] [ 804/1582] time: 1057.7729, d_loss: 1.20886469, g_loss: 0.74660826\n",
      "Epoch: [ 0] [ 805/1582] time: 1059.0170, d_loss: 1.18278229, g_loss: 0.74681371\n",
      "Epoch: [ 0] [ 806/1582] time: 1060.2583, d_loss: 1.17352605, g_loss: 0.76031113\n",
      "Epoch: [ 0] [ 807/1582] time: 1061.5002, d_loss: 1.16488862, g_loss: 0.76649481\n",
      "Epoch: [ 0] [ 808/1582] time: 1062.7502, d_loss: 1.16642642, g_loss: 0.76722211\n",
      "Epoch: [ 0] [ 809/1582] time: 1063.9931, d_loss: 1.15418065, g_loss: 0.77400136\n",
      "Epoch: [ 0] [ 810/1582] time: 1065.2441, d_loss: 1.14116573, g_loss: 0.77953571\n",
      "Epoch: [ 0] [ 811/1582] time: 1066.4861, d_loss: 1.13942671, g_loss: 0.78295177\n",
      "Epoch: [ 0] [ 812/1582] time: 1067.7280, d_loss: 1.11731791, g_loss: 0.78524595\n",
      "Epoch: [ 0] [ 813/1582] time: 1068.9689, d_loss: 1.10496068, g_loss: 0.78694832\n",
      "Epoch: [ 0] [ 814/1582] time: 1070.2101, d_loss: 1.06419849, g_loss: 0.77954173\n",
      "Epoch: [ 0] [ 815/1582] time: 1071.4501, d_loss: 1.05828917, g_loss: 0.78052497\n",
      "Epoch: [ 0] [ 816/1582] time: 1072.6910, d_loss: 1.02035403, g_loss: 0.77685654\n",
      "Epoch: [ 0] [ 817/1582] time: 1073.9310, d_loss: 1.02298665, g_loss: 0.77255517\n",
      "Epoch: [ 0] [ 818/1582] time: 1075.1724, d_loss: 1.01361394, g_loss: 0.75855982\n",
      "Epoch: [ 0] [ 819/1582] time: 1076.4114, d_loss: 0.97825283, g_loss: 0.74985385\n",
      "Epoch: [ 0] [ 820/1582] time: 1077.6513, d_loss: 1.01678431, g_loss: 0.72888792\n",
      "Epoch: [ 0] [ 821/1582] time: 1078.8913, d_loss: 1.01665533, g_loss: 0.70306754\n",
      "Epoch: [ 0] [ 822/1582] time: 1080.1332, d_loss: 0.99439412, g_loss: 0.67717636\n",
      "Epoch: [ 0] [ 823/1582] time: 1081.3742, d_loss: 1.04957616, g_loss: 0.63063300\n",
      "Epoch: [ 0] [ 824/1582] time: 1082.6141, d_loss: 1.10088885, g_loss: 0.60155380\n",
      "Epoch: [ 0] [ 825/1582] time: 1083.8544, d_loss: 1.13137007, g_loss: 0.56366771\n",
      "Epoch: [ 0] [ 826/1582] time: 1085.1004, d_loss: 1.12187338, g_loss: 0.53754306\n",
      "Epoch: [ 0] [ 827/1582] time: 1086.3433, d_loss: 1.16974711, g_loss: 0.51598418\n",
      "Epoch: [ 0] [ 828/1582] time: 1087.5839, d_loss: 1.18176985, g_loss: 0.51450354\n",
      "Epoch: [ 0] [ 829/1582] time: 1088.8259, d_loss: 1.15201306, g_loss: 0.52903759\n",
      "Epoch: [ 0] [ 830/1582] time: 1090.0723, d_loss: 1.24444222, g_loss: 0.55204773\n",
      "Epoch: [ 0] [ 831/1582] time: 1091.3133, d_loss: 1.17804766, g_loss: 0.58828789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [ 832/1582] time: 1092.5572, d_loss: 1.21641123, g_loss: 0.61982608\n",
      "Epoch: [ 0] [ 833/1582] time: 1093.7982, d_loss: 1.24490166, g_loss: 0.64826357\n",
      "Epoch: [ 0] [ 834/1582] time: 1095.0412, d_loss: 1.17319238, g_loss: 0.68028563\n",
      "Epoch: [ 0] [ 835/1582] time: 1096.2821, d_loss: 1.15339923, g_loss: 0.70689547\n",
      "Epoch: [ 0] [ 836/1582] time: 1097.5241, d_loss: 1.09054208, g_loss: 0.72367632\n",
      "Epoch: [ 0] [ 837/1582] time: 1098.7656, d_loss: 1.10994864, g_loss: 0.74731779\n",
      "Epoch: [ 0] [ 838/1582] time: 1100.0085, d_loss: 1.15080667, g_loss: 0.75634390\n",
      "Epoch: [ 0] [ 839/1582] time: 1101.2487, d_loss: 1.09678233, g_loss: 0.76722872\n",
      "Epoch: [ 0] [ 840/1582] time: 1102.4887, d_loss: 1.12706685, g_loss: 0.77683377\n",
      "Epoch: [ 0] [ 841/1582] time: 1103.7297, d_loss: 1.06453204, g_loss: 0.77502751\n",
      "Epoch: [ 0] [ 842/1582] time: 1104.9696, d_loss: 1.04950643, g_loss: 0.78685129\n",
      "Epoch: [ 0] [ 843/1582] time: 1106.2105, d_loss: 1.04332936, g_loss: 0.79170954\n",
      "Epoch: [ 0] [ 844/1582] time: 1107.4515, d_loss: 1.03512239, g_loss: 0.82295883\n",
      "Epoch: [ 0] [ 845/1582] time: 1108.6905, d_loss: 1.00036848, g_loss: 0.84207785\n",
      "Epoch: [ 0] [ 846/1582] time: 1109.9312, d_loss: 0.91121143, g_loss: 0.86613363\n",
      "Epoch: [ 0] [ 847/1582] time: 1111.1711, d_loss: 0.90515566, g_loss: 0.87998486\n",
      "Epoch: [ 0] [ 848/1582] time: 1112.4121, d_loss: 0.93205941, g_loss: 0.88553190\n",
      "Epoch: [ 0] [ 849/1582] time: 1113.6511, d_loss: 0.89552855, g_loss: 0.84687251\n",
      "Epoch: [ 0] [ 850/1582] time: 1114.8910, d_loss: 0.94139099, g_loss: 0.77408028\n",
      "Epoch: [ 0] [ 851/1582] time: 1116.1310, d_loss: 0.96313220, g_loss: 0.67003012\n",
      "Epoch: [ 0] [ 852/1582] time: 1117.3729, d_loss: 1.13828468, g_loss: 0.53959817\n",
      "Epoch: [ 0] [ 853/1582] time: 1118.6099, d_loss: 1.30199564, g_loss: 0.45537582\n",
      "Epoch: [ 0] [ 854/1582] time: 1119.8488, d_loss: 1.32865083, g_loss: 0.40591228\n",
      "Epoch: [ 0] [ 855/1582] time: 1121.0889, d_loss: 1.40648222, g_loss: 0.38634348\n",
      "Epoch: [ 0] [ 856/1582] time: 1122.3289, d_loss: 1.37883210, g_loss: 0.41608959\n",
      "Epoch: [ 0] [ 857/1582] time: 1123.5688, d_loss: 1.39752471, g_loss: 0.45426762\n",
      "Epoch: [ 0] [ 858/1582] time: 1124.8088, d_loss: 1.32876337, g_loss: 0.51695698\n",
      "Epoch: [ 0] [ 859/1582] time: 1126.0531, d_loss: 1.26317501, g_loss: 0.57558447\n",
      "Epoch: [ 0] [ 860/1582] time: 1127.2950, d_loss: 1.28094316, g_loss: 0.63368356\n",
      "Epoch: [ 0] [ 861/1582] time: 1128.5390, d_loss: 1.28709900, g_loss: 0.67085946\n",
      "Epoch: [ 0] [ 862/1582] time: 1129.7829, d_loss: 1.25888622, g_loss: 0.68663728\n",
      "Epoch: [ 0] [ 863/1582] time: 1131.0205, d_loss: 1.30583513, g_loss: 0.70972908\n",
      "Epoch: [ 0] [ 864/1582] time: 1132.2625, d_loss: 1.31251478, g_loss: 0.71492451\n",
      "Epoch: [ 0] [ 865/1582] time: 1133.5034, d_loss: 1.27201605, g_loss: 0.72499329\n",
      "Epoch: [ 0] [ 866/1582] time: 1134.7431, d_loss: 1.30038238, g_loss: 0.74734569\n",
      "Epoch: [ 0] [ 867/1582] time: 1135.9831, d_loss: 1.30578768, g_loss: 0.76709884\n",
      "Epoch: [ 0] [ 868/1582] time: 1137.2255, d_loss: 1.27074623, g_loss: 0.81423354\n",
      "Epoch: [ 0] [ 869/1582] time: 1138.4665, d_loss: 1.25424945, g_loss: 0.85808605\n",
      "Epoch: [ 0] [ 870/1582] time: 1139.7097, d_loss: 1.19780219, g_loss: 0.90873981\n",
      "Epoch: [ 0] [ 871/1582] time: 1140.9482, d_loss: 1.17778087, g_loss: 0.93727756\n",
      "Epoch: [ 0] [ 872/1582] time: 1142.1907, d_loss: 1.20930481, g_loss: 0.97401601\n",
      "Epoch: [ 0] [ 873/1582] time: 1143.4336, d_loss: 1.15895867, g_loss: 0.99202490\n",
      "Epoch: [ 0] [ 874/1582] time: 1144.6736, d_loss: 1.20575166, g_loss: 0.99377239\n",
      "Epoch: [ 0] [ 875/1582] time: 1145.9166, d_loss: 1.13464463, g_loss: 0.99750608\n",
      "Epoch: [ 0] [ 876/1582] time: 1147.1595, d_loss: 1.12024403, g_loss: 0.97814178\n",
      "Epoch: [ 0] [ 877/1582] time: 1148.4015, d_loss: 1.09932280, g_loss: 0.95670217\n",
      "Epoch: [ 0] [ 878/1582] time: 1149.6424, d_loss: 1.10245872, g_loss: 0.93660557\n",
      "Epoch: [ 0] [ 879/1582] time: 1150.8824, d_loss: 1.11031795, g_loss: 0.91185391\n",
      "Epoch: [ 0] [ 880/1582] time: 1152.1264, d_loss: 1.08557034, g_loss: 0.88419187\n",
      "Epoch: [ 0] [ 881/1582] time: 1153.3655, d_loss: 1.06915081, g_loss: 0.84797585\n",
      "Epoch: [ 0] [ 882/1582] time: 1154.6077, d_loss: 1.10389376, g_loss: 0.81372076\n",
      "Epoch: [ 0] [ 883/1582] time: 1155.8496, d_loss: 1.07151222, g_loss: 0.78852826\n",
      "Epoch: [ 0] [ 884/1582] time: 1157.0916, d_loss: 1.09453392, g_loss: 0.75374877\n",
      "Epoch: [ 0] [ 885/1582] time: 1158.3305, d_loss: 1.10477853, g_loss: 0.72659552\n",
      "Epoch: [ 0] [ 886/1582] time: 1159.5705, d_loss: 1.14815414, g_loss: 0.69262254\n",
      "Epoch: [ 0] [ 887/1582] time: 1160.8095, d_loss: 1.07476974, g_loss: 0.66804188\n",
      "Epoch: [ 0] [ 888/1582] time: 1162.0554, d_loss: 1.10021114, g_loss: 0.64242601\n",
      "Epoch: [ 0] [ 889/1582] time: 1163.3094, d_loss: 1.12389159, g_loss: 0.61642635\n",
      "Epoch: [ 0] [ 890/1582] time: 1164.5643, d_loss: 1.09285069, g_loss: 0.58687425\n",
      "Epoch: [ 0] [ 891/1582] time: 1165.8033, d_loss: 1.15224910, g_loss: 0.57101357\n",
      "Epoch: [ 0] [ 892/1582] time: 1167.0472, d_loss: 1.15112317, g_loss: 0.55257571\n",
      "Epoch: [ 0] [ 893/1582] time: 1168.2863, d_loss: 1.14708352, g_loss: 0.53592134\n",
      "Epoch: [ 0] [ 894/1582] time: 1169.5282, d_loss: 1.14270175, g_loss: 0.53215247\n",
      "Epoch: [ 0] [ 895/1582] time: 1170.7702, d_loss: 1.17646909, g_loss: 0.52930737\n",
      "Epoch: [ 0] [ 896/1582] time: 1172.0122, d_loss: 1.18208575, g_loss: 0.52787805\n",
      "Epoch: [ 0] [ 897/1582] time: 1173.2535, d_loss: 1.14519978, g_loss: 0.53803062\n",
      "Epoch: [ 0] [ 898/1582] time: 1174.4963, d_loss: 1.15691805, g_loss: 0.54970884\n",
      "Epoch: [ 0] [ 899/1582] time: 1175.7372, d_loss: 1.13580453, g_loss: 0.56522137\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 0] [ 900/1582] time: 1183.5008, d_loss: 1.12976027, g_loss: 0.57805097\n",
      "Epoch: [ 0] [ 901/1582] time: 1184.7488, d_loss: 1.13302493, g_loss: 0.59752929\n",
      "Epoch: [ 0] [ 902/1582] time: 1185.9918, d_loss: 1.14110065, g_loss: 0.61271334\n",
      "Epoch: [ 0] [ 903/1582] time: 1187.2347, d_loss: 1.14619422, g_loss: 0.63116544\n",
      "Epoch: [ 0] [ 904/1582] time: 1188.4787, d_loss: 1.11398280, g_loss: 0.65112245\n",
      "Epoch: [ 0] [ 905/1582] time: 1189.7206, d_loss: 1.11138189, g_loss: 0.66617209\n",
      "Epoch: [ 0] [ 906/1582] time: 1190.9616, d_loss: 1.12531221, g_loss: 0.67356324\n",
      "Epoch: [ 0] [ 907/1582] time: 1192.2026, d_loss: 1.10482383, g_loss: 0.68471646\n",
      "Epoch: [ 0] [ 908/1582] time: 1193.4465, d_loss: 1.11678267, g_loss: 0.69325900\n",
      "Epoch: [ 0] [ 909/1582] time: 1194.6865, d_loss: 1.10630703, g_loss: 0.69668251\n",
      "Epoch: [ 0] [ 910/1582] time: 1195.9295, d_loss: 1.14433396, g_loss: 0.69160432\n",
      "Epoch: [ 0] [ 911/1582] time: 1197.1734, d_loss: 1.16133070, g_loss: 0.69079399\n",
      "Epoch: [ 0] [ 912/1582] time: 1198.4164, d_loss: 1.14374340, g_loss: 0.68377626\n",
      "Epoch: [ 0] [ 913/1582] time: 1199.6583, d_loss: 1.15857410, g_loss: 0.67504418\n",
      "Epoch: [ 0] [ 914/1582] time: 1200.8993, d_loss: 1.18574584, g_loss: 0.66307604\n",
      "Epoch: [ 0] [ 915/1582] time: 1202.1433, d_loss: 1.22107816, g_loss: 0.64872348\n",
      "Epoch: [ 0] [ 916/1582] time: 1203.3852, d_loss: 1.20775509, g_loss: 0.64845711\n",
      "Epoch: [ 0] [ 917/1582] time: 1204.6253, d_loss: 1.24237108, g_loss: 0.64185560\n",
      "Epoch: [ 0] [ 918/1582] time: 1205.8664, d_loss: 1.22996342, g_loss: 0.64327025\n",
      "Epoch: [ 0] [ 919/1582] time: 1207.1103, d_loss: 1.23596251, g_loss: 0.65770388\n",
      "Epoch: [ 0] [ 920/1582] time: 1208.3533, d_loss: 1.19485259, g_loss: 0.66223419\n",
      "Epoch: [ 0] [ 921/1582] time: 1209.5952, d_loss: 1.19764721, g_loss: 0.67837071\n",
      "Epoch: [ 0] [ 922/1582] time: 1210.8412, d_loss: 1.21137393, g_loss: 0.70063818\n",
      "Epoch: [ 0] [ 923/1582] time: 1212.0832, d_loss: 1.19979203, g_loss: 0.71464610\n",
      "Epoch: [ 0] [ 924/1582] time: 1213.3241, d_loss: 1.18564439, g_loss: 0.72680271\n",
      "Epoch: [ 0] [ 925/1582] time: 1214.5711, d_loss: 1.13798368, g_loss: 0.74424446\n",
      "Epoch: [ 0] [ 926/1582] time: 1215.8190, d_loss: 1.17389226, g_loss: 0.76067317\n",
      "Epoch: [ 0] [ 927/1582] time: 1217.0686, d_loss: 1.16403461, g_loss: 0.77408624\n",
      "Epoch: [ 0] [ 928/1582] time: 1218.3125, d_loss: 1.16079724, g_loss: 0.78286356\n",
      "Epoch: [ 0] [ 929/1582] time: 1219.5545, d_loss: 1.13753200, g_loss: 0.78813070\n",
      "Epoch: [ 0] [ 930/1582] time: 1220.7987, d_loss: 1.14227223, g_loss: 0.79539406\n",
      "Epoch: [ 0] [ 931/1582] time: 1222.0446, d_loss: 1.14418542, g_loss: 0.79734665\n",
      "Epoch: [ 0] [ 932/1582] time: 1223.2876, d_loss: 1.11041427, g_loss: 0.79914927\n",
      "Epoch: [ 0] [ 933/1582] time: 1224.5306, d_loss: 1.10812461, g_loss: 0.79418105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [ 934/1582] time: 1225.7742, d_loss: 1.12928474, g_loss: 0.78741586\n",
      "Epoch: [ 0] [ 935/1582] time: 1227.0161, d_loss: 1.09755588, g_loss: 0.77999818\n",
      "Epoch: [ 0] [ 936/1582] time: 1228.2620, d_loss: 1.10522258, g_loss: 0.76836574\n",
      "Epoch: [ 0] [ 937/1582] time: 1229.5029, d_loss: 1.10266542, g_loss: 0.76312554\n",
      "Epoch: [ 0] [ 938/1582] time: 1230.7439, d_loss: 1.12522733, g_loss: 0.74298513\n",
      "Epoch: [ 0] [ 939/1582] time: 1231.9848, d_loss: 1.14828932, g_loss: 0.72837484\n",
      "Epoch: [ 0] [ 940/1582] time: 1233.2286, d_loss: 1.15785170, g_loss: 0.71146500\n",
      "Epoch: [ 0] [ 941/1582] time: 1234.4696, d_loss: 1.12057567, g_loss: 0.69568843\n",
      "Epoch: [ 0] [ 942/1582] time: 1235.7125, d_loss: 1.18195271, g_loss: 0.67709750\n",
      "Epoch: [ 0] [ 943/1582] time: 1236.9555, d_loss: 1.17248130, g_loss: 0.66266823\n",
      "Epoch: [ 0] [ 944/1582] time: 1238.1995, d_loss: 1.16603017, g_loss: 0.64422357\n",
      "Epoch: [ 0] [ 945/1582] time: 1239.4424, d_loss: 1.15485287, g_loss: 0.63251698\n",
      "Epoch: [ 0] [ 946/1582] time: 1240.6854, d_loss: 1.17147982, g_loss: 0.62023211\n",
      "Epoch: [ 0] [ 947/1582] time: 1241.9284, d_loss: 1.16770387, g_loss: 0.61320847\n",
      "Epoch: [ 0] [ 948/1582] time: 1243.1708, d_loss: 1.15801883, g_loss: 0.60280323\n",
      "Epoch: [ 0] [ 949/1582] time: 1244.4109, d_loss: 1.19052267, g_loss: 0.59988075\n",
      "Epoch: [ 0] [ 950/1582] time: 1245.6528, d_loss: 1.15847659, g_loss: 0.59182686\n",
      "Epoch: [ 0] [ 951/1582] time: 1246.8958, d_loss: 1.18256521, g_loss: 0.59224164\n",
      "Epoch: [ 0] [ 952/1582] time: 1248.1357, d_loss: 1.19564700, g_loss: 0.59553903\n",
      "Epoch: [ 0] [ 953/1582] time: 1249.3777, d_loss: 1.20278716, g_loss: 0.60002649\n",
      "Epoch: [ 0] [ 954/1582] time: 1250.6197, d_loss: 1.17855453, g_loss: 0.59946370\n",
      "Epoch: [ 0] [ 955/1582] time: 1251.8613, d_loss: 1.18794072, g_loss: 0.60250664\n",
      "Epoch: [ 0] [ 956/1582] time: 1253.1053, d_loss: 1.17338824, g_loss: 0.61089993\n",
      "Epoch: [ 0] [ 957/1582] time: 1254.3452, d_loss: 1.13368964, g_loss: 0.61903334\n",
      "Epoch: [ 0] [ 958/1582] time: 1255.5872, d_loss: 1.15979290, g_loss: 0.62651151\n",
      "Epoch: [ 0] [ 959/1582] time: 1256.8282, d_loss: 1.17613864, g_loss: 0.63277960\n",
      "Epoch: [ 0] [ 960/1582] time: 1258.0716, d_loss: 1.15846181, g_loss: 0.64559865\n",
      "Epoch: [ 0] [ 961/1582] time: 1259.3135, d_loss: 1.15938425, g_loss: 0.65377504\n",
      "Epoch: [ 0] [ 962/1582] time: 1260.5545, d_loss: 1.14122057, g_loss: 0.66378736\n",
      "Epoch: [ 0] [ 963/1582] time: 1261.7962, d_loss: 1.15792823, g_loss: 0.67359930\n",
      "Epoch: [ 0] [ 964/1582] time: 1263.0402, d_loss: 1.14479780, g_loss: 0.68099445\n",
      "Epoch: [ 0] [ 965/1582] time: 1264.2831, d_loss: 1.09747934, g_loss: 0.69197178\n",
      "Epoch: [ 0] [ 966/1582] time: 1265.5241, d_loss: 1.15292788, g_loss: 0.69580853\n",
      "Epoch: [ 0] [ 967/1582] time: 1266.7641, d_loss: 1.09248614, g_loss: 0.70516634\n",
      "Epoch: [ 0] [ 968/1582] time: 1268.0070, d_loss: 1.07454324, g_loss: 0.71007562\n",
      "Epoch: [ 0] [ 969/1582] time: 1269.2490, d_loss: 1.09239173, g_loss: 0.71363580\n",
      "Epoch: [ 0] [ 970/1582] time: 1270.4900, d_loss: 1.07840300, g_loss: 0.71760863\n",
      "Epoch: [ 0] [ 971/1582] time: 1271.7329, d_loss: 1.04839242, g_loss: 0.71913230\n",
      "Epoch: [ 0] [ 972/1582] time: 1272.9749, d_loss: 1.10810590, g_loss: 0.71754634\n",
      "Epoch: [ 0] [ 973/1582] time: 1274.2199, d_loss: 1.06826377, g_loss: 0.71725863\n",
      "Epoch: [ 0] [ 974/1582] time: 1275.4648, d_loss: 1.03363013, g_loss: 0.71187758\n",
      "Epoch: [ 0] [ 975/1582] time: 1276.7078, d_loss: 1.07371211, g_loss: 0.70165622\n",
      "Epoch: [ 0] [ 976/1582] time: 1277.9487, d_loss: 1.09854078, g_loss: 0.69374144\n",
      "Epoch: [ 0] [ 977/1582] time: 1279.1907, d_loss: 1.10190916, g_loss: 0.68233317\n",
      "Epoch: [ 0] [ 978/1582] time: 1280.4346, d_loss: 1.05267501, g_loss: 0.66632086\n",
      "Epoch: [ 0] [ 979/1582] time: 1281.6778, d_loss: 1.09222293, g_loss: 0.65371120\n",
      "Epoch: [ 0] [ 980/1582] time: 1282.9239, d_loss: 1.10457885, g_loss: 0.63104141\n",
      "Epoch: [ 0] [ 981/1582] time: 1284.1659, d_loss: 1.13040602, g_loss: 0.61851460\n",
      "Epoch: [ 0] [ 982/1582] time: 1285.4103, d_loss: 1.14449072, g_loss: 0.59793460\n",
      "Epoch: [ 0] [ 983/1582] time: 1286.6542, d_loss: 1.16327620, g_loss: 0.58139777\n",
      "Epoch: [ 0] [ 984/1582] time: 1287.8962, d_loss: 1.15849781, g_loss: 0.56746066\n",
      "Epoch: [ 0] [ 985/1582] time: 1289.1382, d_loss: 1.17551160, g_loss: 0.55971658\n",
      "Epoch: [ 0] [ 986/1582] time: 1290.3791, d_loss: 1.17973912, g_loss: 0.55259079\n",
      "Epoch: [ 0] [ 987/1582] time: 1291.6211, d_loss: 1.16357589, g_loss: 0.55791485\n",
      "Epoch: [ 0] [ 988/1582] time: 1292.8640, d_loss: 1.15106010, g_loss: 0.56380945\n",
      "Epoch: [ 0] [ 989/1582] time: 1294.1051, d_loss: 1.15836298, g_loss: 0.58095580\n",
      "Epoch: [ 0] [ 990/1582] time: 1295.3451, d_loss: 1.14397168, g_loss: 0.60640109\n",
      "Epoch: [ 0] [ 991/1582] time: 1296.5870, d_loss: 1.11159146, g_loss: 0.62775767\n",
      "Epoch: [ 0] [ 992/1582] time: 1297.8300, d_loss: 1.09037781, g_loss: 0.66105562\n",
      "Epoch: [ 0] [ 993/1582] time: 1299.0719, d_loss: 1.05402160, g_loss: 0.69020766\n",
      "Epoch: [ 0] [ 994/1582] time: 1300.3158, d_loss: 1.03225946, g_loss: 0.72536767\n",
      "Epoch: [ 0] [ 995/1582] time: 1301.5587, d_loss: 1.00189257, g_loss: 0.76114064\n",
      "Epoch: [ 0] [ 996/1582] time: 1302.8077, d_loss: 0.94397676, g_loss: 0.79590833\n",
      "Epoch: [ 0] [ 997/1582] time: 1304.0517, d_loss: 0.94862682, g_loss: 0.83931202\n",
      "Epoch: [ 0] [ 998/1582] time: 1305.3017, d_loss: 0.89499021, g_loss: 0.86363292\n",
      "Epoch: [ 0] [ 999/1582] time: 1306.5426, d_loss: 0.88877755, g_loss: 0.88959312\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 0] [1000/1582] time: 1314.3285, d_loss: 0.88973373, g_loss: 0.89662445\n",
      "Epoch: [ 0] [1001/1582] time: 1315.5705, d_loss: 0.89149934, g_loss: 0.89044243\n",
      "Epoch: [ 0] [1002/1582] time: 1316.8124, d_loss: 0.91119927, g_loss: 0.87842572\n",
      "Epoch: [ 0] [1003/1582] time: 1318.0569, d_loss: 0.89535189, g_loss: 0.84850860\n",
      "Epoch: [ 0] [1004/1582] time: 1319.3009, d_loss: 0.90962327, g_loss: 0.81778884\n",
      "Epoch: [ 0] [1005/1582] time: 1320.5458, d_loss: 0.93510818, g_loss: 0.77051532\n",
      "Epoch: [ 0] [1006/1582] time: 1321.7888, d_loss: 0.95496011, g_loss: 0.71668220\n",
      "Epoch: [ 0] [1007/1582] time: 1323.0348, d_loss: 1.01944518, g_loss: 0.63885331\n",
      "Epoch: [ 0] [1008/1582] time: 1324.2790, d_loss: 1.09176791, g_loss: 0.53307182\n",
      "Epoch: [ 0] [1009/1582] time: 1325.5220, d_loss: 1.19967461, g_loss: 0.44919571\n",
      "Epoch: [ 0] [1010/1582] time: 1326.7640, d_loss: 1.31702256, g_loss: 0.38936645\n",
      "Epoch: [ 0] [1011/1582] time: 1328.0072, d_loss: 1.34637690, g_loss: 0.36489481\n",
      "Epoch: [ 0] [1012/1582] time: 1329.2532, d_loss: 1.27129507, g_loss: 0.41084859\n",
      "Epoch: [ 0] [1013/1582] time: 1330.4971, d_loss: 1.07771218, g_loss: 0.50468951\n",
      "Epoch: [ 0] [1014/1582] time: 1331.7389, d_loss: 0.96535474, g_loss: 0.63318288\n",
      "Epoch: [ 0] [1015/1582] time: 1332.9819, d_loss: 0.88100040, g_loss: 0.74089849\n",
      "Epoch: [ 0] [1016/1582] time: 1334.2259, d_loss: 0.79661351, g_loss: 0.80552536\n",
      "Epoch: [ 0] [1017/1582] time: 1335.4678, d_loss: 0.74079835, g_loss: 0.82056761\n",
      "Epoch: [ 0] [1018/1582] time: 1336.7106, d_loss: 0.69659728, g_loss: 0.82564962\n",
      "Epoch: [ 0] [1019/1582] time: 1337.9536, d_loss: 0.74934733, g_loss: 0.81243068\n",
      "Epoch: [ 0] [1020/1582] time: 1339.1966, d_loss: 0.77356887, g_loss: 0.77486706\n",
      "Epoch: [ 0] [1021/1582] time: 1340.4395, d_loss: 0.83983159, g_loss: 0.72223997\n",
      "Epoch: [ 0] [1022/1582] time: 1341.6814, d_loss: 0.83759946, g_loss: 0.66742033\n",
      "Epoch: [ 0] [1023/1582] time: 1342.9254, d_loss: 0.96284318, g_loss: 0.59604830\n",
      "Epoch: [ 0] [1024/1582] time: 1344.1693, d_loss: 1.10436058, g_loss: 0.54502892\n",
      "Epoch: [ 0] [1025/1582] time: 1345.4113, d_loss: 1.17286921, g_loss: 0.51086140\n",
      "Epoch: [ 0] [1026/1582] time: 1346.6562, d_loss: 1.15366709, g_loss: 0.49749869\n",
      "Epoch: [ 0] [1027/1582] time: 1347.8992, d_loss: 1.16156089, g_loss: 0.51314384\n",
      "Epoch: [ 0] [1028/1582] time: 1349.1442, d_loss: 1.20569873, g_loss: 0.54959464\n",
      "Epoch: [ 0] [1029/1582] time: 1350.3871, d_loss: 1.09070778, g_loss: 0.61136556\n",
      "Epoch: [ 0] [1030/1582] time: 1351.6301, d_loss: 1.11725342, g_loss: 0.68280810\n",
      "Epoch: [ 0] [1031/1582] time: 1352.8720, d_loss: 1.01969707, g_loss: 0.74749780\n",
      "Epoch: [ 0] [1032/1582] time: 1354.1150, d_loss: 1.12283444, g_loss: 0.79375339\n",
      "Epoch: [ 0] [1033/1582] time: 1355.3610, d_loss: 1.06749845, g_loss: 0.82532257\n",
      "Epoch: [ 0] [1034/1582] time: 1356.6059, d_loss: 1.02684331, g_loss: 0.83610535\n",
      "Epoch: [ 0] [1035/1582] time: 1357.8509, d_loss: 0.97372794, g_loss: 0.83243895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [1036/1582] time: 1359.0952, d_loss: 0.99297321, g_loss: 0.78732234\n",
      "Epoch: [ 0] [1037/1582] time: 1360.3359, d_loss: 1.08011842, g_loss: 0.64971954\n",
      "Epoch: [ 0] [1038/1582] time: 1361.5772, d_loss: 1.33601546, g_loss: 0.47128269\n",
      "Epoch: [ 0] [1039/1582] time: 1362.8187, d_loss: 1.62560010, g_loss: 0.32371908\n",
      "Epoch: [ 0] [1040/1582] time: 1364.0627, d_loss: 1.71280956, g_loss: 0.28459096\n",
      "Epoch: [ 0] [1041/1582] time: 1365.3072, d_loss: 1.64111698, g_loss: 0.34760323\n",
      "Epoch: [ 0] [1042/1582] time: 1366.5511, d_loss: 1.37185311, g_loss: 0.51996672\n",
      "Epoch: [ 0] [1043/1582] time: 1367.7931, d_loss: 1.08852720, g_loss: 0.78561872\n",
      "Epoch: [ 0] [1044/1582] time: 1369.0370, d_loss: 0.95341861, g_loss: 1.12863755\n",
      "Epoch: [ 0] [1045/1582] time: 1370.2792, d_loss: 0.88080585, g_loss: 1.35735059\n",
      "Epoch: [ 0] [1046/1582] time: 1371.5222, d_loss: 0.73918766, g_loss: 1.49758506\n",
      "Epoch: [ 0] [1047/1582] time: 1372.7692, d_loss: 0.75105488, g_loss: 1.52122235\n",
      "Epoch: [ 0] [1048/1582] time: 1374.0121, d_loss: 0.70303839, g_loss: 1.42591226\n",
      "Epoch: [ 0] [1049/1582] time: 1375.2541, d_loss: 0.71953249, g_loss: 1.29779780\n",
      "Epoch: [ 0] [1050/1582] time: 1376.4970, d_loss: 0.79507804, g_loss: 1.11705935\n",
      "Epoch: [ 0] [1051/1582] time: 1377.7360, d_loss: 0.89869767, g_loss: 0.93455458\n",
      "Epoch: [ 0] [1052/1582] time: 1378.9780, d_loss: 1.01763606, g_loss: 0.77862871\n",
      "Epoch: [ 0] [1053/1582] time: 1380.2203, d_loss: 1.02381253, g_loss: 0.62817240\n",
      "Epoch: [ 0] [1054/1582] time: 1381.4652, d_loss: 1.14654922, g_loss: 0.55910540\n",
      "Epoch: [ 0] [1055/1582] time: 1382.7072, d_loss: 1.15586686, g_loss: 0.51985532\n",
      "Epoch: [ 0] [1056/1582] time: 1383.9502, d_loss: 1.20712852, g_loss: 0.50998288\n",
      "Epoch: [ 0] [1057/1582] time: 1385.1931, d_loss: 1.13247776, g_loss: 0.51640129\n",
      "Epoch: [ 0] [1058/1582] time: 1386.4369, d_loss: 1.22132230, g_loss: 0.54933244\n",
      "Epoch: [ 0] [1059/1582] time: 1387.6808, d_loss: 1.19735038, g_loss: 0.58862931\n",
      "Epoch: [ 0] [1060/1582] time: 1388.9268, d_loss: 1.15627360, g_loss: 0.63986278\n",
      "Epoch: [ 0] [1061/1582] time: 1390.1767, d_loss: 1.08584774, g_loss: 0.69663012\n",
      "Epoch: [ 0] [1062/1582] time: 1391.4197, d_loss: 1.09979820, g_loss: 0.73262107\n",
      "Epoch: [ 0] [1063/1582] time: 1392.6637, d_loss: 1.05823004, g_loss: 0.77087313\n",
      "Epoch: [ 0] [1064/1582] time: 1393.9096, d_loss: 1.08003974, g_loss: 0.80877787\n",
      "Epoch: [ 0] [1065/1582] time: 1395.1556, d_loss: 1.11946821, g_loss: 0.82929075\n",
      "Epoch: [ 0] [1066/1582] time: 1396.4015, d_loss: 1.04651630, g_loss: 0.83190405\n",
      "Epoch: [ 0] [1067/1582] time: 1397.6455, d_loss: 1.00080788, g_loss: 0.84340662\n",
      "Epoch: [ 0] [1068/1582] time: 1398.8895, d_loss: 1.00371325, g_loss: 0.85088539\n",
      "Epoch: [ 0] [1069/1582] time: 1400.1344, d_loss: 1.02086508, g_loss: 0.85251540\n",
      "Epoch: [ 0] [1070/1582] time: 1401.3764, d_loss: 1.05948460, g_loss: 0.84890521\n",
      "Epoch: [ 0] [1071/1582] time: 1402.6193, d_loss: 0.95283926, g_loss: 0.84560633\n",
      "Epoch: [ 0] [1072/1582] time: 1403.8634, d_loss: 0.93438935, g_loss: 0.84795845\n",
      "Epoch: [ 0] [1073/1582] time: 1405.1064, d_loss: 0.91906154, g_loss: 0.84529912\n",
      "Epoch: [ 0] [1074/1582] time: 1406.3494, d_loss: 0.94760662, g_loss: 0.83796769\n",
      "Epoch: [ 0] [1075/1582] time: 1407.5923, d_loss: 0.94641018, g_loss: 0.82511854\n",
      "Epoch: [ 0] [1076/1582] time: 1408.8363, d_loss: 0.85017884, g_loss: 0.81191826\n",
      "Epoch: [ 0] [1077/1582] time: 1410.0812, d_loss: 0.89435458, g_loss: 0.80579221\n",
      "Epoch: [ 0] [1078/1582] time: 1411.3262, d_loss: 0.86416650, g_loss: 0.77478111\n",
      "Epoch: [ 0] [1079/1582] time: 1412.5702, d_loss: 0.90246165, g_loss: 0.74728930\n",
      "Epoch: [ 0] [1080/1582] time: 1413.8131, d_loss: 0.91867799, g_loss: 0.67922872\n",
      "Epoch: [ 0] [1081/1582] time: 1415.0601, d_loss: 0.99666584, g_loss: 0.60388935\n",
      "Epoch: [ 0] [1082/1582] time: 1416.3041, d_loss: 1.05363524, g_loss: 0.52069288\n",
      "Epoch: [ 0] [1083/1582] time: 1417.5491, d_loss: 1.20268190, g_loss: 0.44921216\n",
      "Epoch: [ 0] [1084/1582] time: 1418.7930, d_loss: 1.29232764, g_loss: 0.43385115\n",
      "Epoch: [ 0] [1085/1582] time: 1420.0380, d_loss: 1.17783976, g_loss: 0.46269387\n",
      "Epoch: [ 0] [1086/1582] time: 1421.2807, d_loss: 1.08904302, g_loss: 0.57430780\n",
      "Epoch: [ 0] [1087/1582] time: 1422.5226, d_loss: 0.98024797, g_loss: 0.73449510\n",
      "Epoch: [ 0] [1088/1582] time: 1423.7696, d_loss: 0.84677660, g_loss: 0.98846209\n",
      "Epoch: [ 0] [1089/1582] time: 1425.0202, d_loss: 0.73637414, g_loss: 1.20749855\n",
      "Epoch: [ 0] [1090/1582] time: 1426.2652, d_loss: 0.67689729, g_loss: 1.38742816\n",
      "Epoch: [ 0] [1091/1582] time: 1427.5082, d_loss: 0.60352045, g_loss: 1.45376599\n",
      "Epoch: [ 0] [1092/1582] time: 1428.7541, d_loss: 0.70525450, g_loss: 1.29464650\n",
      "Epoch: [ 0] [1093/1582] time: 1429.9991, d_loss: 0.73002720, g_loss: 1.08206367\n",
      "Epoch: [ 0] [1094/1582] time: 1431.2466, d_loss: 0.98563218, g_loss: 0.70350194\n",
      "Epoch: [ 0] [1095/1582] time: 1432.4956, d_loss: 1.30714774, g_loss: 0.43664074\n",
      "Epoch: [ 0] [1096/1582] time: 1433.7435, d_loss: 1.51515591, g_loss: 0.32271564\n",
      "Epoch: [ 0] [1097/1582] time: 1434.9885, d_loss: 1.55354953, g_loss: 0.28561991\n",
      "Epoch: [ 0] [1098/1582] time: 1436.2325, d_loss: 1.59623218, g_loss: 0.33296627\n",
      "Epoch: [ 0] [1099/1582] time: 1437.4774, d_loss: 1.43710113, g_loss: 0.40753746\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 0] [1100/1582] time: 1445.1920, d_loss: 1.17205882, g_loss: 0.51975864\n",
      "Epoch: [ 0] [1101/1582] time: 1446.4288, d_loss: 1.00092506, g_loss: 0.63895434\n",
      "Epoch: [ 0] [1102/1582] time: 1447.6771, d_loss: 0.91964483, g_loss: 0.73952210\n",
      "Epoch: [ 0] [1103/1582] time: 1448.9220, d_loss: 0.94527537, g_loss: 0.76594239\n",
      "Epoch: [ 0] [1104/1582] time: 1450.1720, d_loss: 0.85081947, g_loss: 0.77278054\n",
      "Epoch: [ 0] [1105/1582] time: 1451.4170, d_loss: 0.91263026, g_loss: 0.73098493\n",
      "Epoch: [ 0] [1106/1582] time: 1452.6633, d_loss: 0.93281394, g_loss: 0.68531460\n",
      "Epoch: [ 0] [1107/1582] time: 1453.9103, d_loss: 0.97366881, g_loss: 0.63141406\n",
      "Epoch: [ 0] [1108/1582] time: 1455.1563, d_loss: 1.02515197, g_loss: 0.56348610\n",
      "Epoch: [ 0] [1109/1582] time: 1456.4022, d_loss: 1.06124520, g_loss: 0.53611028\n",
      "Epoch: [ 0] [1110/1582] time: 1457.6457, d_loss: 1.15697229, g_loss: 0.50045872\n",
      "Epoch: [ 0] [1111/1582] time: 1458.8906, d_loss: 1.13748097, g_loss: 0.47115475\n",
      "Epoch: [ 0] [1112/1582] time: 1460.1356, d_loss: 1.12432384, g_loss: 0.47564301\n",
      "Epoch: [ 0] [1113/1582] time: 1461.3795, d_loss: 1.20290375, g_loss: 0.51715791\n",
      "Epoch: [ 0] [1114/1582] time: 1462.6245, d_loss: 1.25498235, g_loss: 0.53826398\n",
      "Epoch: [ 0] [1115/1582] time: 1463.8683, d_loss: 1.31675768, g_loss: 0.56653684\n",
      "Epoch: [ 0] [1116/1582] time: 1465.1123, d_loss: 1.30656409, g_loss: 0.59317762\n",
      "Epoch: [ 0] [1117/1582] time: 1466.3592, d_loss: 1.32842827, g_loss: 0.61270028\n",
      "Epoch: [ 0] [1118/1582] time: 1467.6052, d_loss: 1.33869350, g_loss: 0.63755667\n",
      "Epoch: [ 0] [1119/1582] time: 1468.8541, d_loss: 1.22830963, g_loss: 0.66276997\n",
      "Epoch: [ 0] [1120/1582] time: 1470.1002, d_loss: 1.22553325, g_loss: 0.70363641\n",
      "Epoch: [ 0] [1121/1582] time: 1471.3441, d_loss: 1.16967034, g_loss: 0.75774306\n",
      "Epoch: [ 0] [1122/1582] time: 1472.5877, d_loss: 1.15080559, g_loss: 0.81026971\n",
      "Epoch: [ 0] [1123/1582] time: 1473.8307, d_loss: 1.01791930, g_loss: 0.84330863\n",
      "Epoch: [ 0] [1124/1582] time: 1475.0758, d_loss: 1.00718951, g_loss: 0.87856710\n",
      "Epoch: [ 0] [1125/1582] time: 1476.3167, d_loss: 0.97263038, g_loss: 0.89674008\n",
      "Epoch: [ 0] [1126/1582] time: 1477.5597, d_loss: 1.00639391, g_loss: 0.90188712\n",
      "Epoch: [ 0] [1127/1582] time: 1478.8036, d_loss: 0.96623838, g_loss: 0.88535309\n",
      "Epoch: [ 0] [1128/1582] time: 1480.0494, d_loss: 0.93600768, g_loss: 0.86013865\n",
      "Epoch: [ 0] [1129/1582] time: 1481.2964, d_loss: 0.89704061, g_loss: 0.84381539\n",
      "Epoch: [ 0] [1130/1582] time: 1482.5419, d_loss: 0.91435772, g_loss: 0.81460035\n",
      "Epoch: [ 0] [1131/1582] time: 1483.7848, d_loss: 0.90477717, g_loss: 0.80255997\n",
      "Epoch: [ 0] [1132/1582] time: 1485.0298, d_loss: 0.90366411, g_loss: 0.78916705\n",
      "Epoch: [ 0] [1133/1582] time: 1486.2748, d_loss: 0.86637980, g_loss: 0.78699118\n",
      "Epoch: [ 0] [1134/1582] time: 1487.5197, d_loss: 0.84458280, g_loss: 0.77887768\n",
      "Epoch: [ 0] [1135/1582] time: 1488.7637, d_loss: 0.86284661, g_loss: 0.78249049\n",
      "Epoch: [ 0] [1136/1582] time: 1490.0096, d_loss: 0.83624095, g_loss: 0.78891164\n",
      "Epoch: [ 0] [1137/1582] time: 1491.2545, d_loss: 0.82255387, g_loss: 0.78951782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [1138/1582] time: 1492.5005, d_loss: 0.84552860, g_loss: 0.79881150\n",
      "Epoch: [ 0] [1139/1582] time: 1493.7425, d_loss: 0.76109505, g_loss: 0.80418140\n",
      "Epoch: [ 0] [1140/1582] time: 1494.9879, d_loss: 0.76986694, g_loss: 0.81681383\n",
      "Epoch: [ 0] [1141/1582] time: 1496.2285, d_loss: 0.76020265, g_loss: 0.82734674\n",
      "Epoch: [ 0] [1142/1582] time: 1497.4715, d_loss: 0.76626110, g_loss: 0.83077914\n",
      "Epoch: [ 0] [1143/1582] time: 1498.7167, d_loss: 0.72641546, g_loss: 0.83897406\n",
      "Epoch: [ 0] [1144/1582] time: 1499.9616, d_loss: 0.75826061, g_loss: 0.83661681\n",
      "Epoch: [ 0] [1145/1582] time: 1501.2056, d_loss: 0.73472977, g_loss: 0.83428043\n",
      "Epoch: [ 0] [1146/1582] time: 1502.4486, d_loss: 0.73882818, g_loss: 0.83229363\n",
      "Epoch: [ 0] [1147/1582] time: 1503.6935, d_loss: 0.71914876, g_loss: 0.82342434\n",
      "Epoch: [ 0] [1148/1582] time: 1504.9385, d_loss: 0.72391254, g_loss: 0.81268239\n",
      "Epoch: [ 0] [1149/1582] time: 1506.1824, d_loss: 0.75779307, g_loss: 0.78783220\n",
      "Epoch: [ 0] [1150/1582] time: 1507.4254, d_loss: 0.69859695, g_loss: 0.76233596\n",
      "Epoch: [ 0] [1151/1582] time: 1508.6673, d_loss: 0.74961430, g_loss: 0.71798587\n",
      "Epoch: [ 0] [1152/1582] time: 1509.9133, d_loss: 0.83224481, g_loss: 0.69181359\n",
      "Epoch: [ 0] [1153/1582] time: 1511.1563, d_loss: 0.89575267, g_loss: 0.64066243\n",
      "Epoch: [ 0] [1154/1582] time: 1512.3982, d_loss: 0.90063149, g_loss: 0.56548810\n",
      "Epoch: [ 0] [1155/1582] time: 1513.6392, d_loss: 1.10048854, g_loss: 0.45636177\n",
      "Epoch: [ 0] [1156/1582] time: 1514.8832, d_loss: 1.31673956, g_loss: 0.37424287\n",
      "Epoch: [ 0] [1157/1582] time: 1516.1262, d_loss: 1.41498339, g_loss: 0.30711108\n",
      "Epoch: [ 0] [1158/1582] time: 1517.3681, d_loss: 1.47959030, g_loss: 0.29057723\n",
      "Epoch: [ 0] [1159/1582] time: 1518.6100, d_loss: 1.37618613, g_loss: 0.30471593\n",
      "Epoch: [ 0] [1160/1582] time: 1519.8525, d_loss: 1.26911151, g_loss: 0.42119128\n",
      "Epoch: [ 0] [1161/1582] time: 1521.0956, d_loss: 0.98942304, g_loss: 0.55713320\n",
      "Epoch: [ 0] [1162/1582] time: 1522.3397, d_loss: 0.72370398, g_loss: 0.77753353\n",
      "Epoch: [ 0] [1163/1582] time: 1523.5836, d_loss: 0.63850355, g_loss: 0.99535930\n",
      "Epoch: [ 0] [1164/1582] time: 1524.8286, d_loss: 0.56226343, g_loss: 1.11599529\n",
      "Epoch: [ 0] [1165/1582] time: 1526.0725, d_loss: 0.55855978, g_loss: 1.07469440\n",
      "Epoch: [ 0] [1166/1582] time: 1527.3175, d_loss: 0.65117007, g_loss: 0.93295896\n",
      "Epoch: [ 0] [1167/1582] time: 1528.5624, d_loss: 0.83319682, g_loss: 0.75237840\n",
      "Epoch: [ 0] [1168/1582] time: 1529.8064, d_loss: 0.94484913, g_loss: 0.60167861\n",
      "Epoch: [ 0] [1169/1582] time: 1531.0523, d_loss: 1.10313892, g_loss: 0.52352136\n",
      "Epoch: [ 0] [1170/1582] time: 1532.2972, d_loss: 1.14791358, g_loss: 0.48949566\n",
      "Epoch: [ 0] [1171/1582] time: 1533.5417, d_loss: 1.08780861, g_loss: 0.51759017\n",
      "Epoch: [ 0] [1172/1582] time: 1534.7876, d_loss: 1.05477190, g_loss: 0.54622990\n",
      "Epoch: [ 0] [1173/1582] time: 1536.0336, d_loss: 1.05525863, g_loss: 0.63402939\n",
      "Epoch: [ 0] [1174/1582] time: 1537.2795, d_loss: 0.98723882, g_loss: 0.68377030\n",
      "Epoch: [ 0] [1175/1582] time: 1538.5234, d_loss: 1.00562274, g_loss: 0.71974152\n",
      "Epoch: [ 0] [1176/1582] time: 1539.7674, d_loss: 1.00691664, g_loss: 0.71644753\n",
      "Epoch: [ 0] [1177/1582] time: 1541.0100, d_loss: 1.11868382, g_loss: 0.66540760\n",
      "Epoch: [ 0] [1178/1582] time: 1542.2529, d_loss: 1.17188895, g_loss: 0.60721266\n",
      "Epoch: [ 0] [1179/1582] time: 1543.4979, d_loss: 1.27739239, g_loss: 0.59653920\n",
      "Epoch: [ 0] [1180/1582] time: 1544.7489, d_loss: 1.18616486, g_loss: 0.60537350\n",
      "Epoch: [ 0] [1181/1582] time: 1545.9969, d_loss: 1.18851221, g_loss: 0.62700963\n",
      "Epoch: [ 0] [1182/1582] time: 1547.2468, d_loss: 1.26443815, g_loss: 0.67336303\n",
      "Epoch: [ 0] [1183/1582] time: 1548.4940, d_loss: 1.15415502, g_loss: 0.72378266\n",
      "Epoch: [ 0] [1184/1582] time: 1549.7400, d_loss: 1.05075479, g_loss: 0.77519077\n",
      "Epoch: [ 0] [1185/1582] time: 1550.9859, d_loss: 0.97072619, g_loss: 0.83270741\n",
      "Epoch: [ 0] [1186/1582] time: 1552.2328, d_loss: 1.00679517, g_loss: 0.86986101\n",
      "Epoch: [ 0] [1187/1582] time: 1553.4787, d_loss: 1.00440526, g_loss: 0.89941514\n",
      "Epoch: [ 0] [1188/1582] time: 1554.7239, d_loss: 0.96662229, g_loss: 0.91934812\n",
      "Epoch: [ 0] [1189/1582] time: 1555.9638, d_loss: 0.78013378, g_loss: 0.93644059\n",
      "Epoch: [ 0] [1190/1582] time: 1557.2102, d_loss: 0.93193871, g_loss: 0.94417953\n",
      "Epoch: [ 0] [1191/1582] time: 1558.4552, d_loss: 0.95312095, g_loss: 0.91264248\n",
      "Epoch: [ 0] [1192/1582] time: 1559.7010, d_loss: 0.83486164, g_loss: 0.88651460\n",
      "Epoch: [ 0] [1193/1582] time: 1560.9463, d_loss: 0.83493567, g_loss: 0.84640980\n",
      "Epoch: [ 0] [1194/1582] time: 1562.1909, d_loss: 0.84759527, g_loss: 0.83028746\n",
      "Epoch: [ 0] [1195/1582] time: 1563.4379, d_loss: 0.84172678, g_loss: 0.79816866\n",
      "Epoch: [ 0] [1196/1582] time: 1564.6789, d_loss: 0.84451258, g_loss: 0.77314210\n",
      "Epoch: [ 0] [1197/1582] time: 1565.9220, d_loss: 0.80973363, g_loss: 0.73783273\n",
      "Epoch: [ 0] [1198/1582] time: 1567.1670, d_loss: 0.81798655, g_loss: 0.71998394\n",
      "Epoch: [ 0] [1199/1582] time: 1568.4099, d_loss: 0.88310766, g_loss: 0.68289316\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 0] [1200/1582] time: 1576.4288, d_loss: 0.94587171, g_loss: 0.63239670\n",
      "Epoch: [ 0] [1201/1582] time: 1577.6718, d_loss: 1.03872943, g_loss: 0.55772430\n",
      "Epoch: [ 0] [1202/1582] time: 1578.9157, d_loss: 1.13678658, g_loss: 0.47688228\n",
      "Epoch: [ 0] [1203/1582] time: 1580.1596, d_loss: 1.27442968, g_loss: 0.39164108\n",
      "Epoch: [ 0] [1204/1582] time: 1581.4026, d_loss: 1.35511279, g_loss: 0.34977359\n",
      "Epoch: [ 0] [1205/1582] time: 1582.6436, d_loss: 1.46631694, g_loss: 0.33281225\n",
      "Epoch: [ 0] [1206/1582] time: 1583.8866, d_loss: 1.40052807, g_loss: 0.33874452\n",
      "Epoch: [ 0] [1207/1582] time: 1585.1325, d_loss: 1.47867084, g_loss: 0.36836177\n",
      "Epoch: [ 0] [1208/1582] time: 1586.3765, d_loss: 1.27799475, g_loss: 0.42616546\n",
      "Epoch: [ 0] [1209/1582] time: 1587.6204, d_loss: 1.17318034, g_loss: 0.50305915\n",
      "Epoch: [ 0] [1210/1582] time: 1588.8684, d_loss: 1.00007558, g_loss: 0.68035561\n",
      "Epoch: [ 0] [1211/1582] time: 1590.1133, d_loss: 0.87741649, g_loss: 0.86599505\n",
      "Epoch: [ 0] [1212/1582] time: 1591.3592, d_loss: 0.73630881, g_loss: 1.06613994\n",
      "Epoch: [ 0] [1213/1582] time: 1592.6022, d_loss: 0.62227464, g_loss: 1.30973172\n",
      "Epoch: [ 0] [1214/1582] time: 1593.8441, d_loss: 0.61266887, g_loss: 1.37467122\n",
      "Epoch: [ 0] [1215/1582] time: 1595.0871, d_loss: 0.60647851, g_loss: 1.36653697\n",
      "Epoch: [ 0] [1216/1582] time: 1596.3337, d_loss: 0.61502361, g_loss: 1.22960448\n",
      "Epoch: [ 0] [1217/1582] time: 1597.5787, d_loss: 0.72610670, g_loss: 1.00537491\n",
      "Epoch: [ 0] [1218/1582] time: 1598.8249, d_loss: 0.81674111, g_loss: 0.79879367\n",
      "Epoch: [ 0] [1219/1582] time: 1600.0682, d_loss: 0.94874024, g_loss: 0.63116467\n",
      "Epoch: [ 0] [1220/1582] time: 1601.3151, d_loss: 1.06611729, g_loss: 0.51044399\n",
      "Epoch: [ 0] [1221/1582] time: 1602.5591, d_loss: 1.19652021, g_loss: 0.46643558\n",
      "Epoch: [ 0] [1222/1582] time: 1603.8020, d_loss: 1.11456752, g_loss: 0.47504628\n",
      "Epoch: [ 0] [1223/1582] time: 1605.0472, d_loss: 1.08533835, g_loss: 0.50100195\n",
      "Epoch: [ 0] [1224/1582] time: 1606.2912, d_loss: 1.04239917, g_loss: 0.54470098\n",
      "Epoch: [ 0] [1225/1582] time: 1607.5371, d_loss: 0.99358284, g_loss: 0.57294226\n",
      "Epoch: [ 0] [1226/1582] time: 1608.7781, d_loss: 0.92350864, g_loss: 0.58190912\n",
      "Epoch: [ 0] [1227/1582] time: 1610.0230, d_loss: 0.97093832, g_loss: 0.61748993\n",
      "Epoch: [ 0] [1228/1582] time: 1611.2697, d_loss: 0.90488976, g_loss: 0.66218501\n",
      "Epoch: [ 0] [1229/1582] time: 1612.5156, d_loss: 0.85356921, g_loss: 0.74219871\n",
      "Epoch: [ 0] [1230/1582] time: 1613.7596, d_loss: 0.71479601, g_loss: 0.83681399\n",
      "Epoch: [ 0] [1231/1582] time: 1615.0035, d_loss: 0.76821506, g_loss: 0.92488348\n",
      "Epoch: [ 0] [1232/1582] time: 1616.2505, d_loss: 0.69754064, g_loss: 0.99535203\n",
      "Epoch: [ 0] [1233/1582] time: 1617.4945, d_loss: 0.77920854, g_loss: 0.94447112\n",
      "Epoch: [ 0] [1234/1582] time: 1618.7340, d_loss: 0.79451919, g_loss: 0.88299942\n",
      "Epoch: [ 0] [1235/1582] time: 1619.9789, d_loss: 0.98524636, g_loss: 0.72826445\n",
      "Epoch: [ 0] [1236/1582] time: 1621.2235, d_loss: 1.19004726, g_loss: 0.56683511\n",
      "Epoch: [ 0] [1237/1582] time: 1622.4674, d_loss: 1.25769258, g_loss: 0.45441246\n",
      "Epoch: [ 0] [1238/1582] time: 1623.7114, d_loss: 1.38507414, g_loss: 0.40621486\n",
      "Epoch: [ 0] [1239/1582] time: 1624.9574, d_loss: 1.35895443, g_loss: 0.38491744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [1240/1582] time: 1626.1946, d_loss: 1.38667917, g_loss: 0.40142182\n",
      "Epoch: [ 0] [1241/1582] time: 1627.4405, d_loss: 1.26495337, g_loss: 0.45599630\n",
      "Epoch: [ 0] [1242/1582] time: 1628.6840, d_loss: 1.13480592, g_loss: 0.53321517\n",
      "Epoch: [ 0] [1243/1582] time: 1629.9340, d_loss: 1.09104025, g_loss: 0.62340111\n",
      "Epoch: [ 0] [1244/1582] time: 1631.1820, d_loss: 0.98372918, g_loss: 0.73306000\n",
      "Epoch: [ 0] [1245/1582] time: 1632.4269, d_loss: 0.94702375, g_loss: 0.84279406\n",
      "Epoch: [ 0] [1246/1582] time: 1633.6738, d_loss: 0.68847513, g_loss: 0.94366050\n",
      "Epoch: [ 0] [1247/1582] time: 1634.9158, d_loss: 0.76707518, g_loss: 1.03448117\n",
      "Epoch: [ 0] [1248/1582] time: 1636.1628, d_loss: 0.69868934, g_loss: 1.08171034\n",
      "Epoch: [ 0] [1249/1582] time: 1637.4100, d_loss: 0.66875565, g_loss: 1.12240338\n",
      "Epoch: [ 0] [1250/1582] time: 1638.6571, d_loss: 0.60355663, g_loss: 1.10415554\n",
      "Epoch: [ 0] [1251/1582] time: 1639.9021, d_loss: 0.64354146, g_loss: 1.09469938\n",
      "Epoch: [ 0] [1252/1582] time: 1641.1504, d_loss: 0.68100548, g_loss: 1.04981768\n",
      "Epoch: [ 0] [1253/1582] time: 1642.3944, d_loss: 0.65791470, g_loss: 0.98282677\n",
      "Epoch: [ 0] [1254/1582] time: 1643.6423, d_loss: 0.66465557, g_loss: 0.94251382\n",
      "Epoch: [ 0] [1255/1582] time: 1644.8873, d_loss: 0.68538505, g_loss: 0.89560401\n",
      "Epoch: [ 0] [1256/1582] time: 1646.1323, d_loss: 0.71892715, g_loss: 0.85833812\n",
      "Epoch: [ 0] [1257/1582] time: 1647.3762, d_loss: 0.83684003, g_loss: 0.82871115\n",
      "Epoch: [ 0] [1258/1582] time: 1648.6212, d_loss: 0.72718585, g_loss: 0.79655141\n",
      "Epoch: [ 0] [1259/1582] time: 1649.8651, d_loss: 0.81919968, g_loss: 0.79776889\n",
      "Epoch: [ 0] [1260/1582] time: 1651.1096, d_loss: 0.80145967, g_loss: 0.81600934\n",
      "Epoch: [ 0] [1261/1582] time: 1652.3557, d_loss: 0.81912452, g_loss: 0.84691000\n",
      "Epoch: [ 0] [1262/1582] time: 1653.6027, d_loss: 0.87974447, g_loss: 0.87983274\n",
      "Epoch: [ 0] [1263/1582] time: 1654.8497, d_loss: 0.82413208, g_loss: 0.89685154\n",
      "Epoch: [ 0] [1264/1582] time: 1656.0956, d_loss: 0.85742235, g_loss: 0.91227639\n",
      "Epoch: [ 0] [1265/1582] time: 1657.3426, d_loss: 0.82852912, g_loss: 0.90053368\n",
      "Epoch: [ 0] [1266/1582] time: 1658.5835, d_loss: 0.91950107, g_loss: 0.85681248\n",
      "Epoch: [ 0] [1267/1582] time: 1659.8265, d_loss: 0.82561707, g_loss: 0.80830836\n",
      "Epoch: [ 0] [1268/1582] time: 1661.0745, d_loss: 0.86341792, g_loss: 0.73956370\n",
      "Epoch: [ 0] [1269/1582] time: 1662.3204, d_loss: 0.87586594, g_loss: 0.66864002\n",
      "Epoch: [ 0] [1270/1582] time: 1663.5714, d_loss: 1.02953362, g_loss: 0.56076717\n",
      "Epoch: [ 0] [1271/1582] time: 1664.8253, d_loss: 1.22540855, g_loss: 0.41434842\n",
      "Epoch: [ 0] [1272/1582] time: 1666.0733, d_loss: 1.43212962, g_loss: 0.29985720\n",
      "Epoch: [ 0] [1273/1582] time: 1667.3193, d_loss: 1.54538381, g_loss: 0.25471002\n",
      "Epoch: [ 0] [1274/1582] time: 1668.5652, d_loss: 1.51992404, g_loss: 0.26549771\n",
      "Epoch: [ 0] [1275/1582] time: 1669.8132, d_loss: 1.23394179, g_loss: 0.36824897\n",
      "Epoch: [ 0] [1276/1582] time: 1671.0616, d_loss: 1.03364480, g_loss: 0.52095878\n",
      "Epoch: [ 0] [1277/1582] time: 1672.3066, d_loss: 0.77560604, g_loss: 0.71312916\n",
      "Epoch: [ 0] [1278/1582] time: 1673.5525, d_loss: 0.59259737, g_loss: 0.93820697\n",
      "Epoch: [ 0] [1279/1582] time: 1674.7945, d_loss: 0.55780548, g_loss: 1.10233319\n",
      "Epoch: [ 0] [1280/1582] time: 1676.0405, d_loss: 0.54100859, g_loss: 1.17554009\n",
      "Epoch: [ 0] [1281/1582] time: 1677.2812, d_loss: 0.54750055, g_loss: 1.16736686\n",
      "Epoch: [ 0] [1282/1582] time: 1678.5272, d_loss: 0.52364022, g_loss: 1.09794879\n",
      "Epoch: [ 0] [1283/1582] time: 1679.7705, d_loss: 0.65684921, g_loss: 1.00574875\n",
      "Epoch: [ 0] [1284/1582] time: 1681.0154, d_loss: 0.74294132, g_loss: 0.90397584\n",
      "Epoch: [ 0] [1285/1582] time: 1682.2586, d_loss: 0.79065681, g_loss: 0.76570588\n",
      "Epoch: [ 0] [1286/1582] time: 1683.5055, d_loss: 0.85632610, g_loss: 0.70702654\n",
      "Epoch: [ 0] [1287/1582] time: 1684.7515, d_loss: 1.06071353, g_loss: 0.66136461\n",
      "Epoch: [ 0] [1288/1582] time: 1685.9954, d_loss: 1.07999873, g_loss: 0.62770224\n",
      "Epoch: [ 0] [1289/1582] time: 1687.2394, d_loss: 1.08762574, g_loss: 0.64171112\n",
      "Epoch: [ 0] [1290/1582] time: 1688.4863, d_loss: 1.12676764, g_loss: 0.65658283\n",
      "Epoch: [ 0] [1291/1582] time: 1689.7321, d_loss: 1.08616519, g_loss: 0.68516302\n",
      "Epoch: [ 0] [1292/1582] time: 1690.9790, d_loss: 1.11944580, g_loss: 0.74685520\n",
      "Epoch: [ 0] [1293/1582] time: 1692.2220, d_loss: 1.10972083, g_loss: 0.78342944\n",
      "Epoch: [ 0] [1294/1582] time: 1693.4670, d_loss: 0.95968628, g_loss: 0.84338832\n",
      "Epoch: [ 0] [1295/1582] time: 1694.7099, d_loss: 0.82595092, g_loss: 0.88548303\n",
      "Epoch: [ 0] [1296/1582] time: 1695.9537, d_loss: 0.83613718, g_loss: 0.92589474\n",
      "Epoch: [ 0] [1297/1582] time: 1697.1977, d_loss: 0.79482895, g_loss: 0.93904960\n",
      "Epoch: [ 0] [1298/1582] time: 1698.4367, d_loss: 0.69983482, g_loss: 0.98553646\n",
      "Epoch: [ 0] [1299/1582] time: 1699.6773, d_loss: 0.68384337, g_loss: 1.01016128\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 0] [1300/1582] time: 1707.5567, d_loss: 0.67545307, g_loss: 1.04234946\n",
      "Epoch: [ 0] [1301/1582] time: 1708.8018, d_loss: 0.60970867, g_loss: 1.04567540\n",
      "Epoch: [ 0] [1302/1582] time: 1710.0487, d_loss: 0.60625780, g_loss: 1.06265759\n",
      "Epoch: [ 0] [1303/1582] time: 1711.2927, d_loss: 0.57031918, g_loss: 1.05752289\n",
      "Epoch: [ 0] [1304/1582] time: 1712.5387, d_loss: 0.60305083, g_loss: 1.06580853\n",
      "Epoch: [ 0] [1305/1582] time: 1713.7826, d_loss: 0.54420245, g_loss: 1.03939486\n",
      "Epoch: [ 0] [1306/1582] time: 1715.0306, d_loss: 0.56776023, g_loss: 0.98040068\n",
      "Epoch: [ 0] [1307/1582] time: 1716.2745, d_loss: 0.53388119, g_loss: 0.93254989\n",
      "Epoch: [ 0] [1308/1582] time: 1717.5195, d_loss: 0.62916940, g_loss: 0.85458910\n",
      "Epoch: [ 0] [1309/1582] time: 1718.7634, d_loss: 0.87921870, g_loss: 0.65822935\n",
      "Epoch: [ 0] [1310/1582] time: 1720.0095, d_loss: 1.12107670, g_loss: 0.47903857\n",
      "Epoch: [ 0] [1311/1582] time: 1721.2535, d_loss: 1.47417343, g_loss: 0.36477965\n",
      "Epoch: [ 0] [1312/1582] time: 1722.5014, d_loss: 1.44192207, g_loss: 0.31225950\n",
      "Epoch: [ 0] [1313/1582] time: 1723.7484, d_loss: 1.48618519, g_loss: 0.38055596\n",
      "Epoch: [ 0] [1314/1582] time: 1724.9934, d_loss: 1.13581622, g_loss: 0.58474147\n",
      "Epoch: [ 0] [1315/1582] time: 1726.2397, d_loss: 0.91846806, g_loss: 0.93811321\n",
      "Epoch: [ 0] [1316/1582] time: 1727.4867, d_loss: 0.78222048, g_loss: 1.34909177\n",
      "Epoch: [ 0] [1317/1582] time: 1728.7326, d_loss: 0.69298530, g_loss: 1.61131740\n",
      "Epoch: [ 0] [1318/1582] time: 1729.9776, d_loss: 0.66147059, g_loss: 1.64791739\n",
      "Epoch: [ 0] [1319/1582] time: 1731.2227, d_loss: 0.80999762, g_loss: 1.38010573\n",
      "Epoch: [ 0] [1320/1582] time: 1732.4656, d_loss: 0.88332355, g_loss: 1.01706851\n",
      "Epoch: [ 0] [1321/1582] time: 1733.7111, d_loss: 0.93506324, g_loss: 0.72015208\n",
      "Epoch: [ 0] [1322/1582] time: 1734.9566, d_loss: 1.01541126, g_loss: 0.58638251\n",
      "Epoch: [ 0] [1323/1582] time: 1736.2016, d_loss: 0.99607325, g_loss: 0.55886936\n",
      "Epoch: [ 0] [1324/1582] time: 1737.4495, d_loss: 1.02458215, g_loss: 0.55552673\n",
      "Epoch: [ 0] [1325/1582] time: 1738.6945, d_loss: 0.93067986, g_loss: 0.60541594\n",
      "Epoch: [ 0] [1326/1582] time: 1739.9405, d_loss: 0.95261729, g_loss: 0.61211318\n",
      "Epoch: [ 0] [1327/1582] time: 1741.1864, d_loss: 0.84993362, g_loss: 0.61175412\n",
      "Epoch: [ 0] [1328/1582] time: 1742.4337, d_loss: 0.83528769, g_loss: 0.61954844\n",
      "Epoch: [ 0] [1329/1582] time: 1743.6736, d_loss: 0.90717554, g_loss: 0.63736951\n",
      "Epoch: [ 0] [1330/1582] time: 1744.9216, d_loss: 0.81078124, g_loss: 0.67993188\n",
      "Epoch: [ 0] [1331/1582] time: 1746.1716, d_loss: 0.86644322, g_loss: 0.70907784\n",
      "Epoch: [ 0] [1332/1582] time: 1747.4205, d_loss: 0.70933735, g_loss: 0.82923841\n",
      "Epoch: [ 0] [1333/1582] time: 1748.6665, d_loss: 0.68364346, g_loss: 0.84728342\n",
      "Epoch: [ 0] [1334/1582] time: 1749.9164, d_loss: 0.76561844, g_loss: 0.93499005\n",
      "Epoch: [ 0] [1335/1582] time: 1751.1583, d_loss: 0.73241735, g_loss: 0.92549658\n",
      "Epoch: [ 0] [1336/1582] time: 1752.4043, d_loss: 0.80231714, g_loss: 0.86178672\n",
      "Epoch: [ 0] [1337/1582] time: 1753.6492, d_loss: 0.93480575, g_loss: 0.72608775\n",
      "Epoch: [ 0] [1338/1582] time: 1754.8962, d_loss: 1.00967622, g_loss: 0.66479164\n",
      "Epoch: [ 0] [1339/1582] time: 1756.1421, d_loss: 1.26299453, g_loss: 0.63668621\n",
      "Epoch: [ 0] [1340/1582] time: 1757.3871, d_loss: 1.25967097, g_loss: 0.62795889\n",
      "Epoch: [ 0] [1341/1582] time: 1758.6300, d_loss: 1.20333278, g_loss: 0.68567050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [1342/1582] time: 1759.8740, d_loss: 1.04069066, g_loss: 0.71566969\n",
      "Epoch: [ 0] [1343/1582] time: 1761.1205, d_loss: 1.06308663, g_loss: 0.80408865\n",
      "Epoch: [ 0] [1344/1582] time: 1762.3655, d_loss: 0.90716344, g_loss: 0.83444548\n",
      "Epoch: [ 0] [1345/1582] time: 1763.6104, d_loss: 0.78424859, g_loss: 0.88917708\n",
      "Epoch: [ 0] [1346/1582] time: 1764.8574, d_loss: 0.72036421, g_loss: 0.92990369\n",
      "Epoch: [ 0] [1347/1582] time: 1766.1043, d_loss: 0.70166582, g_loss: 0.96918416\n",
      "Epoch: [ 0] [1348/1582] time: 1767.3513, d_loss: 0.65444940, g_loss: 0.99053162\n",
      "Epoch: [ 0] [1349/1582] time: 1768.5943, d_loss: 0.61487973, g_loss: 0.98678070\n",
      "Epoch: [ 0] [1350/1582] time: 1769.8382, d_loss: 0.60548806, g_loss: 1.00269079\n",
      "Epoch: [ 0] [1351/1582] time: 1771.0822, d_loss: 0.60794121, g_loss: 0.98932600\n",
      "Epoch: [ 0] [1352/1582] time: 1772.3294, d_loss: 0.60355580, g_loss: 0.94648135\n",
      "Epoch: [ 0] [1353/1582] time: 1773.5740, d_loss: 0.66130733, g_loss: 0.90320218\n",
      "Epoch: [ 0] [1354/1582] time: 1774.8172, d_loss: 0.63826472, g_loss: 0.86848962\n",
      "Epoch: [ 0] [1355/1582] time: 1776.0612, d_loss: 0.67518848, g_loss: 0.85768038\n",
      "Epoch: [ 0] [1356/1582] time: 1777.3031, d_loss: 0.68675685, g_loss: 0.86293650\n",
      "Epoch: [ 0] [1357/1582] time: 1778.5472, d_loss: 0.76851875, g_loss: 0.81700683\n",
      "Epoch: [ 0] [1358/1582] time: 1779.7912, d_loss: 0.70499468, g_loss: 0.83137810\n",
      "Epoch: [ 0] [1359/1582] time: 1781.0362, d_loss: 0.68751836, g_loss: 0.84035486\n",
      "Epoch: [ 0] [1360/1582] time: 1782.2811, d_loss: 0.65810680, g_loss: 0.89117944\n",
      "Epoch: [ 0] [1361/1582] time: 1783.5321, d_loss: 0.70301235, g_loss: 0.91918403\n",
      "Epoch: [ 0] [1362/1582] time: 1784.7820, d_loss: 0.66140509, g_loss: 0.94444096\n",
      "Epoch: [ 0] [1363/1582] time: 1786.0290, d_loss: 0.65458536, g_loss: 0.90946382\n",
      "Epoch: [ 0] [1364/1582] time: 1787.2729, d_loss: 0.72288662, g_loss: 0.88110709\n",
      "Epoch: [ 0] [1365/1582] time: 1788.5179, d_loss: 0.84842837, g_loss: 0.83452272\n",
      "Epoch: [ 0] [1366/1582] time: 1789.7619, d_loss: 0.79126620, g_loss: 0.73098922\n",
      "Epoch: [ 0] [1367/1582] time: 1791.0058, d_loss: 0.96445918, g_loss: 0.73580980\n",
      "Epoch: [ 0] [1368/1582] time: 1792.2508, d_loss: 0.86881566, g_loss: 0.72046167\n",
      "Epoch: [ 0] [1369/1582] time: 1793.4937, d_loss: 0.92228663, g_loss: 0.77242452\n",
      "Epoch: [ 0] [1370/1582] time: 1794.7377, d_loss: 0.83583689, g_loss: 0.78424293\n",
      "Epoch: [ 0] [1371/1582] time: 1795.9826, d_loss: 0.75769144, g_loss: 0.88743573\n",
      "Epoch: [ 0] [1372/1582] time: 1797.2285, d_loss: 0.63004279, g_loss: 0.98070693\n",
      "Epoch: [ 0] [1373/1582] time: 1798.4735, d_loss: 0.59948558, g_loss: 1.00496578\n",
      "Epoch: [ 0] [1374/1582] time: 1799.7125, d_loss: 0.57682544, g_loss: 1.00395560\n",
      "Epoch: [ 0] [1375/1582] time: 1800.9584, d_loss: 0.57476723, g_loss: 0.98080146\n",
      "Epoch: [ 0] [1376/1582] time: 1802.2024, d_loss: 0.68192279, g_loss: 0.96477902\n",
      "Epoch: [ 0] [1377/1582] time: 1803.4483, d_loss: 0.61423290, g_loss: 0.91901839\n",
      "Epoch: [ 0] [1378/1582] time: 1804.6948, d_loss: 0.58070785, g_loss: 0.93526137\n",
      "Epoch: [ 0] [1379/1582] time: 1805.9415, d_loss: 0.61474371, g_loss: 0.93826616\n",
      "Epoch: [ 0] [1380/1582] time: 1807.1864, d_loss: 0.63045025, g_loss: 0.93580836\n",
      "Epoch: [ 0] [1381/1582] time: 1808.4304, d_loss: 0.64381987, g_loss: 0.96086264\n",
      "Epoch: [ 0] [1382/1582] time: 1809.6774, d_loss: 0.62321222, g_loss: 0.94521928\n",
      "Epoch: [ 0] [1383/1582] time: 1810.9250, d_loss: 0.62248105, g_loss: 0.93721008\n",
      "Epoch: [ 0] [1384/1582] time: 1812.1759, d_loss: 0.73950434, g_loss: 0.91098326\n",
      "Epoch: [ 0] [1385/1582] time: 1813.4281, d_loss: 0.66903412, g_loss: 0.90853161\n",
      "Epoch: [ 0] [1386/1582] time: 1814.6774, d_loss: 0.77974474, g_loss: 0.89404571\n",
      "Epoch: [ 0] [1387/1582] time: 1815.9226, d_loss: 0.80248415, g_loss: 0.85896713\n",
      "Epoch: [ 0] [1388/1582] time: 1817.1675, d_loss: 0.86998284, g_loss: 0.80833197\n",
      "Epoch: [ 0] [1389/1582] time: 1818.4105, d_loss: 0.86109054, g_loss: 0.77798390\n",
      "Epoch: [ 0] [1390/1582] time: 1819.6554, d_loss: 0.99391800, g_loss: 0.70159107\n",
      "Epoch: [ 0] [1391/1582] time: 1820.9012, d_loss: 1.05944836, g_loss: 0.64355284\n",
      "Epoch: [ 0] [1392/1582] time: 1822.1495, d_loss: 1.07686257, g_loss: 0.60170972\n",
      "Epoch: [ 0] [1393/1582] time: 1823.3944, d_loss: 1.10283864, g_loss: 0.58774024\n",
      "Epoch: [ 0] [1394/1582] time: 1824.6434, d_loss: 1.18521452, g_loss: 0.50827068\n",
      "Epoch: [ 0] [1395/1582] time: 1825.8923, d_loss: 1.05965984, g_loss: 0.51671767\n",
      "Epoch: [ 0] [1396/1582] time: 1827.1443, d_loss: 1.10454249, g_loss: 0.54834640\n",
      "Epoch: [ 0] [1397/1582] time: 1828.4073, d_loss: 1.22162747, g_loss: 0.56185615\n",
      "Epoch: [ 0] [1398/1582] time: 1829.6522, d_loss: 1.01732051, g_loss: 0.62379301\n",
      "Epoch: [ 0] [1399/1582] time: 1830.8992, d_loss: 0.95171666, g_loss: 0.67886913\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 0] [1400/1582] time: 1838.7544, d_loss: 0.82696629, g_loss: 0.78623456\n",
      "Epoch: [ 0] [1401/1582] time: 1839.9994, d_loss: 0.77988434, g_loss: 0.88348514\n",
      "Epoch: [ 0] [1402/1582] time: 1841.2453, d_loss: 0.65050131, g_loss: 1.01788163\n",
      "Epoch: [ 0] [1403/1582] time: 1842.4903, d_loss: 0.68033582, g_loss: 1.14654064\n",
      "Epoch: [ 0] [1404/1582] time: 1843.7319, d_loss: 0.61157966, g_loss: 1.23745644\n",
      "Epoch: [ 0] [1405/1582] time: 1844.9749, d_loss: 0.66515636, g_loss: 1.25804329\n",
      "Epoch: [ 0] [1406/1582] time: 1846.2183, d_loss: 0.57760888, g_loss: 1.28280222\n",
      "Epoch: [ 0] [1407/1582] time: 1847.4595, d_loss: 0.56759989, g_loss: 1.23973691\n",
      "Epoch: [ 0] [1408/1582] time: 1848.7195, d_loss: 0.69689542, g_loss: 1.09051514\n",
      "Epoch: [ 0] [1409/1582] time: 1849.9621, d_loss: 0.91083562, g_loss: 0.84234834\n",
      "Epoch: [ 0] [1410/1582] time: 1851.2039, d_loss: 1.28864241, g_loss: 0.63180190\n",
      "Epoch: [ 0] [1411/1582] time: 1852.4457, d_loss: 1.66890848, g_loss: 0.33490244\n",
      "Epoch: [ 0] [1412/1582] time: 1853.6894, d_loss: 1.80280519, g_loss: 0.30042544\n",
      "Epoch: [ 0] [1413/1582] time: 1854.9343, d_loss: 1.78739715, g_loss: 0.35022816\n",
      "Epoch: [ 0] [1414/1582] time: 1856.1783, d_loss: 1.41593504, g_loss: 0.46790841\n",
      "Epoch: [ 0] [1415/1582] time: 1857.4233, d_loss: 1.22928190, g_loss: 0.66398609\n",
      "Epoch: [ 0] [1416/1582] time: 1858.6672, d_loss: 0.92293918, g_loss: 0.83649397\n",
      "Epoch: [ 0] [1417/1582] time: 1859.9085, d_loss: 0.75427610, g_loss: 1.21864772\n",
      "Epoch: [ 0] [1418/1582] time: 1861.1524, d_loss: 0.86474931, g_loss: 1.43517399\n",
      "Epoch: [ 0] [1419/1582] time: 1862.3974, d_loss: 0.68493891, g_loss: 1.63307106\n",
      "Epoch: [ 0] [1420/1582] time: 1863.6420, d_loss: 0.65687054, g_loss: 1.55618536\n",
      "Epoch: [ 0] [1421/1582] time: 1864.8860, d_loss: 0.65828836, g_loss: 1.40397263\n",
      "Epoch: [ 0] [1422/1582] time: 1866.1309, d_loss: 0.59280229, g_loss: 1.25516272\n",
      "Epoch: [ 0] [1423/1582] time: 1867.3730, d_loss: 0.54823816, g_loss: 1.16235638\n",
      "Epoch: [ 0] [1424/1582] time: 1868.6180, d_loss: 0.51664352, g_loss: 1.17205977\n",
      "Epoch: [ 0] [1425/1582] time: 1869.8649, d_loss: 0.50126225, g_loss: 1.20872688\n",
      "Epoch: [ 0] [1426/1582] time: 1871.1109, d_loss: 0.40961599, g_loss: 1.34325087\n",
      "Epoch: [ 0] [1427/1582] time: 1872.3539, d_loss: 0.35688716, g_loss: 1.46406233\n",
      "Epoch: [ 0] [1428/1582] time: 1873.6008, d_loss: 0.41142380, g_loss: 1.55971694\n",
      "Epoch: [ 0] [1429/1582] time: 1874.8428, d_loss: 0.39849502, g_loss: 1.54350710\n",
      "Epoch: [ 0] [1430/1582] time: 1876.0897, d_loss: 0.50137413, g_loss: 1.41390002\n",
      "Epoch: [ 0] [1431/1582] time: 1877.3337, d_loss: 0.55802453, g_loss: 1.25074005\n",
      "Epoch: [ 0] [1432/1582] time: 1878.5787, d_loss: 0.62174976, g_loss: 1.17021370\n",
      "Epoch: [ 0] [1433/1582] time: 1879.8206, d_loss: 0.71220136, g_loss: 1.03898191\n",
      "Epoch: [ 0] [1434/1582] time: 1881.0666, d_loss: 0.77928942, g_loss: 1.01209414\n",
      "Epoch: [ 0] [1435/1582] time: 1882.3115, d_loss: 0.91506231, g_loss: 1.05148339\n",
      "Epoch: [ 0] [1436/1582] time: 1883.5555, d_loss: 0.90263259, g_loss: 1.06299520\n",
      "Epoch: [ 0] [1437/1582] time: 1884.7985, d_loss: 0.88153088, g_loss: 1.12439680\n",
      "Epoch: [ 0] [1438/1582] time: 1886.0424, d_loss: 0.93922997, g_loss: 1.28244162\n",
      "Epoch: [ 0] [1439/1582] time: 1887.2864, d_loss: 0.98190027, g_loss: 1.08879948\n",
      "Epoch: [ 0] [1440/1582] time: 1888.5303, d_loss: 0.71385312, g_loss: 1.09974885\n",
      "Epoch: [ 0] [1441/1582] time: 1889.7743, d_loss: 0.60035110, g_loss: 1.29848611\n",
      "Epoch: [ 0] [1442/1582] time: 1891.0193, d_loss: 0.53058875, g_loss: 1.65230012\n",
      "Epoch: [ 0] [1443/1582] time: 1892.2632, d_loss: 0.56917143, g_loss: 1.71157670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [1444/1582] time: 1893.5082, d_loss: 0.59413165, g_loss: 1.60733843\n",
      "Epoch: [ 0] [1445/1582] time: 1894.7511, d_loss: 0.60325754, g_loss: 1.44421601\n",
      "Epoch: [ 0] [1446/1582] time: 1895.9981, d_loss: 0.65410572, g_loss: 1.15510023\n",
      "Epoch: [ 0] [1447/1582] time: 1897.2441, d_loss: 0.70485109, g_loss: 0.96344620\n",
      "Epoch: [ 0] [1448/1582] time: 1898.4910, d_loss: 0.77768540, g_loss: 0.77441120\n",
      "Epoch: [ 0] [1449/1582] time: 1899.7380, d_loss: 0.89317477, g_loss: 0.59886348\n",
      "Epoch: [ 0] [1450/1582] time: 1900.9829, d_loss: 1.11346412, g_loss: 0.48550466\n",
      "Epoch: [ 0] [1451/1582] time: 1902.2248, d_loss: 1.19071448, g_loss: 0.39831382\n",
      "Epoch: [ 0] [1452/1582] time: 1903.4688, d_loss: 1.34575438, g_loss: 0.32291228\n",
      "Epoch: [ 0] [1453/1582] time: 1904.7127, d_loss: 1.30230951, g_loss: 0.32228756\n",
      "Epoch: [ 0] [1454/1582] time: 1905.9596, d_loss: 1.33125257, g_loss: 0.39828008\n",
      "Epoch: [ 0] [1455/1582] time: 1907.2020, d_loss: 1.18430710, g_loss: 0.46611375\n",
      "Epoch: [ 0] [1456/1582] time: 1908.4459, d_loss: 0.78388238, g_loss: 0.65173686\n",
      "Epoch: [ 0] [1457/1582] time: 1909.6929, d_loss: 0.59514117, g_loss: 1.01479125\n",
      "Epoch: [ 0] [1458/1582] time: 1910.9399, d_loss: 0.61927217, g_loss: 1.32015061\n",
      "Epoch: [ 0] [1459/1582] time: 1912.1839, d_loss: 0.48754489, g_loss: 1.53031623\n",
      "Epoch: [ 0] [1460/1582] time: 1913.4249, d_loss: 0.44646889, g_loss: 1.69812334\n",
      "Epoch: [ 0] [1461/1582] time: 1914.6678, d_loss: 0.36407414, g_loss: 1.63653874\n",
      "Epoch: [ 0] [1462/1582] time: 1915.9118, d_loss: 0.44555479, g_loss: 1.47979283\n",
      "Epoch: [ 0] [1463/1582] time: 1917.1587, d_loss: 0.61967826, g_loss: 1.21841884\n",
      "Epoch: [ 0] [1464/1582] time: 1918.4057, d_loss: 0.91651928, g_loss: 0.83793235\n",
      "Epoch: [ 0] [1465/1582] time: 1919.6483, d_loss: 0.91262394, g_loss: 0.67039955\n",
      "Epoch: [ 0] [1466/1582] time: 1920.8902, d_loss: 1.10139358, g_loss: 0.53034794\n",
      "Epoch: [ 0] [1467/1582] time: 1922.1342, d_loss: 1.02381825, g_loss: 0.59394944\n",
      "Epoch: [ 0] [1468/1582] time: 1923.3752, d_loss: 0.94439107, g_loss: 0.68695939\n",
      "Epoch: [ 0] [1469/1582] time: 1924.6191, d_loss: 0.82401288, g_loss: 0.80495560\n",
      "Epoch: [ 0] [1470/1582] time: 1925.8611, d_loss: 0.79359233, g_loss: 0.97312677\n",
      "Epoch: [ 0] [1471/1582] time: 1927.1074, d_loss: 0.71893251, g_loss: 1.13947845\n",
      "Epoch: [ 0] [1472/1582] time: 1928.3553, d_loss: 0.63489467, g_loss: 1.42495155\n",
      "Epoch: [ 0] [1473/1582] time: 1929.6002, d_loss: 0.61064494, g_loss: 1.61375558\n",
      "Epoch: [ 0] [1474/1582] time: 1930.8472, d_loss: 0.58329201, g_loss: 1.78010440\n",
      "Epoch: [ 0] [1475/1582] time: 1932.0942, d_loss: 0.61475909, g_loss: 1.78016996\n",
      "Epoch: [ 0] [1476/1582] time: 1933.3391, d_loss: 0.60227716, g_loss: 1.70605183\n",
      "Epoch: [ 0] [1477/1582] time: 1934.5831, d_loss: 0.48051095, g_loss: 1.60256004\n",
      "Epoch: [ 0] [1478/1582] time: 1935.8300, d_loss: 0.47577831, g_loss: 1.65761673\n",
      "Epoch: [ 0] [1479/1582] time: 1937.0760, d_loss: 0.54100406, g_loss: 1.51633632\n",
      "Epoch: [ 0] [1480/1582] time: 1938.3240, d_loss: 0.57464123, g_loss: 1.38046694\n",
      "Epoch: [ 0] [1481/1582] time: 1939.5679, d_loss: 0.68366587, g_loss: 1.16930842\n",
      "Epoch: [ 0] [1482/1582] time: 1940.8147, d_loss: 0.76780534, g_loss: 0.96341497\n",
      "Epoch: [ 0] [1483/1582] time: 1942.0586, d_loss: 0.81249523, g_loss: 0.79981411\n",
      "Epoch: [ 0] [1484/1582] time: 1943.3056, d_loss: 0.84530413, g_loss: 0.66967511\n",
      "Epoch: [ 0] [1485/1582] time: 1944.5507, d_loss: 0.92451692, g_loss: 0.61474431\n",
      "Epoch: [ 0] [1486/1582] time: 1945.7973, d_loss: 0.79064679, g_loss: 0.62639284\n",
      "Epoch: [ 0] [1487/1582] time: 1947.0413, d_loss: 0.84755331, g_loss: 0.63843179\n",
      "Epoch: [ 0] [1488/1582] time: 1948.2882, d_loss: 0.70541668, g_loss: 0.69690353\n",
      "Epoch: [ 0] [1489/1582] time: 1949.5342, d_loss: 0.73422992, g_loss: 0.74038708\n",
      "Epoch: [ 0] [1490/1582] time: 1950.7812, d_loss: 0.71390110, g_loss: 0.79826301\n",
      "Epoch: [ 0] [1491/1582] time: 1952.0271, d_loss: 0.62665880, g_loss: 0.86330426\n",
      "Epoch: [ 0] [1492/1582] time: 1953.2731, d_loss: 0.66933328, g_loss: 0.82684237\n",
      "Epoch: [ 0] [1493/1582] time: 1954.5190, d_loss: 0.64668381, g_loss: 0.85931277\n",
      "Epoch: [ 0] [1494/1582] time: 1955.7690, d_loss: 0.87889415, g_loss: 0.84450543\n",
      "Epoch: [ 0] [1495/1582] time: 1957.0170, d_loss: 0.93556148, g_loss: 0.73263752\n",
      "Epoch: [ 0] [1496/1582] time: 1958.2629, d_loss: 1.00600314, g_loss: 0.67918468\n",
      "Epoch: [ 0] [1497/1582] time: 1959.5079, d_loss: 0.86793625, g_loss: 0.67607379\n",
      "Epoch: [ 0] [1498/1582] time: 1960.7528, d_loss: 0.75950480, g_loss: 0.85396206\n",
      "Epoch: [ 0] [1499/1582] time: 1961.9958, d_loss: 0.61513817, g_loss: 1.13257599\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 0] [1500/1582] time: 1969.9091, d_loss: 0.78927165, g_loss: 1.28416443\n",
      "Epoch: [ 0] [1501/1582] time: 1971.1571, d_loss: 0.72897011, g_loss: 1.34209704\n",
      "Epoch: [ 0] [1502/1582] time: 1972.4060, d_loss: 0.85199821, g_loss: 1.21286869\n",
      "Epoch: [ 0] [1503/1582] time: 1973.6560, d_loss: 0.81153595, g_loss: 1.02528560\n",
      "Epoch: [ 0] [1504/1582] time: 1974.9059, d_loss: 0.84223664, g_loss: 0.83600140\n",
      "Epoch: [ 0] [1505/1582] time: 1976.1549, d_loss: 0.94295692, g_loss: 0.61717546\n",
      "Epoch: [ 0] [1506/1582] time: 1977.4029, d_loss: 0.91590965, g_loss: 0.54345769\n",
      "Epoch: [ 0] [1507/1582] time: 1978.6518, d_loss: 0.99612254, g_loss: 0.49172941\n",
      "Epoch: [ 0] [1508/1582] time: 1979.8988, d_loss: 0.99753928, g_loss: 0.49938008\n",
      "Epoch: [ 0] [1509/1582] time: 1981.1458, d_loss: 0.84778267, g_loss: 0.58470339\n",
      "Epoch: [ 0] [1510/1582] time: 1982.3927, d_loss: 0.73642063, g_loss: 0.74479365\n",
      "Epoch: [ 0] [1511/1582] time: 1983.6387, d_loss: 0.59052700, g_loss: 0.95031720\n",
      "Epoch: [ 0] [1512/1582] time: 1984.8836, d_loss: 0.51607138, g_loss: 1.12464273\n",
      "Epoch: [ 0] [1513/1582] time: 1986.1316, d_loss: 0.52824068, g_loss: 1.26132655\n",
      "Epoch: [ 0] [1514/1582] time: 1987.3776, d_loss: 0.39356756, g_loss: 1.37683249\n",
      "Epoch: [ 0] [1515/1582] time: 1988.6235, d_loss: 0.46996480, g_loss: 1.41614377\n",
      "Epoch: [ 0] [1516/1582] time: 1989.8755, d_loss: 0.39614707, g_loss: 1.43825221\n",
      "Epoch: [ 0] [1517/1582] time: 1991.1214, d_loss: 0.38573033, g_loss: 1.44829392\n",
      "Epoch: [ 0] [1518/1582] time: 1992.3694, d_loss: 0.37250566, g_loss: 1.45221877\n",
      "Epoch: [ 0] [1519/1582] time: 1993.6184, d_loss: 0.42754757, g_loss: 1.42911661\n",
      "Epoch: [ 0] [1520/1582] time: 1994.8643, d_loss: 0.42743397, g_loss: 1.34764123\n",
      "Epoch: [ 0] [1521/1582] time: 1996.1083, d_loss: 0.41942519, g_loss: 1.28975964\n",
      "Epoch: [ 0] [1522/1582] time: 1997.3532, d_loss: 0.43184265, g_loss: 1.33396566\n",
      "Epoch: [ 0] [1523/1582] time: 1998.5972, d_loss: 0.50955421, g_loss: 1.29581022\n",
      "Epoch: [ 0] [1524/1582] time: 1999.8452, d_loss: 0.58806419, g_loss: 1.26864862\n",
      "Epoch: [ 0] [1525/1582] time: 2001.0891, d_loss: 0.63171911, g_loss: 1.16834593\n",
      "Epoch: [ 0] [1526/1582] time: 2002.3351, d_loss: 0.63000071, g_loss: 1.15333998\n",
      "Epoch: [ 0] [1527/1582] time: 2003.5810, d_loss: 0.82961464, g_loss: 1.00161028\n",
      "Epoch: [ 0] [1528/1582] time: 2004.8280, d_loss: 0.93820846, g_loss: 0.88553888\n",
      "Epoch: [ 0] [1529/1582] time: 2006.0749, d_loss: 0.83241737, g_loss: 0.81715006\n",
      "Epoch: [ 0] [1530/1582] time: 2007.3209, d_loss: 0.78707772, g_loss: 0.81926930\n",
      "Epoch: [ 0] [1531/1582] time: 2008.5669, d_loss: 0.82914066, g_loss: 0.80477989\n",
      "Epoch: [ 0] [1532/1582] time: 2009.8128, d_loss: 0.75648057, g_loss: 0.78197372\n",
      "Epoch: [ 0] [1533/1582] time: 2011.0608, d_loss: 0.70144767, g_loss: 0.82322514\n",
      "Epoch: [ 0] [1534/1582] time: 2012.3095, d_loss: 0.62480462, g_loss: 0.92940485\n",
      "Epoch: [ 0] [1535/1582] time: 2013.5585, d_loss: 0.52945429, g_loss: 1.05098176\n",
      "Epoch: [ 0] [1536/1582] time: 2014.8055, d_loss: 0.48296237, g_loss: 1.24343884\n",
      "Epoch: [ 0] [1537/1582] time: 2016.0504, d_loss: 0.44353181, g_loss: 1.42551589\n",
      "Epoch: [ 0] [1538/1582] time: 2017.2964, d_loss: 0.41866225, g_loss: 1.53540373\n",
      "Epoch: [ 0] [1539/1582] time: 2018.5443, d_loss: 0.38166386, g_loss: 1.56055760\n",
      "Epoch: [ 0] [1540/1582] time: 2019.7918, d_loss: 0.38417438, g_loss: 1.56989396\n",
      "Epoch: [ 0] [1541/1582] time: 2021.0387, d_loss: 0.34483331, g_loss: 1.59120679\n",
      "Epoch: [ 0] [1542/1582] time: 2022.2847, d_loss: 0.32760635, g_loss: 1.64716339\n",
      "Epoch: [ 0] [1543/1582] time: 2023.5287, d_loss: 0.35460162, g_loss: 1.65960538\n",
      "Epoch: [ 0] [1544/1582] time: 2024.7746, d_loss: 0.31327266, g_loss: 1.65868783\n",
      "Epoch: [ 0] [1545/1582] time: 2026.0171, d_loss: 0.30605000, g_loss: 1.62830055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [1546/1582] time: 2027.2581, d_loss: 0.33715779, g_loss: 1.58367848\n",
      "Epoch: [ 0] [1547/1582] time: 2028.5020, d_loss: 0.39006150, g_loss: 1.50122380\n",
      "Epoch: [ 0] [1548/1582] time: 2029.7460, d_loss: 0.37509182, g_loss: 1.43091464\n",
      "Epoch: [ 0] [1549/1582] time: 2030.9921, d_loss: 0.44064382, g_loss: 1.32504380\n",
      "Epoch: [ 0] [1550/1582] time: 2032.2351, d_loss: 0.52775908, g_loss: 1.26114345\n",
      "Epoch: [ 0] [1551/1582] time: 2033.4800, d_loss: 0.51768756, g_loss: 1.23061848\n",
      "Epoch: [ 0] [1552/1582] time: 2034.7250, d_loss: 0.63728553, g_loss: 1.13159657\n",
      "Epoch: [ 0] [1553/1582] time: 2035.9699, d_loss: 0.66755295, g_loss: 1.05140996\n",
      "Epoch: [ 0] [1554/1582] time: 2037.2151, d_loss: 0.64503872, g_loss: 1.10621190\n",
      "Epoch: [ 0] [1555/1582] time: 2038.4591, d_loss: 0.43263555, g_loss: 1.29031646\n",
      "Epoch: [ 0] [1556/1582] time: 2039.7040, d_loss: 0.67610329, g_loss: 1.35213256\n",
      "Epoch: [ 0] [1557/1582] time: 2040.9490, d_loss: 0.48476207, g_loss: 1.46577311\n",
      "Epoch: [ 0] [1558/1582] time: 2042.1937, d_loss: 0.46925008, g_loss: 1.64678669\n",
      "Epoch: [ 0] [1559/1582] time: 2043.4357, d_loss: 0.31291425, g_loss: 1.77840757\n",
      "Epoch: [ 0] [1560/1582] time: 2044.6807, d_loss: 0.36761957, g_loss: 1.83904791\n",
      "Epoch: [ 0] [1561/1582] time: 2045.9256, d_loss: 0.30835533, g_loss: 1.82746291\n",
      "Epoch: [ 0] [1562/1582] time: 2047.1716, d_loss: 0.28575200, g_loss: 1.77774429\n",
      "Epoch: [ 0] [1563/1582] time: 2048.4186, d_loss: 0.40628687, g_loss: 1.61888599\n",
      "Epoch: [ 0] [1564/1582] time: 2049.6635, d_loss: 0.36900407, g_loss: 1.43676567\n",
      "Epoch: [ 0] [1565/1582] time: 2050.9075, d_loss: 0.49576032, g_loss: 1.33127987\n",
      "Epoch: [ 0] [1566/1582] time: 2052.1514, d_loss: 0.51842684, g_loss: 1.18268824\n",
      "Epoch: [ 0] [1567/1582] time: 2053.3924, d_loss: 0.67366511, g_loss: 1.12534320\n",
      "Epoch: [ 0] [1568/1582] time: 2054.6374, d_loss: 0.89487880, g_loss: 0.99080694\n",
      "Epoch: [ 0] [1569/1582] time: 2055.8813, d_loss: 1.01068521, g_loss: 0.87224948\n",
      "Epoch: [ 0] [1570/1582] time: 2057.1263, d_loss: 1.23466778, g_loss: 0.65052986\n",
      "Epoch: [ 0] [1571/1582] time: 2058.3672, d_loss: 1.27460063, g_loss: 0.49576515\n",
      "Epoch: [ 0] [1572/1582] time: 2059.6092, d_loss: 1.36388397, g_loss: 0.39535636\n",
      "Epoch: [ 0] [1573/1582] time: 2060.8552, d_loss: 1.32726264, g_loss: 0.36476937\n",
      "Epoch: [ 0] [1574/1582] time: 2062.1011, d_loss: 1.08265924, g_loss: 0.42042512\n",
      "Epoch: [ 0] [1575/1582] time: 2063.3441, d_loss: 0.87552679, g_loss: 0.53570545\n",
      "Epoch: [ 0] [1576/1582] time: 2064.5870, d_loss: 0.75897890, g_loss: 0.72399920\n",
      "Epoch: [ 0] [1577/1582] time: 2065.8330, d_loss: 0.70714432, g_loss: 0.85352755\n",
      "Epoch: [ 0] [1578/1582] time: 2067.0769, d_loss: 0.57775718, g_loss: 0.93233454\n",
      "Epoch: [ 0] [1579/1582] time: 2068.3199, d_loss: 0.56515431, g_loss: 1.00699830\n",
      "Epoch: [ 0] [1580/1582] time: 2069.5809, d_loss: 0.59870046, g_loss: 0.94695860\n",
      "Epoch: [ 0] [1581/1582] time: 2070.8288, d_loss: 0.67221528, g_loss: 0.87542009\n",
      "Epoch: [ 1] [   0/1582] time: 2072.0748, d_loss: 0.60600924, g_loss: 0.86786628\n",
      "Epoch: [ 1] [   1/1582] time: 2073.3188, d_loss: 0.66354024, g_loss: 0.87689573\n",
      "Epoch: [ 1] [   2/1582] time: 2074.5597, d_loss: 0.71620929, g_loss: 0.81803000\n",
      "Epoch: [ 1] [   3/1582] time: 2075.8017, d_loss: 0.58881527, g_loss: 0.93068868\n",
      "Epoch: [ 1] [   4/1582] time: 2077.0456, d_loss: 0.61411524, g_loss: 1.05480587\n",
      "Epoch: [ 1] [   5/1582] time: 2078.2896, d_loss: 0.49135834, g_loss: 1.19902813\n",
      "Epoch: [ 1] [   6/1582] time: 2079.5325, d_loss: 0.44265342, g_loss: 1.46816850\n",
      "Epoch: [ 1] [   7/1582] time: 2080.7765, d_loss: 0.31356636, g_loss: 1.78154898\n",
      "Epoch: [ 1] [   8/1582] time: 2082.0205, d_loss: 0.31425792, g_loss: 1.89335561\n",
      "Epoch: [ 1] [   9/1582] time: 2083.2644, d_loss: 0.41031671, g_loss: 1.71544528\n",
      "Epoch: [ 1] [  10/1582] time: 2084.5094, d_loss: 0.59690136, g_loss: 1.35469794\n",
      "Epoch: [ 1] [  11/1582] time: 2085.7544, d_loss: 0.91915548, g_loss: 0.86568707\n",
      "Epoch: [ 1] [  12/1582] time: 2087.0013, d_loss: 1.62995410, g_loss: 0.46386719\n",
      "Epoch: [ 1] [  13/1582] time: 2088.2450, d_loss: 1.66882229, g_loss: 0.44269294\n",
      "Epoch: [ 1] [  14/1582] time: 2089.4930, d_loss: 1.36169338, g_loss: 0.53753293\n",
      "Epoch: [ 1] [  15/1582] time: 2090.7360, d_loss: 1.11532247, g_loss: 0.75935936\n",
      "Epoch: [ 1] [  16/1582] time: 2091.9800, d_loss: 1.04144549, g_loss: 1.01483405\n",
      "Epoch: [ 1] [  17/1582] time: 2093.2244, d_loss: 0.70212978, g_loss: 1.17155790\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 1] [  18/1582] time: 2101.3112, d_loss: 0.62570006, g_loss: 1.19194496\n",
      "Epoch: [ 1] [  19/1582] time: 2102.5502, d_loss: 0.38704666, g_loss: 1.33997774\n",
      "Epoch: [ 1] [  20/1582] time: 2103.7957, d_loss: 0.29546970, g_loss: 1.54239905\n",
      "Epoch: [ 1] [  21/1582] time: 2105.0426, d_loss: 0.38475096, g_loss: 1.69607925\n",
      "Epoch: [ 1] [  22/1582] time: 2106.2876, d_loss: 0.28356501, g_loss: 1.74094129\n",
      "Epoch: [ 1] [  23/1582] time: 2107.5326, d_loss: 0.23336342, g_loss: 2.08708715\n",
      "Epoch: [ 1] [  24/1582] time: 2108.7795, d_loss: 0.32936195, g_loss: 2.38816428\n",
      "Epoch: [ 1] [  25/1582] time: 2110.0306, d_loss: 0.23817046, g_loss: 2.78051209\n",
      "Epoch: [ 1] [  26/1582] time: 2111.2736, d_loss: 0.38911811, g_loss: 3.02050877\n",
      "Epoch: [ 1] [  27/1582] time: 2112.5156, d_loss: 0.30112654, g_loss: 3.23421359\n",
      "Epoch: [ 1] [  28/1582] time: 2113.7595, d_loss: 0.37621516, g_loss: 3.54342794\n",
      "Epoch: [ 1] [  29/1582] time: 2115.0045, d_loss: 0.30993080, g_loss: 4.14583397\n",
      "Epoch: [ 1] [  30/1582] time: 2116.2474, d_loss: 0.44309250, g_loss: 4.58636951\n",
      "Epoch: [ 1] [  31/1582] time: 2117.4924, d_loss: 0.38622525, g_loss: 4.52583313\n",
      "Epoch: [ 1] [  32/1582] time: 2118.7414, d_loss: 0.40393537, g_loss: 4.75685453\n",
      "Epoch: [ 1] [  33/1582] time: 2119.9893, d_loss: 0.41081813, g_loss: 4.82385874\n",
      "Epoch: [ 1] [  34/1582] time: 2121.2333, d_loss: 0.36628374, g_loss: 4.82516336\n",
      "Epoch: [ 1] [  35/1582] time: 2122.4782, d_loss: 0.34330931, g_loss: 4.69571161\n",
      "Epoch: [ 1] [  36/1582] time: 2123.7242, d_loss: 0.42557269, g_loss: 4.56795168\n",
      "Epoch: [ 1] [  37/1582] time: 2124.9702, d_loss: 0.32135776, g_loss: 4.43085384\n",
      "Epoch: [ 1] [  38/1582] time: 2126.2206, d_loss: 0.36717582, g_loss: 4.16081715\n",
      "Epoch: [ 1] [  39/1582] time: 2127.4636, d_loss: 0.34992206, g_loss: 3.94350171\n",
      "Epoch: [ 1] [  40/1582] time: 2128.7125, d_loss: 0.39582765, g_loss: 3.74244404\n",
      "Epoch: [ 1] [  41/1582] time: 2129.9615, d_loss: 0.43072399, g_loss: 3.76500750\n",
      "Epoch: [ 1] [  42/1582] time: 2131.2072, d_loss: 0.41509947, g_loss: 3.50201821\n",
      "Epoch: [ 1] [  43/1582] time: 2132.4511, d_loss: 0.48654449, g_loss: 3.21656656\n",
      "Epoch: [ 1] [  44/1582] time: 2133.6941, d_loss: 0.53390437, g_loss: 2.60555196\n",
      "Epoch: [ 1] [  45/1582] time: 2134.9381, d_loss: 0.41933489, g_loss: 2.22550201\n",
      "Epoch: [ 1] [  46/1582] time: 2136.1820, d_loss: 0.29963833, g_loss: 2.34900665\n",
      "Epoch: [ 1] [  47/1582] time: 2137.4270, d_loss: 0.44943705, g_loss: 2.38780212\n",
      "Epoch: [ 1] [  48/1582] time: 2138.6720, d_loss: 0.37636089, g_loss: 2.51829553\n",
      "Epoch: [ 1] [  49/1582] time: 2139.9162, d_loss: 0.44687271, g_loss: 2.22115135\n",
      "Epoch: [ 1] [  50/1582] time: 2141.1631, d_loss: 0.40202326, g_loss: 1.92213917\n",
      "Epoch: [ 1] [  51/1582] time: 2142.4081, d_loss: 0.32149541, g_loss: 1.73546529\n",
      "Epoch: [ 1] [  52/1582] time: 2143.6551, d_loss: 0.30660272, g_loss: 1.75583339\n",
      "Epoch: [ 1] [  53/1582] time: 2144.8980, d_loss: 0.30611044, g_loss: 1.90523136\n",
      "Epoch: [ 1] [  54/1582] time: 2146.1430, d_loss: 0.43134090, g_loss: 1.93692207\n",
      "Epoch: [ 1] [  55/1582] time: 2147.3889, d_loss: 0.40028614, g_loss: 1.88503706\n",
      "Epoch: [ 1] [  56/1582] time: 2148.6359, d_loss: 0.37751946, g_loss: 1.68576729\n",
      "Epoch: [ 1] [  57/1582] time: 2149.8819, d_loss: 0.43485481, g_loss: 1.56765962\n",
      "Epoch: [ 1] [  58/1582] time: 2151.1288, d_loss: 0.32997629, g_loss: 1.48480129\n",
      "Epoch: [ 1] [  59/1582] time: 2152.3728, d_loss: 0.51002848, g_loss: 1.38067853\n",
      "Epoch: [ 1] [  60/1582] time: 2153.6167, d_loss: 0.50385773, g_loss: 1.29889035\n",
      "Epoch: [ 1] [  61/1582] time: 2154.8627, d_loss: 0.63820374, g_loss: 1.15352321\n",
      "Epoch: [ 1] [  62/1582] time: 2156.1106, d_loss: 0.66881633, g_loss: 1.05017340\n",
      "Epoch: [ 1] [  63/1582] time: 2157.3536, d_loss: 0.60105371, g_loss: 0.98622155\n",
      "Epoch: [ 1] [  64/1582] time: 2158.5996, d_loss: 0.63899398, g_loss: 0.99334902\n",
      "Epoch: [ 1] [  65/1582] time: 2159.8445, d_loss: 0.62475753, g_loss: 1.09969819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1] [  66/1582] time: 2161.0925, d_loss: 0.66627926, g_loss: 1.11345065\n",
      "Epoch: [ 1] [  67/1582] time: 2162.3365, d_loss: 0.50581533, g_loss: 1.23284400\n",
      "Epoch: [ 1] [  68/1582] time: 2163.5814, d_loss: 0.56185144, g_loss: 1.26041448\n",
      "Epoch: [ 1] [  69/1582] time: 2164.8284, d_loss: 0.49514189, g_loss: 1.37444317\n",
      "Epoch: [ 1] [  70/1582] time: 2166.0753, d_loss: 0.47913575, g_loss: 1.58327460\n",
      "Epoch: [ 1] [  71/1582] time: 2167.3187, d_loss: 0.51624680, g_loss: 1.55606365\n",
      "Epoch: [ 1] [  72/1582] time: 2168.5626, d_loss: 0.44433084, g_loss: 1.51977682\n",
      "Epoch: [ 1] [  73/1582] time: 2169.8120, d_loss: 0.53332943, g_loss: 1.51087677\n",
      "Epoch: [ 1] [  74/1582] time: 2171.0590, d_loss: 0.57028472, g_loss: 1.40361512\n",
      "Epoch: [ 1] [  75/1582] time: 2172.3030, d_loss: 0.66745055, g_loss: 1.15025449\n",
      "Epoch: [ 1] [  76/1582] time: 2173.5479, d_loss: 0.58847463, g_loss: 1.14727390\n",
      "Epoch: [ 1] [  77/1582] time: 2174.7930, d_loss: 0.50387871, g_loss: 1.16821837\n",
      "Epoch: [ 1] [  78/1582] time: 2176.0379, d_loss: 0.50169289, g_loss: 1.32914829\n",
      "Epoch: [ 1] [  79/1582] time: 2177.2829, d_loss: 0.49640995, g_loss: 1.41280818\n",
      "Epoch: [ 1] [  80/1582] time: 2178.5269, d_loss: 0.57933307, g_loss: 1.41434133\n",
      "Epoch: [ 1] [  81/1582] time: 2179.7718, d_loss: 0.48051763, g_loss: 1.39388871\n",
      "Epoch: [ 1] [  82/1582] time: 2181.0178, d_loss: 0.47842973, g_loss: 1.32829225\n",
      "Epoch: [ 1] [  83/1582] time: 2182.2617, d_loss: 0.61300147, g_loss: 1.21367359\n",
      "Epoch: [ 1] [  84/1582] time: 2183.5057, d_loss: 0.63604367, g_loss: 1.04236889\n",
      "Epoch: [ 1] [  85/1582] time: 2184.7517, d_loss: 0.74511868, g_loss: 0.84609705\n",
      "Epoch: [ 1] [  86/1582] time: 2185.9956, d_loss: 0.68916851, g_loss: 0.75797522\n",
      "Epoch: [ 1] [  87/1582] time: 2187.2396, d_loss: 0.77385557, g_loss: 0.72880423\n",
      "Epoch: [ 1] [  88/1582] time: 2188.4856, d_loss: 0.72608507, g_loss: 0.70202780\n",
      "Epoch: [ 1] [  89/1582] time: 2189.7295, d_loss: 0.78791118, g_loss: 0.70217210\n",
      "Epoch: [ 1] [  90/1582] time: 2190.9745, d_loss: 0.84722227, g_loss: 0.65315568\n",
      "Epoch: [ 1] [  91/1582] time: 2192.2174, d_loss: 0.93392313, g_loss: 0.60681367\n",
      "Epoch: [ 1] [  92/1582] time: 2193.4614, d_loss: 0.89353949, g_loss: 0.53636277\n",
      "Epoch: [ 1] [  93/1582] time: 2194.7064, d_loss: 0.99035144, g_loss: 0.47328156\n",
      "Epoch: [ 1] [  94/1582] time: 2195.9493, d_loss: 1.11464763, g_loss: 0.41515726\n",
      "Epoch: [ 1] [  95/1582] time: 2197.1915, d_loss: 1.31843805, g_loss: 0.34123510\n",
      "Epoch: [ 1] [  96/1582] time: 2198.4344, d_loss: 1.38858259, g_loss: 0.31359911\n",
      "Epoch: [ 1] [  97/1582] time: 2199.6794, d_loss: 1.40581644, g_loss: 0.32563162\n",
      "Epoch: [ 1] [  98/1582] time: 2200.9223, d_loss: 1.42090070, g_loss: 0.37035608\n",
      "Epoch: [ 1] [  99/1582] time: 2202.1653, d_loss: 1.42691958, g_loss: 0.39430344\n",
      "Epoch: [ 1] [ 100/1582] time: 2203.4083, d_loss: 1.22974622, g_loss: 0.46477756\n",
      "Epoch: [ 1] [ 101/1582] time: 2204.6523, d_loss: 1.17184567, g_loss: 0.53856546\n",
      "Epoch: [ 1] [ 102/1582] time: 2205.8962, d_loss: 0.83465189, g_loss: 0.69260204\n",
      "Epoch: [ 1] [ 103/1582] time: 2207.1412, d_loss: 0.69511127, g_loss: 0.94147956\n",
      "Epoch: [ 1] [ 104/1582] time: 2208.3845, d_loss: 0.39880732, g_loss: 1.38025999\n",
      "Epoch: [ 1] [ 105/1582] time: 2209.6305, d_loss: 0.29950887, g_loss: 1.94113719\n",
      "Epoch: [ 1] [ 106/1582] time: 2210.8754, d_loss: 0.38411450, g_loss: 2.15160036\n",
      "Epoch: [ 1] [ 107/1582] time: 2212.1194, d_loss: 0.33045554, g_loss: 2.11648703\n",
      "Epoch: [ 1] [ 108/1582] time: 2213.3630, d_loss: 0.30342996, g_loss: 1.84756029\n",
      "Epoch: [ 1] [ 109/1582] time: 2214.6070, d_loss: 0.43324509, g_loss: 1.35336661\n",
      "Epoch: [ 1] [ 110/1582] time: 2215.8540, d_loss: 0.74977744, g_loss: 0.87925828\n",
      "Epoch: [ 1] [ 111/1582] time: 2217.1009, d_loss: 0.91983569, g_loss: 0.56419307\n",
      "Epoch: [ 1] [ 112/1582] time: 2218.3469, d_loss: 1.15894616, g_loss: 0.42753571\n",
      "Epoch: [ 1] [ 113/1582] time: 2219.5899, d_loss: 1.25866294, g_loss: 0.38293135\n",
      "Epoch: [ 1] [ 114/1582] time: 2220.8371, d_loss: 1.20389354, g_loss: 0.39381957\n",
      "Epoch: [ 1] [ 115/1582] time: 2222.0841, d_loss: 1.01005912, g_loss: 0.47103789\n",
      "Epoch: [ 1] [ 116/1582] time: 2223.3280, d_loss: 1.10455191, g_loss: 0.55544829\n",
      "Epoch: [ 1] [ 117/1582] time: 2224.5719, d_loss: 0.97336304, g_loss: 0.64452749\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 1] [ 118/1582] time: 2232.4229, d_loss: 0.85294795, g_loss: 0.72888839\n",
      "Epoch: [ 1] [ 119/1582] time: 2233.6600, d_loss: 0.83349115, g_loss: 0.79409504\n",
      "Epoch: [ 1] [ 120/1582] time: 2234.9040, d_loss: 0.66192007, g_loss: 0.87219024\n",
      "Epoch: [ 1] [ 121/1582] time: 2236.1489, d_loss: 0.62747794, g_loss: 0.97436267\n",
      "Epoch: [ 1] [ 122/1582] time: 2237.3959, d_loss: 0.56503689, g_loss: 1.05087304\n",
      "Epoch: [ 1] [ 123/1582] time: 2238.6408, d_loss: 0.45893401, g_loss: 1.11628449\n",
      "Epoch: [ 1] [ 124/1582] time: 2239.8868, d_loss: 0.47608066, g_loss: 1.18748617\n",
      "Epoch: [ 1] [ 125/1582] time: 2241.1338, d_loss: 0.51068366, g_loss: 1.20424819\n",
      "Epoch: [ 1] [ 126/1582] time: 2242.3807, d_loss: 0.56447196, g_loss: 1.13955641\n",
      "Epoch: [ 1] [ 127/1582] time: 2243.6277, d_loss: 0.56466758, g_loss: 1.03328621\n",
      "Epoch: [ 1] [ 128/1582] time: 2244.8736, d_loss: 0.59069037, g_loss: 0.97406244\n",
      "Epoch: [ 1] [ 129/1582] time: 2246.1176, d_loss: 0.60553932, g_loss: 0.91626549\n",
      "Epoch: [ 1] [ 130/1582] time: 2247.3616, d_loss: 0.59841478, g_loss: 0.95331550\n",
      "Epoch: [ 1] [ 131/1582] time: 2248.6046, d_loss: 0.60474008, g_loss: 0.90493596\n",
      "Epoch: [ 1] [ 132/1582] time: 2249.8485, d_loss: 0.64658439, g_loss: 0.95129478\n",
      "Epoch: [ 1] [ 133/1582] time: 2251.0855, d_loss: 0.69025183, g_loss: 0.90542930\n",
      "Epoch: [ 1] [ 134/1582] time: 2252.3294, d_loss: 0.69038868, g_loss: 0.90047640\n",
      "Epoch: [ 1] [ 135/1582] time: 2253.5714, d_loss: 0.76866567, g_loss: 0.87107527\n",
      "Epoch: [ 1] [ 136/1582] time: 2254.8184, d_loss: 0.72122306, g_loss: 0.80161393\n",
      "Epoch: [ 1] [ 137/1582] time: 2256.0604, d_loss: 0.84548795, g_loss: 0.74116594\n",
      "Epoch: [ 1] [ 138/1582] time: 2257.3058, d_loss: 0.89040691, g_loss: 0.65173304\n",
      "Epoch: [ 1] [ 139/1582] time: 2258.5464, d_loss: 0.85925668, g_loss: 0.64458430\n",
      "Epoch: [ 1] [ 140/1582] time: 2259.7904, d_loss: 0.96211362, g_loss: 0.62135601\n",
      "Epoch: [ 1] [ 141/1582] time: 2261.0353, d_loss: 0.81553447, g_loss: 0.64748299\n",
      "Epoch: [ 1] [ 142/1582] time: 2262.2793, d_loss: 0.78771079, g_loss: 0.70365340\n",
      "Epoch: [ 1] [ 143/1582] time: 2263.5242, d_loss: 0.75139678, g_loss: 0.78249043\n",
      "Epoch: [ 1] [ 144/1582] time: 2264.7712, d_loss: 0.70638192, g_loss: 0.82753479\n",
      "Epoch: [ 1] [ 145/1582] time: 2266.0162, d_loss: 0.56113958, g_loss: 0.92842460\n",
      "Epoch: [ 1] [ 146/1582] time: 2267.2621, d_loss: 0.60610902, g_loss: 0.95878541\n",
      "Epoch: [ 1] [ 147/1582] time: 2268.5034, d_loss: 0.52365130, g_loss: 0.99813825\n",
      "Epoch: [ 1] [ 148/1582] time: 2269.7493, d_loss: 0.45216358, g_loss: 1.06292975\n",
      "Epoch: [ 1] [ 149/1582] time: 2270.9913, d_loss: 0.42247355, g_loss: 1.15622735\n",
      "Epoch: [ 1] [ 150/1582] time: 2272.2363, d_loss: 0.44003707, g_loss: 1.21213436\n",
      "Epoch: [ 1] [ 151/1582] time: 2273.4802, d_loss: 0.43092850, g_loss: 1.17631483\n",
      "Epoch: [ 1] [ 152/1582] time: 2274.7262, d_loss: 0.39841330, g_loss: 1.18544269\n",
      "Epoch: [ 1] [ 153/1582] time: 2275.9741, d_loss: 0.46267077, g_loss: 1.11715472\n",
      "Epoch: [ 1] [ 154/1582] time: 2277.2201, d_loss: 0.53132343, g_loss: 1.05693340\n",
      "Epoch: [ 1] [ 155/1582] time: 2278.4637, d_loss: 0.73906809, g_loss: 0.82913768\n",
      "Epoch: [ 1] [ 156/1582] time: 2279.7097, d_loss: 0.76001734, g_loss: 0.69742221\n",
      "Epoch: [ 1] [ 157/1582] time: 2280.9566, d_loss: 0.85043848, g_loss: 0.65286326\n",
      "Epoch: [ 1] [ 158/1582] time: 2282.2017, d_loss: 0.88646740, g_loss: 0.68403482\n",
      "Epoch: [ 1] [ 159/1582] time: 2283.4457, d_loss: 0.94613707, g_loss: 0.68190980\n",
      "Epoch: [ 1] [ 160/1582] time: 2284.6897, d_loss: 1.18310189, g_loss: 0.59097409\n",
      "Epoch: [ 1] [ 161/1582] time: 2285.9346, d_loss: 1.35917377, g_loss: 0.44005322\n",
      "Epoch: [ 1] [ 162/1582] time: 2287.1825, d_loss: 1.35629082, g_loss: 0.38848150\n",
      "Epoch: [ 1] [ 163/1582] time: 2288.4264, d_loss: 1.43330550, g_loss: 0.33640602\n",
      "Epoch: [ 1] [ 164/1582] time: 2289.6724, d_loss: 1.27281916, g_loss: 0.35345477\n",
      "Epoch: [ 1] [ 165/1582] time: 2290.9173, d_loss: 1.10077083, g_loss: 0.45225468\n",
      "Epoch: [ 1] [ 166/1582] time: 2292.1593, d_loss: 1.00994372, g_loss: 0.53646612\n",
      "Epoch: [ 1] [ 167/1582] time: 2293.4073, d_loss: 0.79038322, g_loss: 0.65682578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1] [ 168/1582] time: 2294.6522, d_loss: 0.84013122, g_loss: 0.83594066\n",
      "Epoch: [ 1] [ 169/1582] time: 2295.8981, d_loss: 0.67058623, g_loss: 0.89378214\n",
      "Epoch: [ 1] [ 170/1582] time: 2297.1491, d_loss: 0.63703686, g_loss: 0.94862998\n",
      "Epoch: [ 1] [ 171/1582] time: 2298.3970, d_loss: 0.59276569, g_loss: 0.97372323\n",
      "Epoch: [ 1] [ 172/1582] time: 2299.6470, d_loss: 0.51906085, g_loss: 1.07269669\n",
      "Epoch: [ 1] [ 173/1582] time: 2300.8989, d_loss: 0.55783314, g_loss: 1.12508214\n",
      "Epoch: [ 1] [ 174/1582] time: 2302.1450, d_loss: 0.59106207, g_loss: 1.15933418\n",
      "Epoch: [ 1] [ 175/1582] time: 2303.3900, d_loss: 0.48342556, g_loss: 1.20573759\n",
      "Epoch: [ 1] [ 176/1582] time: 2304.6359, d_loss: 0.56245887, g_loss: 1.15565205\n",
      "Epoch: [ 1] [ 177/1582] time: 2305.8846, d_loss: 0.52298927, g_loss: 1.19032788\n",
      "Epoch: [ 1] [ 178/1582] time: 2307.1343, d_loss: 0.37731510, g_loss: 1.26384592\n",
      "Epoch: [ 1] [ 179/1582] time: 2308.3823, d_loss: 0.37932497, g_loss: 1.35588384\n",
      "Epoch: [ 1] [ 180/1582] time: 2309.6303, d_loss: 0.54036069, g_loss: 1.31269693\n",
      "Epoch: [ 1] [ 181/1582] time: 2310.8802, d_loss: 0.37059668, g_loss: 1.30288315\n",
      "Epoch: [ 1] [ 182/1582] time: 2312.1312, d_loss: 0.44765994, g_loss: 1.24102092\n",
      "Epoch: [ 1] [ 183/1582] time: 2313.3830, d_loss: 0.51314604, g_loss: 1.14779401\n",
      "Epoch: [ 1] [ 184/1582] time: 2314.6320, d_loss: 0.53202254, g_loss: 1.07005072\n",
      "Epoch: [ 1] [ 185/1582] time: 2315.8779, d_loss: 0.51222450, g_loss: 0.97614729\n",
      "Epoch: [ 1] [ 186/1582] time: 2317.1229, d_loss: 0.66921198, g_loss: 0.88959026\n",
      "Epoch: [ 1] [ 187/1582] time: 2318.3708, d_loss: 0.72549230, g_loss: 0.79731095\n",
      "Epoch: [ 1] [ 188/1582] time: 2319.6195, d_loss: 0.74922812, g_loss: 0.76028097\n",
      "Epoch: [ 1] [ 189/1582] time: 2320.8644, d_loss: 0.86175686, g_loss: 0.70480078\n",
      "Epoch: [ 1] [ 190/1582] time: 2322.1114, d_loss: 0.89488560, g_loss: 0.63152134\n",
      "Epoch: [ 1] [ 191/1582] time: 2323.3563, d_loss: 1.01516724, g_loss: 0.58277893\n",
      "Epoch: [ 1] [ 192/1582] time: 2324.6033, d_loss: 1.04417515, g_loss: 0.52258813\n",
      "Epoch: [ 1] [ 193/1582] time: 2325.8503, d_loss: 1.03238869, g_loss: 0.50768971\n",
      "Epoch: [ 1] [ 194/1582] time: 2327.0992, d_loss: 0.99005866, g_loss: 0.52254379\n",
      "Epoch: [ 1] [ 195/1582] time: 2328.3442, d_loss: 0.94362366, g_loss: 0.54439849\n",
      "Epoch: [ 1] [ 196/1582] time: 2329.5901, d_loss: 0.77025342, g_loss: 0.61853987\n",
      "Epoch: [ 1] [ 197/1582] time: 2330.8381, d_loss: 0.78001279, g_loss: 0.70491093\n",
      "Epoch: [ 1] [ 198/1582] time: 2332.0861, d_loss: 0.77751619, g_loss: 0.71098006\n",
      "Epoch: [ 1] [ 199/1582] time: 2333.3320, d_loss: 0.65434891, g_loss: 0.75373650\n",
      "Epoch: [ 1] [ 200/1582] time: 2334.5790, d_loss: 0.62899601, g_loss: 0.83210599\n",
      "Epoch: [ 1] [ 201/1582] time: 2335.8289, d_loss: 0.62820005, g_loss: 0.90085799\n",
      "Epoch: [ 1] [ 202/1582] time: 2337.0749, d_loss: 0.55045867, g_loss: 0.99029243\n",
      "Epoch: [ 1] [ 203/1582] time: 2338.3229, d_loss: 0.45344061, g_loss: 1.08097792\n",
      "Epoch: [ 1] [ 204/1582] time: 2339.5688, d_loss: 0.46511513, g_loss: 1.15151000\n",
      "Epoch: [ 1] [ 205/1582] time: 2340.8168, d_loss: 0.48436347, g_loss: 1.18959880\n",
      "Epoch: [ 1] [ 206/1582] time: 2342.0638, d_loss: 0.49110883, g_loss: 1.17171562\n",
      "Epoch: [ 1] [ 207/1582] time: 2343.3107, d_loss: 0.52251917, g_loss: 1.10550976\n",
      "Epoch: [ 1] [ 208/1582] time: 2344.5576, d_loss: 0.59380555, g_loss: 0.97559965\n",
      "Epoch: [ 1] [ 209/1582] time: 2345.8036, d_loss: 0.63443500, g_loss: 0.90481633\n",
      "Epoch: [ 1] [ 210/1582] time: 2347.0516, d_loss: 0.62744862, g_loss: 0.85526681\n",
      "Epoch: [ 1] [ 211/1582] time: 2348.2985, d_loss: 0.78997636, g_loss: 0.79986525\n",
      "Epoch: [ 1] [ 212/1582] time: 2349.5485, d_loss: 0.66312516, g_loss: 0.76019174\n",
      "Epoch: [ 1] [ 213/1582] time: 2350.7945, d_loss: 0.64940983, g_loss: 0.80328310\n",
      "Epoch: [ 1] [ 214/1582] time: 2352.0394, d_loss: 0.69247204, g_loss: 0.88516307\n",
      "Epoch: [ 1] [ 215/1582] time: 2353.2844, d_loss: 0.69854236, g_loss: 0.92631745\n",
      "Epoch: [ 1] [ 216/1582] time: 2354.5304, d_loss: 0.75470763, g_loss: 0.90912592\n",
      "Epoch: [ 1] [ 217/1582] time: 2355.7783, d_loss: 0.84973270, g_loss: 0.80101752\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 1] [ 218/1582] time: 2363.7310, d_loss: 0.80704761, g_loss: 0.70470881\n",
      "Epoch: [ 1] [ 219/1582] time: 2364.9750, d_loss: 0.89958996, g_loss: 0.65346098\n",
      "Epoch: [ 1] [ 220/1582] time: 2366.2190, d_loss: 0.98648357, g_loss: 0.59102559\n",
      "Epoch: [ 1] [ 221/1582] time: 2367.4629, d_loss: 1.00879443, g_loss: 0.55875725\n",
      "Epoch: [ 1] [ 222/1582] time: 2368.7104, d_loss: 0.96148586, g_loss: 0.52847445\n",
      "Epoch: [ 1] [ 223/1582] time: 2369.9520, d_loss: 1.07242775, g_loss: 0.50725067\n",
      "Epoch: [ 1] [ 224/1582] time: 2371.1995, d_loss: 0.99667776, g_loss: 0.52474535\n",
      "Epoch: [ 1] [ 225/1582] time: 2372.4425, d_loss: 0.92717916, g_loss: 0.57505667\n",
      "Epoch: [ 1] [ 226/1582] time: 2373.6885, d_loss: 0.86381561, g_loss: 0.64765513\n",
      "Epoch: [ 1] [ 227/1582] time: 2374.9344, d_loss: 0.70955312, g_loss: 0.72238266\n",
      "Epoch: [ 1] [ 228/1582] time: 2376.1814, d_loss: 0.77850652, g_loss: 0.79188752\n",
      "Epoch: [ 1] [ 229/1582] time: 2377.4251, d_loss: 0.66679627, g_loss: 0.85869789\n",
      "Epoch: [ 1] [ 230/1582] time: 2378.6691, d_loss: 0.70453179, g_loss: 0.89397740\n",
      "Epoch: [ 1] [ 231/1582] time: 2379.9172, d_loss: 0.65497148, g_loss: 0.88582861\n",
      "Epoch: [ 1] [ 232/1582] time: 2381.1618, d_loss: 0.57095224, g_loss: 0.94759679\n",
      "Epoch: [ 1] [ 233/1582] time: 2382.4047, d_loss: 0.48988727, g_loss: 1.07487941\n",
      "Epoch: [ 1] [ 234/1582] time: 2383.6527, d_loss: 0.49497360, g_loss: 1.18239093\n",
      "Epoch: [ 1] [ 235/1582] time: 2384.8938, d_loss: 0.47103253, g_loss: 1.22712791\n",
      "Epoch: [ 1] [ 236/1582] time: 2386.1417, d_loss: 0.44123513, g_loss: 1.25637984\n",
      "Epoch: [ 1] [ 237/1582] time: 2387.3877, d_loss: 0.47480911, g_loss: 1.28844714\n",
      "Epoch: [ 1] [ 238/1582] time: 2388.6336, d_loss: 0.48513538, g_loss: 1.14502132\n",
      "Epoch: [ 1] [ 239/1582] time: 2389.8816, d_loss: 0.49671721, g_loss: 1.11056280\n",
      "Epoch: [ 1] [ 240/1582] time: 2391.1297, d_loss: 0.69689769, g_loss: 0.92978597\n",
      "Epoch: [ 1] [ 241/1582] time: 2392.3766, d_loss: 0.70821077, g_loss: 0.83091199\n",
      "Epoch: [ 1] [ 242/1582] time: 2393.6245, d_loss: 0.98767465, g_loss: 0.69423854\n",
      "Epoch: [ 1] [ 243/1582] time: 2394.8685, d_loss: 1.07940972, g_loss: 0.56762385\n",
      "Epoch: [ 1] [ 244/1582] time: 2396.1185, d_loss: 1.01303625, g_loss: 0.68165028\n",
      "Epoch: [ 1] [ 245/1582] time: 2397.3665, d_loss: 0.73963249, g_loss: 0.84483063\n",
      "Epoch: [ 1] [ 246/1582] time: 2398.6144, d_loss: 0.60465997, g_loss: 1.18664861\n",
      "Epoch: [ 1] [ 247/1582] time: 2399.8634, d_loss: 0.73095602, g_loss: 1.52107298\n",
      "Epoch: [ 1] [ 248/1582] time: 2401.1133, d_loss: 0.45610183, g_loss: 1.68539011\n",
      "Epoch: [ 1] [ 249/1582] time: 2402.3603, d_loss: 0.74365652, g_loss: 1.38865733\n",
      "Epoch: [ 1] [ 250/1582] time: 2403.6083, d_loss: 0.87718427, g_loss: 0.80767059\n",
      "Epoch: [ 1] [ 251/1582] time: 2404.8552, d_loss: 1.02598262, g_loss: 0.53713214\n",
      "Epoch: [ 1] [ 252/1582] time: 2406.1022, d_loss: 1.23941839, g_loss: 0.42622426\n",
      "Epoch: [ 1] [ 253/1582] time: 2407.3531, d_loss: 1.11938703, g_loss: 0.46544263\n",
      "Epoch: [ 1] [ 254/1582] time: 2408.6033, d_loss: 1.04261339, g_loss: 0.55595309\n",
      "Epoch: [ 1] [ 255/1582] time: 2409.8583, d_loss: 0.68518174, g_loss: 0.79679906\n",
      "Epoch: [ 1] [ 256/1582] time: 2411.1093, d_loss: 0.63945401, g_loss: 1.01444542\n",
      "Epoch: [ 1] [ 257/1582] time: 2412.3594, d_loss: 0.59556353, g_loss: 1.24038363\n",
      "Epoch: [ 1] [ 258/1582] time: 2413.6073, d_loss: 0.60192072, g_loss: 1.31944597\n",
      "Epoch: [ 1] [ 259/1582] time: 2414.8513, d_loss: 0.38820451, g_loss: 1.39440393\n",
      "Epoch: [ 1] [ 260/1582] time: 2416.0972, d_loss: 0.46112338, g_loss: 1.23855186\n",
      "Epoch: [ 1] [ 261/1582] time: 2417.3432, d_loss: 0.54570353, g_loss: 1.14267540\n",
      "Epoch: [ 1] [ 262/1582] time: 2418.5892, d_loss: 0.55796725, g_loss: 0.96677119\n",
      "Epoch: [ 1] [ 263/1582] time: 2419.8352, d_loss: 0.67788076, g_loss: 0.79531193\n",
      "Epoch: [ 1] [ 264/1582] time: 2421.0841, d_loss: 0.75331819, g_loss: 0.67973506\n",
      "Epoch: [ 1] [ 265/1582] time: 2422.3240, d_loss: 0.90669608, g_loss: 0.57879192\n",
      "Epoch: [ 1] [ 266/1582] time: 2423.5700, d_loss: 0.94667625, g_loss: 0.49913663\n",
      "Epoch: [ 1] [ 267/1582] time: 2424.8160, d_loss: 0.94949424, g_loss: 0.50846440\n",
      "Epoch: [ 1] [ 268/1582] time: 2426.0619, d_loss: 1.09381747, g_loss: 0.49082091\n",
      "Epoch: [ 1] [ 269/1582] time: 2427.3059, d_loss: 0.94928694, g_loss: 0.52872926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1] [ 270/1582] time: 2428.5499, d_loss: 0.97273898, g_loss: 0.57552296\n",
      "Epoch: [ 1] [ 271/1582] time: 2429.7958, d_loss: 0.86340350, g_loss: 0.63966262\n",
      "Epoch: [ 1] [ 272/1582] time: 2431.0358, d_loss: 0.81268495, g_loss: 0.69049412\n",
      "Epoch: [ 1] [ 273/1582] time: 2432.2787, d_loss: 0.81023216, g_loss: 0.73100597\n",
      "Epoch: [ 1] [ 274/1582] time: 2433.5227, d_loss: 0.74518383, g_loss: 0.75025105\n",
      "Epoch: [ 1] [ 275/1582] time: 2434.7667, d_loss: 0.65511167, g_loss: 0.78060734\n",
      "Epoch: [ 1] [ 276/1582] time: 2436.0146, d_loss: 0.69314849, g_loss: 0.79957837\n",
      "Epoch: [ 1] [ 277/1582] time: 2437.2596, d_loss: 0.61251289, g_loss: 0.82129848\n",
      "Epoch: [ 1] [ 278/1582] time: 2438.5075, d_loss: 0.60724163, g_loss: 0.86126709\n",
      "Epoch: [ 1] [ 279/1582] time: 2439.7535, d_loss: 0.61143720, g_loss: 0.87537801\n",
      "Epoch: [ 1] [ 280/1582] time: 2440.9985, d_loss: 0.56021428, g_loss: 0.88113976\n",
      "Epoch: [ 1] [ 281/1582] time: 2442.2434, d_loss: 0.59208286, g_loss: 0.89071286\n",
      "Epoch: [ 1] [ 282/1582] time: 2443.4894, d_loss: 0.60567498, g_loss: 0.86189294\n",
      "Epoch: [ 1] [ 283/1582] time: 2444.7334, d_loss: 0.54039693, g_loss: 0.87750757\n",
      "Epoch: [ 1] [ 284/1582] time: 2445.9793, d_loss: 0.61674821, g_loss: 0.85897434\n",
      "Epoch: [ 1] [ 285/1582] time: 2447.2263, d_loss: 0.63954484, g_loss: 0.84453166\n",
      "Epoch: [ 1] [ 286/1582] time: 2448.4712, d_loss: 0.71981716, g_loss: 0.76424712\n",
      "Epoch: [ 1] [ 287/1582] time: 2449.7192, d_loss: 0.82986760, g_loss: 0.67653310\n",
      "Epoch: [ 1] [ 288/1582] time: 2450.9672, d_loss: 0.89501929, g_loss: 0.57347083\n",
      "Epoch: [ 1] [ 289/1582] time: 2452.2101, d_loss: 0.84861696, g_loss: 0.56717986\n",
      "Epoch: [ 1] [ 290/1582] time: 2453.4561, d_loss: 0.91420996, g_loss: 0.60954309\n",
      "Epoch: [ 1] [ 291/1582] time: 2454.7040, d_loss: 0.85768372, g_loss: 0.70901716\n",
      "Epoch: [ 1] [ 292/1582] time: 2455.9480, d_loss: 0.69131029, g_loss: 0.83820587\n",
      "Epoch: [ 1] [ 293/1582] time: 2457.1939, d_loss: 0.55771196, g_loss: 0.99092960\n",
      "Epoch: [ 1] [ 294/1582] time: 2458.4398, d_loss: 0.43249187, g_loss: 1.27167392\n",
      "Epoch: [ 1] [ 295/1582] time: 2459.6826, d_loss: 0.36471820, g_loss: 1.52669716\n",
      "Epoch: [ 1] [ 296/1582] time: 2460.9295, d_loss: 0.36538506, g_loss: 1.68396544\n",
      "Epoch: [ 1] [ 297/1582] time: 2462.1685, d_loss: 0.26991236, g_loss: 1.78720915\n",
      "Epoch: [ 1] [ 298/1582] time: 2463.4124, d_loss: 0.20224169, g_loss: 1.83682132\n",
      "Epoch: [ 1] [ 299/1582] time: 2464.6586, d_loss: 0.23182768, g_loss: 1.74561226\n",
      "Epoch: [ 1] [ 300/1582] time: 2465.9056, d_loss: 0.28013673, g_loss: 1.59513700\n",
      "Epoch: [ 1] [ 301/1582] time: 2467.1495, d_loss: 0.38622805, g_loss: 1.31617951\n",
      "Epoch: [ 1] [ 302/1582] time: 2468.3935, d_loss: 0.53468674, g_loss: 0.97574127\n",
      "Epoch: [ 1] [ 303/1582] time: 2469.6435, d_loss: 0.74757814, g_loss: 0.70446813\n",
      "Epoch: [ 1] [ 304/1582] time: 2470.8914, d_loss: 0.88030148, g_loss: 0.55318499\n",
      "Epoch: [ 1] [ 305/1582] time: 2472.1364, d_loss: 0.98416406, g_loss: 0.45083499\n",
      "Epoch: [ 1] [ 306/1582] time: 2473.3833, d_loss: 1.02734804, g_loss: 0.46446699\n",
      "Epoch: [ 1] [ 307/1582] time: 2474.6293, d_loss: 1.04355419, g_loss: 0.49751204\n",
      "Epoch: [ 1] [ 308/1582] time: 2475.8743, d_loss: 0.89464831, g_loss: 0.62202001\n",
      "Epoch: [ 1] [ 309/1582] time: 2477.1232, d_loss: 1.17533875, g_loss: 0.62741578\n",
      "Epoch: [ 1] [ 310/1582] time: 2478.3702, d_loss: 0.89185011, g_loss: 0.66090763\n",
      "Epoch: [ 1] [ 311/1582] time: 2479.6171, d_loss: 0.95072347, g_loss: 0.62854069\n",
      "Epoch: [ 1] [ 312/1582] time: 2480.8671, d_loss: 0.88413495, g_loss: 0.61221802\n",
      "Epoch: [ 1] [ 313/1582] time: 2482.1161, d_loss: 0.82998979, g_loss: 0.65328819\n",
      "Epoch: [ 1] [ 314/1582] time: 2483.3620, d_loss: 0.73065102, g_loss: 0.67193246\n",
      "Epoch: [ 1] [ 315/1582] time: 2484.6080, d_loss: 0.69235873, g_loss: 0.78184521\n",
      "Epoch: [ 1] [ 316/1582] time: 2485.8540, d_loss: 0.59609336, g_loss: 0.88720280\n",
      "Epoch: [ 1] [ 317/1582] time: 2487.0999, d_loss: 0.59888828, g_loss: 0.94669676\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 1] [ 318/1582] time: 2494.9817, d_loss: 0.56196725, g_loss: 0.97932184\n",
      "Epoch: [ 1] [ 319/1582] time: 2496.2257, d_loss: 0.59340167, g_loss: 0.92938805\n",
      "Epoch: [ 1] [ 320/1582] time: 2497.4717, d_loss: 0.53957951, g_loss: 0.91776025\n",
      "Epoch: [ 1] [ 321/1582] time: 2498.7187, d_loss: 0.59256595, g_loss: 0.85622954\n",
      "Epoch: [ 1] [ 322/1582] time: 2499.9656, d_loss: 0.68107456, g_loss: 0.74903131\n",
      "Epoch: [ 1] [ 323/1582] time: 2501.2087, d_loss: 0.66121721, g_loss: 0.70669091\n",
      "Epoch: [ 1] [ 324/1582] time: 2502.4547, d_loss: 0.79972446, g_loss: 0.64678532\n",
      "Epoch: [ 1] [ 325/1582] time: 2503.7026, d_loss: 0.89879751, g_loss: 0.55157167\n",
      "Epoch: [ 1] [ 326/1582] time: 2504.9497, d_loss: 0.96043497, g_loss: 0.46560866\n",
      "Epoch: [ 1] [ 327/1582] time: 2506.1957, d_loss: 1.06240463, g_loss: 0.42704701\n",
      "Epoch: [ 1] [ 328/1582] time: 2507.4437, d_loss: 1.07538903, g_loss: 0.38044214\n",
      "Epoch: [ 1] [ 329/1582] time: 2508.6876, d_loss: 1.21138072, g_loss: 0.35082969\n",
      "Epoch: [ 1] [ 330/1582] time: 2509.9352, d_loss: 1.27772450, g_loss: 0.30973321\n",
      "Epoch: [ 1] [ 331/1582] time: 2511.1816, d_loss: 1.34935117, g_loss: 0.29597455\n",
      "Epoch: [ 1] [ 332/1582] time: 2512.4262, d_loss: 1.35951138, g_loss: 0.28804141\n",
      "Epoch: [ 1] [ 333/1582] time: 2513.6692, d_loss: 1.33250320, g_loss: 0.28639477\n",
      "Epoch: [ 1] [ 334/1582] time: 2514.9142, d_loss: 1.32959652, g_loss: 0.30909827\n",
      "Epoch: [ 1] [ 335/1582] time: 2516.1561, d_loss: 1.19797719, g_loss: 0.37677950\n",
      "Epoch: [ 1] [ 336/1582] time: 2517.4012, d_loss: 1.13455701, g_loss: 0.45536655\n",
      "Epoch: [ 1] [ 337/1582] time: 2518.6491, d_loss: 0.94423342, g_loss: 0.55779636\n",
      "Epoch: [ 1] [ 338/1582] time: 2519.8981, d_loss: 0.75145644, g_loss: 0.73005116\n",
      "Epoch: [ 1] [ 339/1582] time: 2521.1471, d_loss: 0.64441192, g_loss: 0.85570776\n",
      "Epoch: [ 1] [ 340/1582] time: 2522.3980, d_loss: 0.52798176, g_loss: 1.05377877\n",
      "Epoch: [ 1] [ 341/1582] time: 2523.6430, d_loss: 0.52709377, g_loss: 1.13700795\n",
      "Epoch: [ 1] [ 342/1582] time: 2524.8899, d_loss: 0.42432082, g_loss: 1.25195265\n",
      "Epoch: [ 1] [ 343/1582] time: 2526.1349, d_loss: 0.41387886, g_loss: 1.23477268\n",
      "Epoch: [ 1] [ 344/1582] time: 2527.3808, d_loss: 0.45381317, g_loss: 1.17092919\n",
      "Epoch: [ 1] [ 345/1582] time: 2528.6278, d_loss: 0.46551847, g_loss: 1.07599640\n",
      "Epoch: [ 1] [ 346/1582] time: 2529.8808, d_loss: 0.54356474, g_loss: 0.91608858\n",
      "Epoch: [ 1] [ 347/1582] time: 2531.1258, d_loss: 0.69596481, g_loss: 0.76977396\n",
      "Epoch: [ 1] [ 348/1582] time: 2532.3738, d_loss: 0.82126546, g_loss: 0.63259047\n",
      "Epoch: [ 1] [ 349/1582] time: 2533.6198, d_loss: 0.89045107, g_loss: 0.53177238\n",
      "Epoch: [ 1] [ 350/1582] time: 2534.8677, d_loss: 0.99908501, g_loss: 0.51577640\n",
      "Epoch: [ 1] [ 351/1582] time: 2536.1127, d_loss: 1.05190241, g_loss: 0.47618604\n",
      "Epoch: [ 1] [ 352/1582] time: 2537.3617, d_loss: 1.06751668, g_loss: 0.46659401\n",
      "Epoch: [ 1] [ 353/1582] time: 2538.6076, d_loss: 1.11806190, g_loss: 0.46515188\n",
      "Epoch: [ 1] [ 354/1582] time: 2539.8556, d_loss: 1.07529986, g_loss: 0.44269127\n",
      "Epoch: [ 1] [ 355/1582] time: 2541.1065, d_loss: 1.13193297, g_loss: 0.42036074\n",
      "Epoch: [ 1] [ 356/1582] time: 2542.3565, d_loss: 1.08458173, g_loss: 0.42935824\n",
      "Epoch: [ 1] [ 357/1582] time: 2543.6015, d_loss: 0.97519678, g_loss: 0.45902786\n",
      "Epoch: [ 1] [ 358/1582] time: 2544.8489, d_loss: 0.93285257, g_loss: 0.49567008\n",
      "Epoch: [ 1] [ 359/1582] time: 2546.0964, d_loss: 0.89938611, g_loss: 0.53976041\n",
      "Epoch: [ 1] [ 360/1582] time: 2547.3462, d_loss: 0.83215350, g_loss: 0.57824457\n",
      "Epoch: [ 1] [ 361/1582] time: 2548.5921, d_loss: 0.82596290, g_loss: 0.60532993\n",
      "Epoch: [ 1] [ 362/1582] time: 2549.8401, d_loss: 0.69948381, g_loss: 0.67529356\n",
      "Epoch: [ 1] [ 363/1582] time: 2551.0861, d_loss: 0.68421662, g_loss: 0.75318944\n",
      "Epoch: [ 1] [ 364/1582] time: 2552.3330, d_loss: 0.69881618, g_loss: 0.77495885\n",
      "Epoch: [ 1] [ 365/1582] time: 2553.5802, d_loss: 0.61175674, g_loss: 0.83522940\n",
      "Epoch: [ 1] [ 366/1582] time: 2554.8281, d_loss: 0.58632386, g_loss: 0.85244840\n",
      "Epoch: [ 1] [ 367/1582] time: 2556.0711, d_loss: 0.62453538, g_loss: 0.86093646\n",
      "Epoch: [ 1] [ 368/1582] time: 2557.3151, d_loss: 0.54217911, g_loss: 0.87643480\n",
      "Epoch: [ 1] [ 369/1582] time: 2558.5590, d_loss: 0.52026141, g_loss: 0.88687390\n",
      "Epoch: [ 1] [ 370/1582] time: 2559.8068, d_loss: 0.52029467, g_loss: 0.93577343\n",
      "Epoch: [ 1] [ 371/1582] time: 2561.0528, d_loss: 0.50609529, g_loss: 0.99390823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1] [ 372/1582] time: 2562.3007, d_loss: 0.49879855, g_loss: 1.00843418\n",
      "Epoch: [ 1] [ 373/1582] time: 2563.5477, d_loss: 0.44532713, g_loss: 1.05291021\n",
      "Epoch: [ 1] [ 374/1582] time: 2564.7967, d_loss: 0.47887161, g_loss: 1.08347082\n",
      "Epoch: [ 1] [ 375/1582] time: 2566.0456, d_loss: 0.42191002, g_loss: 1.10188675\n",
      "Epoch: [ 1] [ 376/1582] time: 2567.2916, d_loss: 0.51459002, g_loss: 1.03612244\n",
      "Epoch: [ 1] [ 377/1582] time: 2568.5385, d_loss: 0.49571237, g_loss: 0.99163359\n",
      "Epoch: [ 1] [ 378/1582] time: 2569.7864, d_loss: 0.55565912, g_loss: 0.90658736\n",
      "Epoch: [ 1] [ 379/1582] time: 2571.0344, d_loss: 0.52970165, g_loss: 0.89421809\n",
      "Epoch: [ 1] [ 380/1582] time: 2572.2824, d_loss: 0.57591963, g_loss: 0.86661500\n",
      "Epoch: [ 1] [ 381/1582] time: 2573.5273, d_loss: 0.61564040, g_loss: 0.79947615\n",
      "Epoch: [ 1] [ 382/1582] time: 2574.7753, d_loss: 0.61899024, g_loss: 0.76602060\n",
      "Epoch: [ 1] [ 383/1582] time: 2576.0212, d_loss: 0.71659672, g_loss: 0.73357683\n",
      "Epoch: [ 1] [ 384/1582] time: 2577.2653, d_loss: 0.82073140, g_loss: 0.63640666\n",
      "Epoch: [ 1] [ 385/1582] time: 2578.5119, d_loss: 0.89136302, g_loss: 0.58535111\n",
      "Epoch: [ 1] [ 386/1582] time: 2579.7589, d_loss: 0.91495466, g_loss: 0.51415467\n",
      "Epoch: [ 1] [ 387/1582] time: 2581.0058, d_loss: 0.97893888, g_loss: 0.48462528\n",
      "Epoch: [ 1] [ 388/1582] time: 2582.2528, d_loss: 1.05860126, g_loss: 0.45295775\n",
      "Epoch: [ 1] [ 389/1582] time: 2583.4977, d_loss: 1.02932703, g_loss: 0.45607695\n",
      "Epoch: [ 1] [ 390/1582] time: 2584.7431, d_loss: 0.97476232, g_loss: 0.49089265\n",
      "Epoch: [ 1] [ 391/1582] time: 2585.9903, d_loss: 0.99704337, g_loss: 0.53424919\n",
      "Epoch: [ 1] [ 392/1582] time: 2587.2373, d_loss: 0.96136498, g_loss: 0.57620078\n",
      "Epoch: [ 1] [ 393/1582] time: 2588.4812, d_loss: 0.87124544, g_loss: 0.62148678\n",
      "Epoch: [ 1] [ 394/1582] time: 2589.7302, d_loss: 0.77079272, g_loss: 0.69211572\n",
      "Epoch: [ 1] [ 395/1582] time: 2590.9782, d_loss: 0.77421069, g_loss: 0.77502143\n",
      "Epoch: [ 1] [ 396/1582] time: 2592.2251, d_loss: 0.64610875, g_loss: 0.89076483\n",
      "Epoch: [ 1] [ 397/1582] time: 2593.4721, d_loss: 0.62182003, g_loss: 0.95063382\n",
      "Epoch: [ 1] [ 398/1582] time: 2594.7200, d_loss: 0.54176909, g_loss: 1.04810035\n",
      "Epoch: [ 1] [ 399/1582] time: 2595.9650, d_loss: 0.58922434, g_loss: 1.00970721\n",
      "Epoch: [ 1] [ 400/1582] time: 2597.2120, d_loss: 0.55116129, g_loss: 1.08195543\n",
      "Epoch: [ 1] [ 401/1582] time: 2598.4569, d_loss: 0.53096551, g_loss: 1.10431314\n",
      "Epoch: [ 1] [ 402/1582] time: 2599.7039, d_loss: 0.64067149, g_loss: 0.97680902\n",
      "Epoch: [ 1] [ 403/1582] time: 2600.9519, d_loss: 0.69144160, g_loss: 0.90146911\n",
      "Epoch: [ 1] [ 404/1582] time: 2602.1998, d_loss: 0.73591495, g_loss: 0.81977451\n",
      "Epoch: [ 1] [ 405/1582] time: 2603.4448, d_loss: 0.80636179, g_loss: 0.78387654\n",
      "Epoch: [ 1] [ 406/1582] time: 2604.6947, d_loss: 0.81966311, g_loss: 0.75359684\n",
      "Epoch: [ 1] [ 407/1582] time: 2605.9407, d_loss: 0.90393049, g_loss: 0.67992067\n",
      "Epoch: [ 1] [ 408/1582] time: 2607.1877, d_loss: 0.94148874, g_loss: 0.63505125\n",
      "Epoch: [ 1] [ 409/1582] time: 2608.4356, d_loss: 0.92790949, g_loss: 0.58809787\n",
      "Epoch: [ 1] [ 410/1582] time: 2609.6826, d_loss: 1.03360450, g_loss: 0.54680341\n",
      "Epoch: [ 1] [ 411/1582] time: 2610.9275, d_loss: 0.95145279, g_loss: 0.51939374\n",
      "Epoch: [ 1] [ 412/1582] time: 2612.1785, d_loss: 0.89856195, g_loss: 0.53498161\n",
      "Epoch: [ 1] [ 413/1582] time: 2613.4235, d_loss: 0.91839921, g_loss: 0.53670621\n",
      "Epoch: [ 1] [ 414/1582] time: 2614.6724, d_loss: 0.92007506, g_loss: 0.55658978\n",
      "Epoch: [ 1] [ 415/1582] time: 2615.9221, d_loss: 0.96717751, g_loss: 0.52456415\n",
      "Epoch: [ 1] [ 416/1582] time: 2617.1701, d_loss: 0.92016387, g_loss: 0.50148249\n",
      "Epoch: [ 1] [ 417/1582] time: 2618.4150, d_loss: 0.89528328, g_loss: 0.51816440\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 1] [ 418/1582] time: 2626.4230, d_loss: 0.87442052, g_loss: 0.53198940\n",
      "Epoch: [ 1] [ 419/1582] time: 2627.6711, d_loss: 0.83137155, g_loss: 0.57955801\n",
      "Epoch: [ 1] [ 420/1582] time: 2628.9205, d_loss: 0.72834808, g_loss: 0.64473605\n",
      "Epoch: [ 1] [ 421/1582] time: 2630.1704, d_loss: 0.76328611, g_loss: 0.70404863\n",
      "Epoch: [ 1] [ 422/1582] time: 2631.4234, d_loss: 0.71304500, g_loss: 0.72850573\n",
      "Epoch: [ 1] [ 423/1582] time: 2632.6720, d_loss: 0.71713769, g_loss: 0.75080287\n",
      "Epoch: [ 1] [ 424/1582] time: 2633.9205, d_loss: 0.68441325, g_loss: 0.75360882\n",
      "Epoch: [ 1] [ 425/1582] time: 2635.1694, d_loss: 0.70714009, g_loss: 0.72455621\n",
      "Epoch: [ 1] [ 426/1582] time: 2636.4204, d_loss: 0.65836221, g_loss: 0.75448203\n",
      "Epoch: [ 1] [ 427/1582] time: 2637.6704, d_loss: 0.63707387, g_loss: 0.78012425\n",
      "Epoch: [ 1] [ 428/1582] time: 2638.9203, d_loss: 0.58385915, g_loss: 0.83138853\n",
      "Epoch: [ 1] [ 429/1582] time: 2640.1713, d_loss: 0.53099084, g_loss: 0.95869875\n",
      "Epoch: [ 1] [ 430/1582] time: 2641.4217, d_loss: 0.49592710, g_loss: 1.04891157\n",
      "Epoch: [ 1] [ 431/1582] time: 2642.6699, d_loss: 0.51546860, g_loss: 1.08068275\n",
      "Epoch: [ 1] [ 432/1582] time: 2643.9219, d_loss: 0.45943063, g_loss: 1.11851966\n",
      "Epoch: [ 1] [ 433/1582] time: 2645.1729, d_loss: 0.46617764, g_loss: 1.15534699\n",
      "Epoch: [ 1] [ 434/1582] time: 2646.4219, d_loss: 0.44879031, g_loss: 1.16617656\n",
      "Epoch: [ 1] [ 435/1582] time: 2647.6697, d_loss: 0.39612210, g_loss: 1.15179181\n",
      "Epoch: [ 1] [ 436/1582] time: 2648.9177, d_loss: 0.45478311, g_loss: 1.15487432\n",
      "Epoch: [ 1] [ 437/1582] time: 2650.1729, d_loss: 0.47604749, g_loss: 1.14141417\n",
      "Epoch: [ 1] [ 438/1582] time: 2651.4238, d_loss: 0.45874670, g_loss: 1.08548021\n",
      "Epoch: [ 1] [ 439/1582] time: 2652.6747, d_loss: 0.48973358, g_loss: 1.00610781\n",
      "Epoch: [ 1] [ 440/1582] time: 2653.9267, d_loss: 0.47944635, g_loss: 0.98124343\n",
      "Epoch: [ 1] [ 441/1582] time: 2655.1737, d_loss: 0.59059590, g_loss: 0.89910758\n",
      "Epoch: [ 1] [ 442/1582] time: 2656.4296, d_loss: 0.56650269, g_loss: 0.81251222\n",
      "Epoch: [ 1] [ 443/1582] time: 2657.6796, d_loss: 0.71034694, g_loss: 0.76311845\n",
      "Epoch: [ 1] [ 444/1582] time: 2658.9306, d_loss: 0.92463058, g_loss: 0.58585703\n",
      "Epoch: [ 1] [ 445/1582] time: 2660.1815, d_loss: 1.04069996, g_loss: 0.49368766\n",
      "Epoch: [ 1] [ 446/1582] time: 2661.4355, d_loss: 1.10935354, g_loss: 0.42722857\n",
      "Epoch: [ 1] [ 447/1582] time: 2662.6844, d_loss: 1.40070081, g_loss: 0.40111411\n",
      "Epoch: [ 1] [ 448/1582] time: 2663.9344, d_loss: 1.42471552, g_loss: 0.36410064\n",
      "Epoch: [ 1] [ 449/1582] time: 2665.1847, d_loss: 1.47222161, g_loss: 0.35816580\n",
      "Epoch: [ 1] [ 450/1582] time: 2666.4346, d_loss: 1.36068738, g_loss: 0.35174316\n",
      "Epoch: [ 1] [ 451/1582] time: 2667.6854, d_loss: 1.35335898, g_loss: 0.40382311\n",
      "Epoch: [ 1] [ 452/1582] time: 2668.9342, d_loss: 1.25222516, g_loss: 0.42228603\n",
      "Epoch: [ 1] [ 453/1582] time: 2670.1842, d_loss: 1.16285384, g_loss: 0.49768102\n",
      "Epoch: [ 1] [ 454/1582] time: 2671.4352, d_loss: 1.06974339, g_loss: 0.53723478\n",
      "Epoch: [ 1] [ 455/1582] time: 2672.6861, d_loss: 1.07709622, g_loss: 0.54233420\n",
      "Epoch: [ 1] [ 456/1582] time: 2673.9381, d_loss: 0.97033387, g_loss: 0.58764744\n",
      "Epoch: [ 1] [ 457/1582] time: 2675.1891, d_loss: 0.83100277, g_loss: 0.64811713\n",
      "Epoch: [ 1] [ 458/1582] time: 2676.4414, d_loss: 0.71361262, g_loss: 0.72805828\n",
      "Epoch: [ 1] [ 459/1582] time: 2677.6917, d_loss: 0.70489323, g_loss: 0.80895388\n",
      "Epoch: [ 1] [ 460/1582] time: 2678.9417, d_loss: 0.73031479, g_loss: 0.82960695\n",
      "Epoch: [ 1] [ 461/1582] time: 2680.1947, d_loss: 0.70594066, g_loss: 0.84401655\n",
      "Epoch: [ 1] [ 462/1582] time: 2681.4476, d_loss: 0.70158774, g_loss: 0.81308234\n",
      "Epoch: [ 1] [ 463/1582] time: 2682.6966, d_loss: 0.79269248, g_loss: 0.75486684\n",
      "Epoch: [ 1] [ 464/1582] time: 2683.9495, d_loss: 0.75277120, g_loss: 0.76436096\n",
      "Epoch: [ 1] [ 465/1582] time: 2685.1993, d_loss: 0.81921518, g_loss: 0.72994399\n",
      "Epoch: [ 1] [ 466/1582] time: 2686.4513, d_loss: 0.85439771, g_loss: 0.68814254\n",
      "Epoch: [ 1] [ 467/1582] time: 2687.7022, d_loss: 0.87197220, g_loss: 0.68579030\n",
      "Epoch: [ 1] [ 468/1582] time: 2688.9692, d_loss: 0.93014765, g_loss: 0.60877889\n",
      "Epoch: [ 1] [ 469/1582] time: 2690.2236, d_loss: 0.91460413, g_loss: 0.58879787\n",
      "Epoch: [ 1] [ 470/1582] time: 2691.4775, d_loss: 0.97004414, g_loss: 0.55022538\n",
      "Epoch: [ 1] [ 471/1582] time: 2692.7295, d_loss: 0.95811760, g_loss: 0.52303874\n",
      "Epoch: [ 1] [ 472/1582] time: 2693.9834, d_loss: 0.93392253, g_loss: 0.53919792\n",
      "Epoch: [ 1] [ 473/1582] time: 2695.2344, d_loss: 0.96685940, g_loss: 0.55020070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1] [ 474/1582] time: 2696.4874, d_loss: 1.00099647, g_loss: 0.53967762\n",
      "Epoch: [ 1] [ 475/1582] time: 2697.7393, d_loss: 0.97151405, g_loss: 0.51158547\n",
      "Epoch: [ 1] [ 476/1582] time: 2698.9913, d_loss: 1.00753415, g_loss: 0.49609697\n",
      "Epoch: [ 1] [ 477/1582] time: 2700.2418, d_loss: 0.99331033, g_loss: 0.49517515\n",
      "Epoch: [ 1] [ 478/1582] time: 2701.4927, d_loss: 1.00053501, g_loss: 0.47765321\n",
      "Epoch: [ 1] [ 479/1582] time: 2702.7427, d_loss: 0.99238706, g_loss: 0.48175097\n",
      "Epoch: [ 1] [ 480/1582] time: 2703.9960, d_loss: 0.89017534, g_loss: 0.50809002\n",
      "Epoch: [ 1] [ 481/1582] time: 2705.2490, d_loss: 0.89057547, g_loss: 0.53139335\n",
      "Epoch: [ 1] [ 482/1582] time: 2706.5010, d_loss: 0.90576470, g_loss: 0.56531024\n",
      "Epoch: [ 1] [ 483/1582] time: 2707.7509, d_loss: 0.81844652, g_loss: 0.60174692\n",
      "Epoch: [ 1] [ 484/1582] time: 2709.0049, d_loss: 0.80474472, g_loss: 0.65672159\n",
      "Epoch: [ 1] [ 485/1582] time: 2710.2608, d_loss: 0.82729977, g_loss: 0.64488018\n",
      "Epoch: [ 1] [ 486/1582] time: 2711.5130, d_loss: 0.81310177, g_loss: 0.65967888\n",
      "Epoch: [ 1] [ 487/1582] time: 2712.7649, d_loss: 0.86959589, g_loss: 0.60507238\n",
      "Epoch: [ 1] [ 488/1582] time: 2714.0148, d_loss: 0.90736127, g_loss: 0.58013308\n",
      "Epoch: [ 1] [ 489/1582] time: 2715.2673, d_loss: 0.88311046, g_loss: 0.58667886\n",
      "Epoch: [ 1] [ 490/1582] time: 2716.5170, d_loss: 0.86877578, g_loss: 0.54567784\n",
      "Epoch: [ 1] [ 491/1582] time: 2717.7690, d_loss: 0.83440739, g_loss: 0.58604193\n",
      "Epoch: [ 1] [ 492/1582] time: 2719.0220, d_loss: 0.83020914, g_loss: 0.60333735\n",
      "Epoch: [ 1] [ 493/1582] time: 2720.2753, d_loss: 0.87444544, g_loss: 0.62899745\n",
      "Epoch: [ 1] [ 494/1582] time: 2721.5283, d_loss: 0.78290594, g_loss: 0.65332282\n",
      "Epoch: [ 1] [ 495/1582] time: 2722.7783, d_loss: 0.85638690, g_loss: 0.67388517\n",
      "Epoch: [ 1] [ 496/1582] time: 2724.0312, d_loss: 0.80420393, g_loss: 0.67891586\n",
      "Epoch: [ 1] [ 497/1582] time: 2725.2812, d_loss: 0.80346370, g_loss: 0.66625500\n",
      "Epoch: [ 1] [ 498/1582] time: 2726.5341, d_loss: 0.79042965, g_loss: 0.67376596\n",
      "Epoch: [ 1] [ 499/1582] time: 2727.7851, d_loss: 0.82429224, g_loss: 0.64134777\n",
      "Epoch: [ 1] [ 500/1582] time: 2729.0381, d_loss: 0.84406877, g_loss: 0.62937826\n",
      "Epoch: [ 1] [ 501/1582] time: 2730.2890, d_loss: 0.86083889, g_loss: 0.60094047\n",
      "Epoch: [ 1] [ 502/1582] time: 2731.5403, d_loss: 0.84939116, g_loss: 0.59755194\n",
      "Epoch: [ 1] [ 503/1582] time: 2732.7872, d_loss: 1.00152588, g_loss: 0.51095933\n",
      "Epoch: [ 1] [ 504/1582] time: 2734.0377, d_loss: 0.93094379, g_loss: 0.52027547\n",
      "Epoch: [ 1] [ 505/1582] time: 2735.2876, d_loss: 0.92573106, g_loss: 0.51848334\n",
      "Epoch: [ 1] [ 506/1582] time: 2736.5376, d_loss: 0.93243110, g_loss: 0.50974697\n",
      "Epoch: [ 1] [ 507/1582] time: 2737.7906, d_loss: 0.91403174, g_loss: 0.55608225\n",
      "Epoch: [ 1] [ 508/1582] time: 2739.0435, d_loss: 0.91556090, g_loss: 0.55583781\n",
      "Epoch: [ 1] [ 509/1582] time: 2740.2959, d_loss: 0.93097913, g_loss: 0.56547433\n",
      "Epoch: [ 1] [ 510/1582] time: 2741.5489, d_loss: 1.00824356, g_loss: 0.51098323\n",
      "Epoch: [ 1] [ 511/1582] time: 2742.8079, d_loss: 0.96765369, g_loss: 0.52884138\n",
      "Epoch: [ 1] [ 512/1582] time: 2744.0618, d_loss: 0.90041298, g_loss: 0.52721441\n",
      "Epoch: [ 1] [ 513/1582] time: 2745.3218, d_loss: 0.93578887, g_loss: 0.56311095\n",
      "Epoch: [ 1] [ 514/1582] time: 2746.5867, d_loss: 0.79221010, g_loss: 0.62328929\n",
      "Epoch: [ 1] [ 515/1582] time: 2747.8418, d_loss: 0.84413397, g_loss: 0.69781291\n",
      "Epoch: [ 1] [ 516/1582] time: 2749.1057, d_loss: 0.77614152, g_loss: 0.70558345\n",
      "Epoch: [ 1] [ 517/1582] time: 2750.3547, d_loss: 0.73978758, g_loss: 0.74733293\n",
      "Saved model\n",
      "WARNING:tensorflow:From C:\\Users\\MachineLearningUser\\AppData\\Local\\conda\\conda\\envs\\ml\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 1] [ 518/1582] time: 2758.3578, d_loss: 0.76414704, g_loss: 0.73568320\n",
      "Epoch: [ 1] [ 519/1582] time: 2759.6078, d_loss: 0.78088415, g_loss: 0.72057664\n",
      "Epoch: [ 1] [ 520/1582] time: 2760.8597, d_loss: 0.78839660, g_loss: 0.69181681\n",
      "Epoch: [ 1] [ 521/1582] time: 2762.1097, d_loss: 0.78872722, g_loss: 0.66253328\n",
      "Epoch: [ 1] [ 522/1582] time: 2763.3617, d_loss: 0.89699453, g_loss: 0.58634883\n",
      "Epoch: [ 1] [ 523/1582] time: 2764.6108, d_loss: 0.95721847, g_loss: 0.53015125\n",
      "Epoch: [ 1] [ 524/1582] time: 2765.8638, d_loss: 0.94729757, g_loss: 0.47738272\n",
      "Epoch: [ 1] [ 525/1582] time: 2767.1147, d_loss: 1.05503654, g_loss: 0.45152107\n",
      "Epoch: [ 1] [ 526/1582] time: 2768.3677, d_loss: 1.09919679, g_loss: 0.42290682\n",
      "Epoch: [ 1] [ 527/1582] time: 2769.6186, d_loss: 1.08856940, g_loss: 0.42004350\n",
      "Epoch: [ 1] [ 528/1582] time: 2770.8726, d_loss: 1.06558204, g_loss: 0.42192805\n",
      "Epoch: [ 1] [ 529/1582] time: 2772.1236, d_loss: 1.07194340, g_loss: 0.43999121\n",
      "Epoch: [ 1] [ 530/1582] time: 2773.3755, d_loss: 1.04898202, g_loss: 0.47051513\n",
      "Epoch: [ 1] [ 531/1582] time: 2774.6235, d_loss: 1.07555866, g_loss: 0.47402731\n",
      "Epoch: [ 1] [ 532/1582] time: 2775.8735, d_loss: 1.06644642, g_loss: 0.43966985\n",
      "Epoch: [ 1] [ 533/1582] time: 2777.1256, d_loss: 1.03446555, g_loss: 0.45864469\n",
      "Epoch: [ 1] [ 534/1582] time: 2778.3816, d_loss: 1.01781595, g_loss: 0.45255005\n",
      "Epoch: [ 1] [ 535/1582] time: 2779.6345, d_loss: 0.96411490, g_loss: 0.49881506\n",
      "Epoch: [ 1] [ 536/1582] time: 2780.8885, d_loss: 0.94208300, g_loss: 0.51722741\n",
      "Epoch: [ 1] [ 537/1582] time: 2782.1425, d_loss: 0.92241913, g_loss: 0.56354666\n",
      "Epoch: [ 1] [ 538/1582] time: 2783.3995, d_loss: 0.87446719, g_loss: 0.58694041\n",
      "Epoch: [ 1] [ 539/1582] time: 2784.6505, d_loss: 0.78753912, g_loss: 0.64253700\n",
      "Epoch: [ 1] [ 540/1582] time: 2785.9030, d_loss: 0.81488633, g_loss: 0.61955851\n",
      "Epoch: [ 1] [ 541/1582] time: 2787.1553, d_loss: 0.78632128, g_loss: 0.64515066\n",
      "Epoch: [ 1] [ 542/1582] time: 2788.4102, d_loss: 0.73481923, g_loss: 0.67770892\n",
      "Epoch: [ 1] [ 543/1582] time: 2789.6602, d_loss: 0.81077182, g_loss: 0.65619016\n",
      "Epoch: [ 1] [ 544/1582] time: 2790.9091, d_loss: 0.84127128, g_loss: 0.63550973\n",
      "Epoch: [ 1] [ 545/1582] time: 2792.1601, d_loss: 0.75337440, g_loss: 0.67370749\n",
      "Epoch: [ 1] [ 546/1582] time: 2793.4150, d_loss: 0.73642033, g_loss: 0.69192266\n",
      "Epoch: [ 1] [ 547/1582] time: 2794.6663, d_loss: 0.73438764, g_loss: 0.72604144\n",
      "Epoch: [ 1] [ 548/1582] time: 2795.9195, d_loss: 0.74240649, g_loss: 0.73367560\n",
      "Epoch: [ 1] [ 549/1582] time: 2797.1695, d_loss: 0.73694646, g_loss: 0.74813735\n",
      "Epoch: [ 1] [ 550/1582] time: 2798.4224, d_loss: 0.71747887, g_loss: 0.75445431\n",
      "Epoch: [ 1] [ 551/1582] time: 2799.6724, d_loss: 0.69527948, g_loss: 0.73106205\n",
      "Epoch: [ 1] [ 552/1582] time: 2800.9248, d_loss: 0.75298131, g_loss: 0.73011214\n",
      "Epoch: [ 1] [ 553/1582] time: 2802.1758, d_loss: 0.80263841, g_loss: 0.68459862\n",
      "Epoch: [ 1] [ 554/1582] time: 2803.4307, d_loss: 0.85633278, g_loss: 0.64180195\n",
      "Epoch: [ 1] [ 555/1582] time: 2804.6827, d_loss: 0.78177309, g_loss: 0.64062893\n",
      "Epoch: [ 1] [ 556/1582] time: 2805.9336, d_loss: 0.76724398, g_loss: 0.67231959\n",
      "Epoch: [ 1] [ 557/1582] time: 2807.1844, d_loss: 0.77844197, g_loss: 0.66391182\n",
      "Epoch: [ 1] [ 558/1582] time: 2808.4394, d_loss: 0.74596852, g_loss: 0.70793802\n",
      "Epoch: [ 1] [ 559/1582] time: 2809.6924, d_loss: 0.77958840, g_loss: 0.69105136\n",
      "Epoch: [ 1] [ 560/1582] time: 2810.9493, d_loss: 0.75678283, g_loss: 0.69723910\n",
      "Epoch: [ 1] [ 561/1582] time: 2812.1983, d_loss: 0.75948453, g_loss: 0.69800198\n",
      "Epoch: [ 1] [ 562/1582] time: 2813.4497, d_loss: 0.81401020, g_loss: 0.68920571\n",
      "Epoch: [ 1] [ 563/1582] time: 2814.7003, d_loss: 0.76693773, g_loss: 0.66134596\n",
      "Epoch: [ 1] [ 564/1582] time: 2815.9542, d_loss: 0.76841044, g_loss: 0.68737596\n",
      "Epoch: [ 1] [ 565/1582] time: 2817.2037, d_loss: 0.72784847, g_loss: 0.67906404\n",
      "Epoch: [ 1] [ 566/1582] time: 2818.4559, d_loss: 0.71919298, g_loss: 0.75042927\n",
      "Epoch: [ 1] [ 567/1582] time: 2819.7058, d_loss: 0.78232825, g_loss: 0.75533068\n",
      "Epoch: [ 1] [ 568/1582] time: 2820.9628, d_loss: 0.81850421, g_loss: 0.70052969\n",
      "Epoch: [ 1] [ 569/1582] time: 2822.2148, d_loss: 0.86314529, g_loss: 0.62010521\n",
      "Epoch: [ 1] [ 570/1582] time: 2823.4657, d_loss: 0.93497378, g_loss: 0.53727186\n",
      "Epoch: [ 1] [ 571/1582] time: 2824.7137, d_loss: 0.92527306, g_loss: 0.51712847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1] [ 572/1582] time: 2825.9671, d_loss: 0.93819249, g_loss: 0.50614172\n",
      "Epoch: [ 1] [ 573/1582] time: 2827.2155, d_loss: 0.92558712, g_loss: 0.55014330\n",
      "Epoch: [ 1] [ 574/1582] time: 2828.4668, d_loss: 0.88693917, g_loss: 0.55190837\n",
      "Epoch: [ 1] [ 575/1582] time: 2829.7172, d_loss: 0.89458781, g_loss: 0.58353317\n",
      "Epoch: [ 1] [ 576/1582] time: 2830.9701, d_loss: 0.83823490, g_loss: 0.61815941\n",
      "Epoch: [ 1] [ 577/1582] time: 2832.2201, d_loss: 0.84072500, g_loss: 0.62264538\n",
      "Epoch: [ 1] [ 578/1582] time: 2833.4711, d_loss: 0.79696417, g_loss: 0.64546382\n",
      "Epoch: [ 1] [ 579/1582] time: 2834.7231, d_loss: 0.77541399, g_loss: 0.67043734\n",
      "Epoch: [ 1] [ 580/1582] time: 2835.9770, d_loss: 0.77609098, g_loss: 0.67384970\n",
      "Epoch: [ 1] [ 581/1582] time: 2837.2270, d_loss: 0.71708310, g_loss: 0.71151829\n",
      "Epoch: [ 1] [ 582/1582] time: 2838.4799, d_loss: 0.73265344, g_loss: 0.73177606\n",
      "Epoch: [ 1] [ 583/1582] time: 2839.7289, d_loss: 0.72940046, g_loss: 0.75808156\n",
      "Epoch: [ 1] [ 584/1582] time: 2840.9809, d_loss: 0.70152968, g_loss: 0.77174616\n",
      "Epoch: [ 1] [ 585/1582] time: 2842.2325, d_loss: 0.78554797, g_loss: 0.73743653\n",
      "Epoch: [ 1] [ 586/1582] time: 2843.4844, d_loss: 0.75974643, g_loss: 0.71205032\n",
      "Epoch: [ 1] [ 587/1582] time: 2844.7328, d_loss: 0.74619168, g_loss: 0.72679448\n",
      "Epoch: [ 1] [ 588/1582] time: 2845.9847, d_loss: 0.71714711, g_loss: 0.76511419\n",
      "Epoch: [ 1] [ 589/1582] time: 2847.2333, d_loss: 0.70534050, g_loss: 0.79226458\n",
      "Epoch: [ 1] [ 590/1582] time: 2848.4872, d_loss: 0.61232507, g_loss: 0.86563617\n",
      "Epoch: [ 1] [ 591/1582] time: 2849.7359, d_loss: 0.64492756, g_loss: 0.92715943\n",
      "Epoch: [ 1] [ 592/1582] time: 2850.9888, d_loss: 0.61392230, g_loss: 0.92265564\n",
      "Epoch: [ 1] [ 593/1582] time: 2852.2378, d_loss: 0.60767865, g_loss: 0.95216966\n",
      "Epoch: [ 1] [ 594/1582] time: 2853.4917, d_loss: 0.59168237, g_loss: 0.95303446\n",
      "Epoch: [ 1] [ 595/1582] time: 2854.7412, d_loss: 0.66468358, g_loss: 0.90758771\n",
      "Epoch: [ 1] [ 596/1582] time: 2855.9940, d_loss: 0.66602075, g_loss: 0.83218354\n",
      "Epoch: [ 1] [ 597/1582] time: 2857.2440, d_loss: 0.63255614, g_loss: 0.83932835\n",
      "Epoch: [ 1] [ 598/1582] time: 2858.4939, d_loss: 0.69814336, g_loss: 0.80149561\n",
      "Epoch: [ 1] [ 599/1582] time: 2859.7429, d_loss: 0.82306737, g_loss: 0.74618727\n",
      "Epoch: [ 1] [ 600/1582] time: 2860.9936, d_loss: 0.83043879, g_loss: 0.64340287\n",
      "Epoch: [ 1] [ 601/1582] time: 2862.2566, d_loss: 0.90371430, g_loss: 0.57983363\n",
      "Epoch: [ 1] [ 602/1582] time: 2863.5295, d_loss: 0.93239772, g_loss: 0.56662595\n",
      "Epoch: [ 1] [ 603/1582] time: 2864.7855, d_loss: 0.93682760, g_loss: 0.55358088\n",
      "Epoch: [ 1] [ 604/1582] time: 2866.0385, d_loss: 0.81746089, g_loss: 0.62404931\n",
      "Epoch: [ 1] [ 605/1582] time: 2867.2904, d_loss: 0.82864201, g_loss: 0.69339871\n",
      "Epoch: [ 1] [ 606/1582] time: 2868.5409, d_loss: 0.70173824, g_loss: 0.76252675\n",
      "Epoch: [ 1] [ 607/1582] time: 2869.7899, d_loss: 0.79342324, g_loss: 0.76072621\n",
      "Epoch: [ 1] [ 608/1582] time: 2871.0448, d_loss: 0.76121271, g_loss: 0.77882862\n",
      "Epoch: [ 1] [ 609/1582] time: 2872.2938, d_loss: 0.69643068, g_loss: 0.79459488\n",
      "Epoch: [ 1] [ 610/1582] time: 2873.5468, d_loss: 0.65461779, g_loss: 0.79524243\n",
      "Epoch: [ 1] [ 611/1582] time: 2874.7957, d_loss: 0.72437251, g_loss: 0.80143785\n",
      "Epoch: [ 1] [ 612/1582] time: 2876.0467, d_loss: 0.76641864, g_loss: 0.78984344\n",
      "Epoch: [ 1] [ 613/1582] time: 2877.2967, d_loss: 0.79937106, g_loss: 0.73387992\n",
      "Epoch: [ 1] [ 614/1582] time: 2878.5486, d_loss: 0.77463531, g_loss: 0.73315555\n",
      "Epoch: [ 1] [ 615/1582] time: 2879.7996, d_loss: 0.79588878, g_loss: 0.72465020\n",
      "Epoch: [ 1] [ 616/1582] time: 2881.0545, d_loss: 0.85934681, g_loss: 0.69790667\n",
      "Epoch: [ 1] [ 617/1582] time: 2882.3055, d_loss: 0.81902808, g_loss: 0.68258870\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 1] [ 618/1582] time: 2890.8337, d_loss: 0.74266469, g_loss: 0.74723923\n",
      "Epoch: [ 1] [ 619/1582] time: 2892.0817, d_loss: 0.70945334, g_loss: 0.77482665\n",
      "Epoch: [ 1] [ 620/1582] time: 2893.3347, d_loss: 0.69276321, g_loss: 0.80593562\n",
      "Epoch: [ 1] [ 621/1582] time: 2894.5841, d_loss: 0.76120204, g_loss: 0.84198594\n",
      "Epoch: [ 1] [ 622/1582] time: 2895.8351, d_loss: 0.69834328, g_loss: 0.84784734\n",
      "Epoch: [ 1] [ 623/1582] time: 2897.0900, d_loss: 0.83025080, g_loss: 0.77914357\n",
      "Epoch: [ 1] [ 624/1582] time: 2898.3440, d_loss: 0.76831627, g_loss: 0.71159428\n",
      "Epoch: [ 1] [ 625/1582] time: 2899.5960, d_loss: 0.96231019, g_loss: 0.63084358\n",
      "Epoch: [ 1] [ 626/1582] time: 2900.8531, d_loss: 0.89497668, g_loss: 0.59907538\n",
      "Epoch: [ 1] [ 627/1582] time: 2902.1071, d_loss: 0.80357778, g_loss: 0.61594969\n",
      "Epoch: [ 1] [ 628/1582] time: 2903.3581, d_loss: 0.71993625, g_loss: 0.67711806\n",
      "Epoch: [ 1] [ 629/1582] time: 2904.6130, d_loss: 0.82638717, g_loss: 0.72757936\n",
      "Epoch: [ 1] [ 630/1582] time: 2905.8720, d_loss: 0.69746953, g_loss: 0.82721925\n",
      "Epoch: [ 1] [ 631/1582] time: 2907.1309, d_loss: 0.62487060, g_loss: 0.92872459\n",
      "Epoch: [ 1] [ 632/1582] time: 2908.3894, d_loss: 0.59165597, g_loss: 1.00926542\n",
      "Epoch: [ 1] [ 633/1582] time: 2909.6499, d_loss: 0.66633511, g_loss: 0.98887444\n",
      "Epoch: [ 1] [ 634/1582] time: 2910.9068, d_loss: 0.64326465, g_loss: 0.90519428\n",
      "Epoch: [ 1] [ 635/1582] time: 2912.1658, d_loss: 0.56659734, g_loss: 0.94657969\n",
      "Epoch: [ 1] [ 636/1582] time: 2913.4247, d_loss: 0.65706617, g_loss: 0.85620713\n",
      "Epoch: [ 1] [ 637/1582] time: 2914.6786, d_loss: 0.65333247, g_loss: 0.83441049\n",
      "Epoch: [ 1] [ 638/1582] time: 2915.9328, d_loss: 0.76707387, g_loss: 0.75639826\n",
      "Epoch: [ 1] [ 639/1582] time: 2917.1847, d_loss: 0.83347797, g_loss: 0.71447378\n",
      "Epoch: [ 1] [ 640/1582] time: 2918.4360, d_loss: 0.78081751, g_loss: 0.68098617\n",
      "Epoch: [ 1] [ 641/1582] time: 2919.6880, d_loss: 0.95764041, g_loss: 0.63528192\n",
      "Epoch: [ 1] [ 642/1582] time: 2920.9410, d_loss: 0.91099679, g_loss: 0.58235723\n",
      "Epoch: [ 1] [ 643/1582] time: 2922.1922, d_loss: 0.98986018, g_loss: 0.54221952\n",
      "Epoch: [ 1] [ 644/1582] time: 2923.4441, d_loss: 1.05318379, g_loss: 0.48197621\n",
      "Epoch: [ 1] [ 645/1582] time: 2924.6971, d_loss: 1.07490838, g_loss: 0.47520408\n",
      "Epoch: [ 1] [ 646/1582] time: 2925.9514, d_loss: 1.02983749, g_loss: 0.47777021\n",
      "Epoch: [ 1] [ 647/1582] time: 2927.2004, d_loss: 1.06398678, g_loss: 0.46955788\n",
      "Epoch: [ 1] [ 648/1582] time: 2928.4553, d_loss: 1.14207327, g_loss: 0.42483643\n",
      "Epoch: [ 1] [ 649/1582] time: 2929.7114, d_loss: 1.08313918, g_loss: 0.42690718\n",
      "Epoch: [ 1] [ 650/1582] time: 2930.9688, d_loss: 1.07563102, g_loss: 0.42770711\n",
      "Epoch: [ 1] [ 651/1582] time: 2932.2239, d_loss: 1.04138029, g_loss: 0.46471137\n",
      "Epoch: [ 1] [ 652/1582] time: 2933.4792, d_loss: 1.04164076, g_loss: 0.47562346\n",
      "Epoch: [ 1] [ 653/1582] time: 2934.7322, d_loss: 0.99498516, g_loss: 0.50852239\n",
      "Epoch: [ 1] [ 654/1582] time: 2935.9911, d_loss: 0.98162776, g_loss: 0.52806836\n",
      "Epoch: [ 1] [ 655/1582] time: 2937.2472, d_loss: 0.96077561, g_loss: 0.50478089\n",
      "Epoch: [ 1] [ 656/1582] time: 2938.5029, d_loss: 0.90695149, g_loss: 0.54596305\n",
      "Epoch: [ 1] [ 657/1582] time: 2939.7577, d_loss: 0.84798026, g_loss: 0.58226997\n",
      "Epoch: [ 1] [ 658/1582] time: 2941.0146, d_loss: 0.79531074, g_loss: 0.61221391\n",
      "Epoch: [ 1] [ 659/1582] time: 2942.2676, d_loss: 0.78260756, g_loss: 0.69726700\n",
      "Epoch: [ 1] [ 660/1582] time: 2943.5205, d_loss: 0.76026917, g_loss: 0.71452051\n",
      "Epoch: [ 1] [ 661/1582] time: 2944.7715, d_loss: 0.64464438, g_loss: 0.77797341\n",
      "Epoch: [ 1] [ 662/1582] time: 2946.0242, d_loss: 0.67466700, g_loss: 0.82870746\n",
      "Epoch: [ 1] [ 663/1582] time: 2947.2792, d_loss: 0.60779542, g_loss: 0.86092812\n",
      "Epoch: [ 1] [ 664/1582] time: 2948.5341, d_loss: 0.59965843, g_loss: 0.89766157\n",
      "Epoch: [ 1] [ 665/1582] time: 2949.7891, d_loss: 0.61394018, g_loss: 0.93299669\n",
      "Epoch: [ 1] [ 666/1582] time: 2951.0420, d_loss: 0.55761385, g_loss: 0.97272968\n",
      "Epoch: [ 1] [ 667/1582] time: 2952.2942, d_loss: 0.60334408, g_loss: 0.94666797\n",
      "Epoch: [ 1] [ 668/1582] time: 2953.5482, d_loss: 0.58831942, g_loss: 0.91713601\n",
      "Epoch: [ 1] [ 669/1582] time: 2954.7973, d_loss: 0.53790754, g_loss: 0.95957363\n",
      "Epoch: [ 1] [ 670/1582] time: 2956.0492, d_loss: 0.57040501, g_loss: 0.99004281\n",
      "Epoch: [ 1] [ 671/1582] time: 2957.3002, d_loss: 0.59025770, g_loss: 0.92462158\n",
      "Epoch: [ 1] [ 672/1582] time: 2958.5541, d_loss: 0.62400812, g_loss: 0.91291976\n",
      "Epoch: [ 1] [ 673/1582] time: 2959.8091, d_loss: 0.58593041, g_loss: 0.91635066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1] [ 674/1582] time: 2961.0631, d_loss: 0.64909732, g_loss: 0.87503493\n",
      "Epoch: [ 1] [ 675/1582] time: 2962.3160, d_loss: 0.61019802, g_loss: 0.88014114\n",
      "Epoch: [ 1] [ 676/1582] time: 2963.5680, d_loss: 0.59626907, g_loss: 0.86748242\n",
      "Epoch: [ 1] [ 677/1582] time: 2964.8220, d_loss: 0.63292688, g_loss: 0.86338180\n",
      "Epoch: [ 1] [ 678/1582] time: 2966.0749, d_loss: 0.67492819, g_loss: 0.84276515\n",
      "Epoch: [ 1] [ 679/1582] time: 2967.3289, d_loss: 0.69877064, g_loss: 0.81149459\n",
      "Epoch: [ 1] [ 680/1582] time: 2968.5819, d_loss: 0.79895329, g_loss: 0.72285062\n",
      "Epoch: [ 1] [ 681/1582] time: 2969.8368, d_loss: 0.83415902, g_loss: 0.69356477\n",
      "Epoch: [ 1] [ 682/1582] time: 2971.0918, d_loss: 0.94548655, g_loss: 0.62151915\n",
      "Epoch: [ 1] [ 683/1582] time: 2972.3457, d_loss: 0.87996852, g_loss: 0.61049145\n",
      "Epoch: [ 1] [ 684/1582] time: 2973.5951, d_loss: 0.96681529, g_loss: 0.59186018\n",
      "Epoch: [ 1] [ 685/1582] time: 2974.8481, d_loss: 1.02224362, g_loss: 0.55035913\n",
      "Epoch: [ 1] [ 686/1582] time: 2976.1030, d_loss: 0.99500644, g_loss: 0.54598641\n",
      "Epoch: [ 1] [ 687/1582] time: 2977.3530, d_loss: 0.98961198, g_loss: 0.52200580\n",
      "Epoch: [ 1] [ 688/1582] time: 2978.6056, d_loss: 0.94602847, g_loss: 0.54929852\n",
      "Epoch: [ 1] [ 689/1582] time: 2979.8546, d_loss: 0.89704245, g_loss: 0.55064350\n",
      "Epoch: [ 1] [ 690/1582] time: 2981.1095, d_loss: 0.77290291, g_loss: 0.66325969\n",
      "Epoch: [ 1] [ 691/1582] time: 2982.3618, d_loss: 0.77730787, g_loss: 0.73709953\n",
      "Epoch: [ 1] [ 692/1582] time: 2983.6178, d_loss: 0.62985528, g_loss: 0.86626041\n",
      "Epoch: [ 1] [ 693/1582] time: 2984.8768, d_loss: 0.62882936, g_loss: 1.00020576\n",
      "Epoch: [ 1] [ 694/1582] time: 2986.1307, d_loss: 0.66579562, g_loss: 0.99285603\n",
      "Epoch: [ 1] [ 695/1582] time: 2987.3807, d_loss: 0.63345230, g_loss: 0.99669886\n",
      "Epoch: [ 1] [ 696/1582] time: 2988.6340, d_loss: 0.68676686, g_loss: 0.89061189\n",
      "Epoch: [ 1] [ 697/1582] time: 2989.8830, d_loss: 0.62011635, g_loss: 0.83681881\n",
      "Epoch: [ 1] [ 698/1582] time: 2991.1350, d_loss: 0.69386733, g_loss: 0.77342904\n",
      "Epoch: [ 1] [ 699/1582] time: 2992.3869, d_loss: 0.63397652, g_loss: 0.80193079\n",
      "Epoch: [ 1] [ 700/1582] time: 2993.6389, d_loss: 0.63924474, g_loss: 0.78280604\n",
      "Epoch: [ 1] [ 701/1582] time: 2994.8909, d_loss: 0.70000720, g_loss: 0.83757132\n",
      "Epoch: [ 1] [ 702/1582] time: 2996.1429, d_loss: 0.71173656, g_loss: 0.80394471\n",
      "Epoch: [ 1] [ 703/1582] time: 2997.3968, d_loss: 0.69521874, g_loss: 0.77017576\n",
      "Epoch: [ 1] [ 704/1582] time: 2998.6478, d_loss: 0.73406816, g_loss: 0.75363517\n",
      "Epoch: [ 1] [ 705/1582] time: 2999.9017, d_loss: 0.69063157, g_loss: 0.75116825\n",
      "Epoch: [ 1] [ 706/1582] time: 3001.1605, d_loss: 0.73588085, g_loss: 0.73866320\n",
      "Epoch: [ 1] [ 707/1582] time: 3002.4114, d_loss: 0.69213080, g_loss: 0.77160090\n",
      "Epoch: [ 1] [ 708/1582] time: 3003.6674, d_loss: 0.69678330, g_loss: 0.74882948\n",
      "Epoch: [ 1] [ 709/1582] time: 3004.9206, d_loss: 0.71244711, g_loss: 0.79498589\n",
      "Epoch: [ 1] [ 710/1582] time: 3006.1776, d_loss: 0.76173049, g_loss: 0.77082729\n",
      "Epoch: [ 1] [ 711/1582] time: 3007.4345, d_loss: 0.70015812, g_loss: 0.73719317\n",
      "Epoch: [ 1] [ 712/1582] time: 3008.6891, d_loss: 0.67293632, g_loss: 0.76187587\n",
      "Epoch: [ 1] [ 713/1582] time: 3009.9490, d_loss: 0.65242028, g_loss: 0.76044333\n",
      "Epoch: [ 1] [ 714/1582] time: 3011.2010, d_loss: 0.65642369, g_loss: 0.77755833\n",
      "Epoch: [ 1] [ 715/1582] time: 3012.4590, d_loss: 0.70585632, g_loss: 0.75682712\n",
      "Epoch: [ 1] [ 716/1582] time: 3013.7170, d_loss: 0.65982282, g_loss: 0.74308342\n",
      "Epoch: [ 1] [ 717/1582] time: 3014.9743, d_loss: 0.61082786, g_loss: 0.78218842\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 1] [ 718/1582] time: 3023.1183, d_loss: 0.63993919, g_loss: 0.83968854\n",
      "Epoch: [ 1] [ 719/1582] time: 3024.3692, d_loss: 0.65275323, g_loss: 0.82773435\n",
      "Epoch: [ 1] [ 720/1582] time: 3025.6232, d_loss: 0.62937486, g_loss: 0.83735514\n",
      "Epoch: [ 1] [ 721/1582] time: 3026.8751, d_loss: 0.65242296, g_loss: 0.81257582\n",
      "Epoch: [ 1] [ 722/1582] time: 3028.1341, d_loss: 0.69212395, g_loss: 0.78731126\n",
      "Epoch: [ 1] [ 723/1582] time: 3029.3880, d_loss: 0.69013768, g_loss: 0.74588835\n",
      "Epoch: [ 1] [ 724/1582] time: 3030.6440, d_loss: 0.64317751, g_loss: 0.78505343\n",
      "Epoch: [ 1] [ 725/1582] time: 3031.8960, d_loss: 0.68303239, g_loss: 0.76985401\n",
      "Epoch: [ 1] [ 726/1582] time: 3033.1477, d_loss: 0.63069755, g_loss: 0.78346336\n",
      "Epoch: [ 1] [ 727/1582] time: 3034.4006, d_loss: 0.72010756, g_loss: 0.79891706\n",
      "Epoch: [ 1] [ 728/1582] time: 3035.6506, d_loss: 0.68384939, g_loss: 0.79812908\n",
      "Epoch: [ 1] [ 729/1582] time: 3036.9036, d_loss: 0.74148083, g_loss: 0.78351462\n",
      "Epoch: [ 1] [ 730/1582] time: 3038.1555, d_loss: 0.82183760, g_loss: 0.68338883\n",
      "Epoch: [ 1] [ 731/1582] time: 3039.4065, d_loss: 0.84389079, g_loss: 0.66231906\n",
      "Epoch: [ 1] [ 732/1582] time: 3040.6596, d_loss: 0.86088663, g_loss: 0.66610444\n",
      "Epoch: [ 1] [ 733/1582] time: 3041.9135, d_loss: 0.84978724, g_loss: 0.62476265\n",
      "Epoch: [ 1] [ 734/1582] time: 3043.1685, d_loss: 0.99211109, g_loss: 0.61855954\n",
      "Epoch: [ 1] [ 735/1582] time: 3044.4224, d_loss: 0.93783617, g_loss: 0.59219909\n",
      "Epoch: [ 1] [ 736/1582] time: 3045.6774, d_loss: 0.80390346, g_loss: 0.64634538\n",
      "Epoch: [ 1] [ 737/1582] time: 3046.9314, d_loss: 0.89975965, g_loss: 0.68083847\n",
      "Epoch: [ 1] [ 738/1582] time: 3048.1875, d_loss: 0.89108646, g_loss: 0.62009358\n",
      "Epoch: [ 1] [ 739/1582] time: 3049.4405, d_loss: 0.91908723, g_loss: 0.71534324\n",
      "Epoch: [ 1] [ 740/1582] time: 3050.6962, d_loss: 0.93355823, g_loss: 0.71435332\n",
      "Epoch: [ 1] [ 741/1582] time: 3051.9482, d_loss: 0.83213711, g_loss: 0.72935164\n",
      "Epoch: [ 1] [ 742/1582] time: 3053.2007, d_loss: 0.82446682, g_loss: 0.73780215\n",
      "Epoch: [ 1] [ 743/1582] time: 3054.4517, d_loss: 0.85735667, g_loss: 0.67399126\n",
      "Epoch: [ 1] [ 744/1582] time: 3055.7060, d_loss: 0.87228435, g_loss: 0.70416629\n",
      "Epoch: [ 1] [ 745/1582] time: 3056.9590, d_loss: 0.93802792, g_loss: 0.63331699\n",
      "Epoch: [ 1] [ 746/1582] time: 3058.2136, d_loss: 0.93104732, g_loss: 0.56092894\n",
      "Epoch: [ 1] [ 747/1582] time: 3059.4699, d_loss: 1.06515861, g_loss: 0.47220266\n",
      "Epoch: [ 1] [ 748/1582] time: 3060.7279, d_loss: 1.01013982, g_loss: 0.44268328\n",
      "Epoch: [ 1] [ 749/1582] time: 3061.9838, d_loss: 0.95715690, g_loss: 0.51212257\n",
      "Epoch: [ 1] [ 750/1582] time: 3063.2403, d_loss: 0.93245614, g_loss: 0.55107951\n",
      "Epoch: [ 1] [ 751/1582] time: 3064.4943, d_loss: 0.85907328, g_loss: 0.61120218\n",
      "Epoch: [ 1] [ 752/1582] time: 3065.7512, d_loss: 0.77253401, g_loss: 0.74579573\n",
      "Epoch: [ 1] [ 753/1582] time: 3067.0062, d_loss: 0.71852261, g_loss: 0.84721547\n",
      "Epoch: [ 1] [ 754/1582] time: 3068.2617, d_loss: 0.75048280, g_loss: 0.93249452\n",
      "Epoch: [ 1] [ 755/1582] time: 3069.5200, d_loss: 0.75157976, g_loss: 0.89521730\n",
      "Epoch: [ 1] [ 756/1582] time: 3070.7779, d_loss: 0.77086061, g_loss: 0.81610662\n",
      "Epoch: [ 1] [ 757/1582] time: 3072.0309, d_loss: 0.70987177, g_loss: 0.79074550\n",
      "Epoch: [ 1] [ 758/1582] time: 3073.2849, d_loss: 0.73940730, g_loss: 0.75623780\n",
      "Epoch: [ 1] [ 759/1582] time: 3074.5359, d_loss: 0.78688723, g_loss: 0.69839317\n",
      "Epoch: [ 1] [ 760/1582] time: 3075.7913, d_loss: 0.75096267, g_loss: 0.70183372\n",
      "Epoch: [ 1] [ 761/1582] time: 3077.0458, d_loss: 0.77649105, g_loss: 0.72381318\n",
      "Epoch: [ 1] [ 762/1582] time: 3078.3023, d_loss: 0.70068109, g_loss: 0.75641453\n",
      "Epoch: [ 1] [ 763/1582] time: 3079.5593, d_loss: 0.80095506, g_loss: 0.77501535\n",
      "Epoch: [ 1] [ 764/1582] time: 3080.8172, d_loss: 0.75764728, g_loss: 0.77485526\n",
      "Epoch: [ 1] [ 765/1582] time: 3082.0742, d_loss: 0.84667957, g_loss: 0.70617044\n",
      "Epoch: [ 1] [ 766/1582] time: 3083.3311, d_loss: 0.83756572, g_loss: 0.69108796\n",
      "Epoch: [ 1] [ 767/1582] time: 3084.5855, d_loss: 0.83123255, g_loss: 0.68810469\n",
      "Epoch: [ 1] [ 768/1582] time: 3085.8415, d_loss: 0.84003061, g_loss: 0.67235744\n",
      "Epoch: [ 1] [ 769/1582] time: 3087.0984, d_loss: 0.77750927, g_loss: 0.72500765\n",
      "Epoch: [ 1] [ 770/1582] time: 3088.3554, d_loss: 0.80175024, g_loss: 0.72341257\n",
      "Epoch: [ 1] [ 771/1582] time: 3089.6103, d_loss: 0.79875237, g_loss: 0.71387672\n",
      "Epoch: [ 1] [ 772/1582] time: 3090.8683, d_loss: 0.73586977, g_loss: 0.79142582\n",
      "Epoch: [ 1] [ 773/1582] time: 3092.1233, d_loss: 0.70330524, g_loss: 0.80774438\n",
      "Epoch: [ 1] [ 774/1582] time: 3093.3797, d_loss: 0.67480546, g_loss: 0.84553564\n",
      "Epoch: [ 1] [ 775/1582] time: 3094.6348, d_loss: 0.70434642, g_loss: 0.81691563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1] [ 776/1582] time: 3095.8898, d_loss: 0.56754953, g_loss: 0.92179239\n",
      "Epoch: [ 1] [ 777/1582] time: 3097.1428, d_loss: 0.64294714, g_loss: 0.93697780\n",
      "Epoch: [ 1] [ 778/1582] time: 3098.3977, d_loss: 0.59689891, g_loss: 0.88483340\n",
      "Epoch: [ 1] [ 779/1582] time: 3099.6527, d_loss: 0.61836624, g_loss: 0.87171483\n",
      "Epoch: [ 1] [ 780/1582] time: 3100.9084, d_loss: 0.57045960, g_loss: 0.88486010\n",
      "Epoch: [ 1] [ 781/1582] time: 3102.1634, d_loss: 0.56069607, g_loss: 0.93662721\n",
      "Epoch: [ 1] [ 782/1582] time: 3103.4243, d_loss: 0.60329759, g_loss: 0.95576036\n",
      "Epoch: [ 1] [ 783/1582] time: 3104.6804, d_loss: 0.54120088, g_loss: 0.92051446\n",
      "Epoch: [ 1] [ 784/1582] time: 3105.9373, d_loss: 0.81826442, g_loss: 0.69426477\n",
      "Epoch: [ 1] [ 785/1582] time: 3107.1928, d_loss: 1.09986365, g_loss: 0.47052437\n",
      "Epoch: [ 1] [ 786/1582] time: 3108.4488, d_loss: 1.40204811, g_loss: 0.34215271\n",
      "Epoch: [ 1] [ 787/1582] time: 3109.7037, d_loss: 1.53456461, g_loss: 0.27008724\n",
      "Epoch: [ 1] [ 788/1582] time: 3110.9577, d_loss: 1.64531147, g_loss: 0.29707617\n",
      "Epoch: [ 1] [ 789/1582] time: 3112.2117, d_loss: 1.44488442, g_loss: 0.37275741\n",
      "Epoch: [ 1] [ 790/1582] time: 3113.4666, d_loss: 1.01708269, g_loss: 0.68373442\n",
      "Epoch: [ 1] [ 791/1582] time: 3114.7216, d_loss: 0.62705112, g_loss: 1.17857587\n",
      "Epoch: [ 1] [ 792/1582] time: 3115.9766, d_loss: 0.49164391, g_loss: 1.77755547\n",
      "Epoch: [ 1] [ 793/1582] time: 3117.2315, d_loss: 0.38966107, g_loss: 2.22006679\n",
      "Epoch: [ 1] [ 794/1582] time: 3118.4845, d_loss: 0.32043856, g_loss: 2.42339945\n",
      "Epoch: [ 1] [ 795/1582] time: 3119.7374, d_loss: 0.40200895, g_loss: 2.24419594\n",
      "Epoch: [ 1] [ 796/1582] time: 3120.9934, d_loss: 0.29043877, g_loss: 1.98395407\n",
      "Epoch: [ 1] [ 797/1582] time: 3122.2469, d_loss: 0.41626176, g_loss: 1.51611328\n",
      "Epoch: [ 1] [ 798/1582] time: 3123.4998, d_loss: 0.54632646, g_loss: 1.19279408\n",
      "Epoch: [ 1] [ 799/1582] time: 3124.7548, d_loss: 0.55474484, g_loss: 0.95856023\n",
      "Epoch: [ 1] [ 800/1582] time: 3126.0108, d_loss: 0.93319851, g_loss: 0.64244735\n",
      "Epoch: [ 1] [ 801/1582] time: 3127.2657, d_loss: 1.13542175, g_loss: 0.45419347\n",
      "Epoch: [ 1] [ 802/1582] time: 3128.5207, d_loss: 1.35966635, g_loss: 0.38943088\n",
      "Epoch: [ 1] [ 803/1582] time: 3129.7766, d_loss: 1.42659998, g_loss: 0.38085118\n",
      "Epoch: [ 1] [ 804/1582] time: 3131.0336, d_loss: 1.43644094, g_loss: 0.39673412\n",
      "Epoch: [ 1] [ 805/1582] time: 3132.2846, d_loss: 1.39364743, g_loss: 0.46542922\n",
      "Epoch: [ 1] [ 806/1582] time: 3133.5349, d_loss: 1.37230158, g_loss: 0.53706872\n",
      "Epoch: [ 1] [ 807/1582] time: 3134.7869, d_loss: 1.30635393, g_loss: 0.57298189\n",
      "Epoch: [ 1] [ 808/1582] time: 3136.0400, d_loss: 1.33137751, g_loss: 0.53720397\n",
      "Epoch: [ 1] [ 809/1582] time: 3137.2940, d_loss: 1.24720168, g_loss: 0.55129826\n",
      "Epoch: [ 1] [ 810/1582] time: 3138.5470, d_loss: 1.26545906, g_loss: 0.52848321\n",
      "Epoch: [ 1] [ 811/1582] time: 3139.8009, d_loss: 1.23368239, g_loss: 0.50017422\n",
      "Epoch: [ 1] [ 812/1582] time: 3141.0549, d_loss: 1.07285917, g_loss: 0.47821549\n",
      "Epoch: [ 1] [ 813/1582] time: 3142.3088, d_loss: 1.09941697, g_loss: 0.47774220\n",
      "Epoch: [ 1] [ 814/1582] time: 3143.5629, d_loss: 1.03071237, g_loss: 0.52331090\n",
      "Epoch: [ 1] [ 815/1582] time: 3144.8165, d_loss: 0.90244067, g_loss: 0.60668111\n",
      "Epoch: [ 1] [ 816/1582] time: 3146.0735, d_loss: 0.95318550, g_loss: 0.57937884\n",
      "Epoch: [ 1] [ 817/1582] time: 3147.3276, d_loss: 0.95682943, g_loss: 0.60663116\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 1] [ 818/1582] time: 3155.4737, d_loss: 1.02471614, g_loss: 0.53694266\n",
      "Epoch: [ 1] [ 819/1582] time: 3156.7207, d_loss: 1.01689529, g_loss: 0.53596920\n",
      "Epoch: [ 1] [ 820/1582] time: 3157.9740, d_loss: 1.02056634, g_loss: 0.50193495\n",
      "Epoch: [ 1] [ 821/1582] time: 3159.2270, d_loss: 1.06573069, g_loss: 0.48718941\n",
      "Epoch: [ 1] [ 822/1582] time: 3160.4810, d_loss: 1.05170214, g_loss: 0.45533270\n",
      "Epoch: [ 1] [ 823/1582] time: 3161.7339, d_loss: 1.08548403, g_loss: 0.43745211\n",
      "Epoch: [ 1] [ 824/1582] time: 3162.9869, d_loss: 1.12139475, g_loss: 0.42547041\n",
      "Epoch: [ 1] [ 825/1582] time: 3164.2398, d_loss: 1.01051819, g_loss: 0.44258705\n",
      "Epoch: [ 1] [ 826/1582] time: 3165.4928, d_loss: 1.00825393, g_loss: 0.47528958\n",
      "Epoch: [ 1] [ 827/1582] time: 3166.7457, d_loss: 0.92006028, g_loss: 0.53026545\n",
      "Epoch: [ 1] [ 828/1582] time: 3167.9987, d_loss: 0.86128104, g_loss: 0.60068291\n",
      "Epoch: [ 1] [ 829/1582] time: 3169.2500, d_loss: 0.85964274, g_loss: 0.63875866\n",
      "Epoch: [ 1] [ 830/1582] time: 3170.5030, d_loss: 0.81122911, g_loss: 0.65709406\n",
      "Epoch: [ 1] [ 831/1582] time: 3171.7554, d_loss: 0.73960745, g_loss: 0.72754890\n",
      "Epoch: [ 1] [ 832/1582] time: 3173.0094, d_loss: 0.78762013, g_loss: 0.70753777\n",
      "Epoch: [ 1] [ 833/1582] time: 3174.2624, d_loss: 0.69498432, g_loss: 0.73465955\n",
      "Epoch: [ 1] [ 834/1582] time: 3175.5164, d_loss: 0.68221116, g_loss: 0.77404267\n",
      "Epoch: [ 1] [ 835/1582] time: 3176.7663, d_loss: 0.68179882, g_loss: 0.81315696\n",
      "Epoch: [ 1] [ 836/1582] time: 3178.0172, d_loss: 0.65511894, g_loss: 0.82274377\n",
      "Epoch: [ 1] [ 837/1582] time: 3179.2697, d_loss: 0.65947545, g_loss: 0.83265281\n",
      "Epoch: [ 1] [ 838/1582] time: 3180.5196, d_loss: 0.66654265, g_loss: 0.81603789\n",
      "Epoch: [ 1] [ 839/1582] time: 3181.7696, d_loss: 0.65880126, g_loss: 0.79204702\n",
      "Epoch: [ 1] [ 840/1582] time: 3183.0225, d_loss: 0.66394991, g_loss: 0.79881340\n",
      "Epoch: [ 1] [ 841/1582] time: 3184.2725, d_loss: 0.57562745, g_loss: 0.83217299\n",
      "Epoch: [ 1] [ 842/1582] time: 3185.5244, d_loss: 0.58967149, g_loss: 0.87802470\n",
      "Epoch: [ 1] [ 843/1582] time: 3186.7773, d_loss: 0.57179284, g_loss: 0.91972679\n",
      "Epoch: [ 1] [ 844/1582] time: 3188.0313, d_loss: 0.59053874, g_loss: 0.96301723\n",
      "Epoch: [ 1] [ 845/1582] time: 3189.2853, d_loss: 0.55591059, g_loss: 0.97557771\n",
      "Epoch: [ 1] [ 846/1582] time: 3190.5402, d_loss: 0.53880310, g_loss: 1.01204467\n",
      "Epoch: [ 1] [ 847/1582] time: 3191.7902, d_loss: 0.60001028, g_loss: 0.92646778\n",
      "Epoch: [ 1] [ 848/1582] time: 3193.0452, d_loss: 0.61689478, g_loss: 0.83542776\n",
      "Epoch: [ 1] [ 849/1582] time: 3194.2971, d_loss: 0.65947342, g_loss: 0.81747591\n",
      "Epoch: [ 1] [ 850/1582] time: 3195.5511, d_loss: 0.69532835, g_loss: 0.76408666\n",
      "Epoch: [ 1] [ 851/1582] time: 3196.8030, d_loss: 0.70276153, g_loss: 0.73529887\n",
      "Epoch: [ 1] [ 852/1582] time: 3198.0570, d_loss: 0.74021667, g_loss: 0.72078085\n",
      "Epoch: [ 1] [ 853/1582] time: 3199.3070, d_loss: 0.74776220, g_loss: 0.68688357\n",
      "Epoch: [ 1] [ 854/1582] time: 3200.5589, d_loss: 0.85564446, g_loss: 0.65049350\n",
      "Epoch: [ 1] [ 855/1582] time: 3201.8109, d_loss: 0.94550276, g_loss: 0.60515952\n",
      "Epoch: [ 1] [ 856/1582] time: 3203.0628, d_loss: 0.88620681, g_loss: 0.61516035\n",
      "Epoch: [ 1] [ 857/1582] time: 3204.3148, d_loss: 1.06417072, g_loss: 0.58190042\n",
      "Epoch: [ 1] [ 858/1582] time: 3205.5678, d_loss: 1.07742763, g_loss: 0.52248967\n",
      "Epoch: [ 1] [ 859/1582] time: 3206.8177, d_loss: 1.20563805, g_loss: 0.46567941\n",
      "Epoch: [ 1] [ 860/1582] time: 3208.0727, d_loss: 1.12863290, g_loss: 0.45795515\n",
      "Epoch: [ 1] [ 861/1582] time: 3209.3266, d_loss: 1.19456816, g_loss: 0.45690668\n",
      "Epoch: [ 1] [ 862/1582] time: 3210.5796, d_loss: 1.14514863, g_loss: 0.43791813\n",
      "Epoch: [ 1] [ 863/1582] time: 3211.8296, d_loss: 1.21290302, g_loss: 0.43730509\n",
      "Epoch: [ 1] [ 864/1582] time: 3213.0825, d_loss: 1.17615759, g_loss: 0.40633106\n",
      "Epoch: [ 1] [ 865/1582] time: 3214.3343, d_loss: 1.05733442, g_loss: 0.45622814\n",
      "Epoch: [ 1] [ 866/1582] time: 3215.5873, d_loss: 1.12641847, g_loss: 0.45727775\n",
      "Epoch: [ 1] [ 867/1582] time: 3216.8393, d_loss: 0.99511898, g_loss: 0.55100548\n",
      "Epoch: [ 1] [ 868/1582] time: 3218.0952, d_loss: 0.91481709, g_loss: 0.63603646\n",
      "Epoch: [ 1] [ 869/1582] time: 3219.3472, d_loss: 0.90260386, g_loss: 0.70000815\n",
      "Epoch: [ 1] [ 870/1582] time: 3220.6012, d_loss: 0.88369054, g_loss: 0.75504798\n",
      "Epoch: [ 1] [ 871/1582] time: 3221.8541, d_loss: 0.80632520, g_loss: 0.75442708\n",
      "Epoch: [ 1] [ 872/1582] time: 3223.1176, d_loss: 0.83305919, g_loss: 0.67843127\n",
      "Epoch: [ 1] [ 873/1582] time: 3224.3716, d_loss: 0.87477833, g_loss: 0.61333728\n",
      "Epoch: [ 1] [ 874/1582] time: 3225.6295, d_loss: 0.92095244, g_loss: 0.52979112\n",
      "Epoch: [ 1] [ 875/1582] time: 3226.8818, d_loss: 0.87472069, g_loss: 0.54084104\n",
      "Epoch: [ 1] [ 876/1582] time: 3228.1377, d_loss: 0.86527020, g_loss: 0.52738023\n",
      "Epoch: [ 1] [ 877/1582] time: 3229.3917, d_loss: 0.80099320, g_loss: 0.58999056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1] [ 878/1582] time: 3230.6458, d_loss: 0.81811112, g_loss: 0.60571444\n",
      "Epoch: [ 1] [ 879/1582] time: 3231.8988, d_loss: 0.73485661, g_loss: 0.66870487\n",
      "Epoch: [ 1] [ 880/1582] time: 3233.1557, d_loss: 0.76497978, g_loss: 0.67465293\n",
      "Epoch: [ 1] [ 881/1582] time: 3234.4097, d_loss: 0.75277805, g_loss: 0.69845569\n",
      "Epoch: [ 1] [ 882/1582] time: 3235.6637, d_loss: 0.75946128, g_loss: 0.70352519\n",
      "Epoch: [ 1] [ 883/1582] time: 3236.9177, d_loss: 0.73411334, g_loss: 0.71137124\n",
      "Epoch: [ 1] [ 884/1582] time: 3238.1726, d_loss: 0.76284885, g_loss: 0.66518718\n",
      "Epoch: [ 1] [ 885/1582] time: 3239.4256, d_loss: 0.79112458, g_loss: 0.65496874\n",
      "Epoch: [ 1] [ 886/1582] time: 3240.6805, d_loss: 0.78245836, g_loss: 0.67054152\n",
      "Epoch: [ 1] [ 887/1582] time: 3241.9335, d_loss: 0.76918525, g_loss: 0.65762138\n",
      "Epoch: [ 1] [ 888/1582] time: 3243.1897, d_loss: 0.76941800, g_loss: 0.61693603\n",
      "Epoch: [ 1] [ 889/1582] time: 3244.4416, d_loss: 0.76419163, g_loss: 0.65573096\n",
      "Epoch: [ 1] [ 890/1582] time: 3245.6966, d_loss: 0.86709309, g_loss: 0.59494084\n",
      "Epoch: [ 1] [ 891/1582] time: 3246.9486, d_loss: 0.87736857, g_loss: 0.58570635\n",
      "Epoch: [ 1] [ 892/1582] time: 3248.2042, d_loss: 0.93821853, g_loss: 0.50272298\n",
      "Epoch: [ 1] [ 893/1582] time: 3249.4592, d_loss: 0.90767235, g_loss: 0.49918276\n",
      "Epoch: [ 1] [ 894/1582] time: 3250.7155, d_loss: 0.97296929, g_loss: 0.50345027\n",
      "Epoch: [ 1] [ 895/1582] time: 3251.9715, d_loss: 0.95012486, g_loss: 0.51414752\n",
      "Epoch: [ 1] [ 896/1582] time: 3253.2275, d_loss: 0.96998996, g_loss: 0.50289768\n",
      "Epoch: [ 1] [ 897/1582] time: 3254.4824, d_loss: 0.96044713, g_loss: 0.52814204\n",
      "Epoch: [ 1] [ 898/1582] time: 3255.7394, d_loss: 0.86950254, g_loss: 0.58935583\n",
      "Epoch: [ 1] [ 899/1582] time: 3256.9943, d_loss: 0.89666498, g_loss: 0.59966695\n",
      "Epoch: [ 1] [ 900/1582] time: 3258.2473, d_loss: 0.94222116, g_loss: 0.58259082\n",
      "Epoch: [ 1] [ 901/1582] time: 3259.4983, d_loss: 0.93178368, g_loss: 0.58736277\n",
      "Epoch: [ 1] [ 902/1582] time: 3260.7512, d_loss: 0.91697621, g_loss: 0.59760910\n",
      "Epoch: [ 1] [ 903/1582] time: 3262.0042, d_loss: 0.84399450, g_loss: 0.59949666\n",
      "Epoch: [ 1] [ 904/1582] time: 3263.2562, d_loss: 0.83056813, g_loss: 0.61496270\n",
      "Epoch: [ 1] [ 905/1582] time: 3264.5111, d_loss: 0.81040001, g_loss: 0.68678284\n",
      "Epoch: [ 1] [ 906/1582] time: 3265.7681, d_loss: 0.79303861, g_loss: 0.69808459\n",
      "Epoch: [ 1] [ 907/1582] time: 3267.0201, d_loss: 0.78511757, g_loss: 0.70548564\n",
      "Epoch: [ 1] [ 908/1582] time: 3268.2761, d_loss: 0.68365377, g_loss: 0.77402496\n",
      "Epoch: [ 1] [ 909/1582] time: 3269.5331, d_loss: 0.72878969, g_loss: 0.76228166\n",
      "Epoch: [ 1] [ 910/1582] time: 3270.7880, d_loss: 0.66462958, g_loss: 0.80508482\n",
      "Epoch: [ 1] [ 911/1582] time: 3272.0450, d_loss: 0.68877780, g_loss: 0.80702567\n",
      "Epoch: [ 1] [ 912/1582] time: 3273.2987, d_loss: 0.67892772, g_loss: 0.81189799\n",
      "Epoch: [ 1] [ 913/1582] time: 3274.5527, d_loss: 0.69626606, g_loss: 0.77608055\n",
      "Epoch: [ 1] [ 914/1582] time: 3275.8067, d_loss: 0.72083914, g_loss: 0.75271857\n",
      "Epoch: [ 1] [ 915/1582] time: 3277.0616, d_loss: 0.75295800, g_loss: 0.72415227\n",
      "Epoch: [ 1] [ 916/1582] time: 3278.3155, d_loss: 0.69319725, g_loss: 0.71599388\n",
      "Epoch: [ 1] [ 917/1582] time: 3279.5665, d_loss: 0.78301585, g_loss: 0.67806548\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 1] [ 918/1582] time: 3287.6564, d_loss: 0.79640692, g_loss: 0.68040800\n",
      "Epoch: [ 1] [ 919/1582] time: 3288.9064, d_loss: 0.73815036, g_loss: 0.67490351\n",
      "Epoch: [ 1] [ 920/1582] time: 3290.1613, d_loss: 0.82174891, g_loss: 0.63199037\n",
      "Epoch: [ 1] [ 921/1582] time: 3291.4183, d_loss: 0.83702397, g_loss: 0.58556652\n",
      "Epoch: [ 1] [ 922/1582] time: 3292.6715, d_loss: 0.82663995, g_loss: 0.60507172\n",
      "Epoch: [ 1] [ 923/1582] time: 3293.9223, d_loss: 0.80292332, g_loss: 0.61242872\n",
      "Epoch: [ 1] [ 924/1582] time: 3295.1760, d_loss: 0.81227160, g_loss: 0.62114459\n",
      "Epoch: [ 1] [ 925/1582] time: 3296.4269, d_loss: 0.84147298, g_loss: 0.62701595\n",
      "Epoch: [ 1] [ 926/1582] time: 3297.6809, d_loss: 0.75952047, g_loss: 0.65797651\n",
      "Epoch: [ 1] [ 927/1582] time: 3298.9339, d_loss: 0.72293943, g_loss: 0.70815498\n",
      "Epoch: [ 1] [ 928/1582] time: 3300.1888, d_loss: 0.70020330, g_loss: 0.73045492\n",
      "Epoch: [ 1] [ 929/1582] time: 3301.4418, d_loss: 0.69268602, g_loss: 0.77429521\n",
      "Epoch: [ 1] [ 930/1582] time: 3302.6969, d_loss: 0.73441648, g_loss: 0.78751963\n",
      "Epoch: [ 1] [ 931/1582] time: 3303.9504, d_loss: 0.69036794, g_loss: 0.79066658\n",
      "Epoch: [ 1] [ 932/1582] time: 3305.2054, d_loss: 0.66907102, g_loss: 0.79717582\n",
      "Epoch: [ 1] [ 933/1582] time: 3306.4599, d_loss: 0.61221629, g_loss: 0.80990922\n",
      "Epoch: [ 1] [ 934/1582] time: 3307.7150, d_loss: 0.58783764, g_loss: 0.84056795\n",
      "Epoch: [ 1] [ 935/1582] time: 3308.9669, d_loss: 0.59172535, g_loss: 0.88504696\n",
      "Epoch: [ 1] [ 936/1582] time: 3310.2249, d_loss: 0.55262387, g_loss: 0.90649307\n",
      "Epoch: [ 1] [ 937/1582] time: 3311.4798, d_loss: 0.53402972, g_loss: 0.93563813\n",
      "Epoch: [ 1] [ 938/1582] time: 3312.7308, d_loss: 0.51540190, g_loss: 0.99962211\n",
      "Epoch: [ 1] [ 939/1582] time: 3313.9828, d_loss: 0.49404916, g_loss: 1.02390432\n",
      "Epoch: [ 1] [ 940/1582] time: 3315.2347, d_loss: 0.56585371, g_loss: 0.99740762\n",
      "Epoch: [ 1] [ 941/1582] time: 3316.4862, d_loss: 0.52583790, g_loss: 0.95925236\n",
      "Epoch: [ 1] [ 942/1582] time: 3317.7391, d_loss: 0.52407992, g_loss: 0.97597241\n",
      "Epoch: [ 1] [ 943/1582] time: 3318.9911, d_loss: 0.54509813, g_loss: 0.93512440\n",
      "Epoch: [ 1] [ 944/1582] time: 3320.2441, d_loss: 0.57567716, g_loss: 0.85082370\n",
      "Epoch: [ 1] [ 945/1582] time: 3321.4946, d_loss: 0.57771182, g_loss: 0.85913301\n",
      "Epoch: [ 1] [ 946/1582] time: 3322.7536, d_loss: 0.56971294, g_loss: 0.84697187\n",
      "Epoch: [ 1] [ 947/1582] time: 3324.0102, d_loss: 0.61059570, g_loss: 0.82329434\n",
      "Epoch: [ 1] [ 948/1582] time: 3325.2672, d_loss: 0.59766638, g_loss: 0.85453761\n",
      "Epoch: [ 1] [ 949/1582] time: 3326.5212, d_loss: 0.70518398, g_loss: 0.81200862\n",
      "Epoch: [ 1] [ 950/1582] time: 3327.7771, d_loss: 0.78187400, g_loss: 0.67163134\n",
      "Epoch: [ 1] [ 951/1582] time: 3329.0332, d_loss: 1.01631153, g_loss: 0.56370258\n",
      "Epoch: [ 1] [ 952/1582] time: 3330.2871, d_loss: 1.25144267, g_loss: 0.45423621\n",
      "Epoch: [ 1] [ 953/1582] time: 3331.5391, d_loss: 1.37675357, g_loss: 0.37981755\n",
      "Epoch: [ 1] [ 954/1582] time: 3332.7971, d_loss: 1.37879276, g_loss: 0.35683930\n",
      "Epoch: [ 1] [ 955/1582] time: 3334.0586, d_loss: 1.60633934, g_loss: 0.32399219\n",
      "Epoch: [ 1] [ 956/1582] time: 3335.3166, d_loss: 1.64722478, g_loss: 0.29939526\n",
      "Epoch: [ 1] [ 957/1582] time: 3336.5737, d_loss: 1.43207932, g_loss: 0.35319355\n",
      "Epoch: [ 1] [ 958/1582] time: 3337.8306, d_loss: 1.27522767, g_loss: 0.47494230\n",
      "Epoch: [ 1] [ 959/1582] time: 3339.0866, d_loss: 1.22138190, g_loss: 0.54120576\n",
      "Epoch: [ 1] [ 960/1582] time: 3340.3435, d_loss: 1.05109763, g_loss: 0.79607010\n",
      "Epoch: [ 1] [ 961/1582] time: 3341.5975, d_loss: 1.03010607, g_loss: 0.80594039\n",
      "Epoch: [ 1] [ 962/1582] time: 3342.8595, d_loss: 0.92425346, g_loss: 0.91046572\n",
      "Epoch: [ 1] [ 963/1582] time: 3344.1164, d_loss: 0.78397882, g_loss: 1.02920938\n",
      "Epoch: [ 1] [ 964/1582] time: 3345.3764, d_loss: 0.76686060, g_loss: 1.22780514\n",
      "Epoch: [ 1] [ 965/1582] time: 3346.6284, d_loss: 0.73538530, g_loss: 1.18740904\n",
      "Epoch: [ 1] [ 966/1582] time: 3347.8813, d_loss: 0.78327906, g_loss: 1.05960011\n",
      "Epoch: [ 1] [ 967/1582] time: 3349.1373, d_loss: 0.81522506, g_loss: 0.90055072\n",
      "Epoch: [ 1] [ 968/1582] time: 3350.3932, d_loss: 0.87153816, g_loss: 0.78510678\n",
      "Epoch: [ 1] [ 969/1582] time: 3351.6480, d_loss: 0.95265341, g_loss: 0.65661311\n",
      "Epoch: [ 1] [ 970/1582] time: 3352.9034, d_loss: 0.98988110, g_loss: 0.54793525\n",
      "Epoch: [ 1] [ 971/1582] time: 3354.1584, d_loss: 0.93696207, g_loss: 0.50478250\n",
      "Epoch: [ 1] [ 972/1582] time: 3355.4143, d_loss: 0.95973575, g_loss: 0.51140100\n",
      "Epoch: [ 1] [ 973/1582] time: 3356.6678, d_loss: 1.03766274, g_loss: 0.46783465\n",
      "Epoch: [ 1] [ 974/1582] time: 3357.9238, d_loss: 0.94296122, g_loss: 0.52195466\n",
      "Epoch: [ 1] [ 975/1582] time: 3359.1790, d_loss: 0.97051698, g_loss: 0.50084752\n",
      "Epoch: [ 1] [ 976/1582] time: 3360.4358, d_loss: 0.93484712, g_loss: 0.50258183\n",
      "Epoch: [ 1] [ 977/1582] time: 3361.6898, d_loss: 1.02318728, g_loss: 0.47534308\n",
      "Epoch: [ 1] [ 978/1582] time: 3362.9448, d_loss: 1.00016510, g_loss: 0.47849628\n",
      "Epoch: [ 1] [ 979/1582] time: 3364.1997, d_loss: 0.96770716, g_loss: 0.47188276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1] [ 980/1582] time: 3365.4547, d_loss: 0.98570055, g_loss: 0.49742565\n",
      "Epoch: [ 1] [ 981/1582] time: 3366.7106, d_loss: 0.93985474, g_loss: 0.51448274\n",
      "Epoch: [ 1] [ 982/1582] time: 3367.9699, d_loss: 0.89408708, g_loss: 0.56256801\n",
      "Epoch: [ 1] [ 983/1582] time: 3369.2271, d_loss: 0.86417121, g_loss: 0.58626622\n",
      "Epoch: [ 1] [ 984/1582] time: 3370.4830, d_loss: 0.82997930, g_loss: 0.59133941\n",
      "Epoch: [ 1] [ 985/1582] time: 3371.7392, d_loss: 0.86656076, g_loss: 0.57836139\n",
      "Epoch: [ 1] [ 986/1582] time: 3372.9972, d_loss: 0.84936476, g_loss: 0.58476371\n",
      "Epoch: [ 1] [ 987/1582] time: 3374.2512, d_loss: 0.81030381, g_loss: 0.58094102\n",
      "Epoch: [ 1] [ 988/1582] time: 3375.5081, d_loss: 0.78222477, g_loss: 0.59787470\n",
      "Epoch: [ 1] [ 989/1582] time: 3376.7601, d_loss: 0.83363914, g_loss: 0.59170204\n",
      "Epoch: [ 1] [ 990/1582] time: 3378.0160, d_loss: 0.81219989, g_loss: 0.60266542\n",
      "Epoch: [ 1] [ 991/1582] time: 3379.2700, d_loss: 0.82448256, g_loss: 0.60163647\n",
      "Epoch: [ 1] [ 992/1582] time: 3380.5240, d_loss: 0.83100849, g_loss: 0.58144182\n",
      "Epoch: [ 1] [ 993/1582] time: 3381.7769, d_loss: 0.81015038, g_loss: 0.59521079\n",
      "Epoch: [ 1] [ 994/1582] time: 3383.0329, d_loss: 0.86065644, g_loss: 0.59398597\n",
      "Epoch: [ 1] [ 995/1582] time: 3384.2859, d_loss: 0.85430902, g_loss: 0.58758479\n",
      "Epoch: [ 1] [ 996/1582] time: 3385.5448, d_loss: 0.78105444, g_loss: 0.62065530\n",
      "Epoch: [ 1] [ 997/1582] time: 3386.8018, d_loss: 0.86344564, g_loss: 0.60058171\n",
      "Epoch: [ 1] [ 998/1582] time: 3388.0627, d_loss: 0.91410607, g_loss: 0.59281766\n",
      "Epoch: [ 1] [ 999/1582] time: 3389.3187, d_loss: 0.96802741, g_loss: 0.53940809\n",
      "Epoch: [ 1] [1000/1582] time: 3390.5767, d_loss: 1.04374564, g_loss: 0.49526256\n",
      "Epoch: [ 1] [1001/1582] time: 3391.8346, d_loss: 1.05993319, g_loss: 0.49907503\n",
      "Epoch: [ 1] [1002/1582] time: 3393.0916, d_loss: 1.03936255, g_loss: 0.47890526\n",
      "Epoch: [ 1] [1003/1582] time: 3394.3426, d_loss: 1.21474326, g_loss: 0.41933188\n",
      "Epoch: [ 1] [1004/1582] time: 3395.5985, d_loss: 1.19287753, g_loss: 0.46665609\n",
      "Epoch: [ 1] [1005/1582] time: 3396.8531, d_loss: 1.16578352, g_loss: 0.44775671\n",
      "Epoch: [ 1] [1006/1582] time: 3398.1126, d_loss: 1.18046415, g_loss: 0.54845846\n",
      "Epoch: [ 1] [1007/1582] time: 3399.3700, d_loss: 1.06176555, g_loss: 0.59606946\n",
      "Epoch: [ 1] [1008/1582] time: 3400.6285, d_loss: 1.07006383, g_loss: 0.67636383\n",
      "Epoch: [ 1] [1009/1582] time: 3401.8865, d_loss: 0.89410913, g_loss: 0.75974995\n",
      "Epoch: [ 1] [1010/1582] time: 3403.1485, d_loss: 0.81640500, g_loss: 0.93177092\n",
      "Epoch: [ 1] [1011/1582] time: 3404.4054, d_loss: 0.83115876, g_loss: 0.99386692\n",
      "Epoch: [ 1] [1012/1582] time: 3405.6639, d_loss: 0.84318787, g_loss: 1.03938174\n",
      "Epoch: [ 1] [1013/1582] time: 3406.9238, d_loss: 0.86747730, g_loss: 1.00855041\n",
      "Epoch: [ 1] [1014/1582] time: 3408.1830, d_loss: 0.89411640, g_loss: 0.88814044\n",
      "Epoch: [ 1] [1015/1582] time: 3409.4440, d_loss: 0.87287539, g_loss: 0.84223944\n",
      "Epoch: [ 1] [1016/1582] time: 3410.7029, d_loss: 0.89224827, g_loss: 0.81654823\n",
      "Epoch: [ 1] [1017/1582] time: 3411.9599, d_loss: 1.06878436, g_loss: 0.66536391\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 1] [1018/1582] time: 3420.0676, d_loss: 1.04009795, g_loss: 0.60941648\n",
      "Epoch: [ 1] [1019/1582] time: 3421.3171, d_loss: 0.99580574, g_loss: 0.57674193\n",
      "Epoch: [ 1] [1020/1582] time: 3422.5701, d_loss: 1.04834533, g_loss: 0.56326938\n",
      "Epoch: [ 1] [1021/1582] time: 3423.8211, d_loss: 1.00085819, g_loss: 0.61473429\n",
      "Epoch: [ 1] [1022/1582] time: 3425.0761, d_loss: 1.10010016, g_loss: 0.58080733\n",
      "Epoch: [ 1] [1023/1582] time: 3426.3300, d_loss: 1.03508997, g_loss: 0.60346442\n",
      "Epoch: [ 1] [1024/1582] time: 3427.5820, d_loss: 0.92222047, g_loss: 0.63479602\n",
      "Epoch: [ 1] [1025/1582] time: 3428.8359, d_loss: 0.88225424, g_loss: 0.74809176\n",
      "Epoch: [ 1] [1026/1582] time: 3430.0949, d_loss: 0.79308444, g_loss: 0.88327235\n",
      "Epoch: [ 1] [1027/1582] time: 3431.3469, d_loss: 0.76037532, g_loss: 1.00077558\n",
      "Epoch: [ 1] [1028/1582] time: 3432.5978, d_loss: 0.77901125, g_loss: 0.92885339\n",
      "Epoch: [ 1] [1029/1582] time: 3433.8478, d_loss: 0.74859995, g_loss: 0.96542245\n",
      "Epoch: [ 1] [1030/1582] time: 3435.1018, d_loss: 0.73616505, g_loss: 0.90664768\n",
      "Epoch: [ 1] [1031/1582] time: 3436.3537, d_loss: 0.77397341, g_loss: 0.80119342\n",
      "Epoch: [ 1] [1032/1582] time: 3437.6057, d_loss: 0.74084431, g_loss: 0.73275900\n",
      "Epoch: [ 1] [1033/1582] time: 3438.8566, d_loss: 0.89753151, g_loss: 0.60702133\n",
      "Epoch: [ 1] [1034/1582] time: 3440.1106, d_loss: 0.94029838, g_loss: 0.54259139\n",
      "Epoch: [ 1] [1035/1582] time: 3441.3611, d_loss: 0.95777327, g_loss: 0.53629756\n",
      "Epoch: [ 1] [1036/1582] time: 3442.6141, d_loss: 0.88064551, g_loss: 0.53377068\n",
      "Epoch: [ 1] [1037/1582] time: 3443.8665, d_loss: 0.89448661, g_loss: 0.54204893\n",
      "Epoch: [ 1] [1038/1582] time: 3445.1226, d_loss: 0.86345017, g_loss: 0.58863413\n",
      "Epoch: [ 1] [1039/1582] time: 3446.3775, d_loss: 0.88986146, g_loss: 0.59329963\n",
      "Epoch: [ 1] [1040/1582] time: 3447.6298, d_loss: 0.82418245, g_loss: 0.62841648\n",
      "Epoch: [ 1] [1041/1582] time: 3448.8838, d_loss: 0.79416299, g_loss: 0.66760254\n",
      "Epoch: [ 1] [1042/1582] time: 3450.1387, d_loss: 0.72859472, g_loss: 0.71400875\n",
      "Epoch: [ 1] [1043/1582] time: 3451.3897, d_loss: 0.73248547, g_loss: 0.70509177\n",
      "Epoch: [ 1] [1044/1582] time: 3452.6436, d_loss: 0.78285718, g_loss: 0.74647009\n",
      "Epoch: [ 1] [1045/1582] time: 3453.8967, d_loss: 0.78795880, g_loss: 0.75265467\n",
      "Epoch: [ 1] [1046/1582] time: 3455.1526, d_loss: 0.67550564, g_loss: 0.76238537\n",
      "Epoch: [ 1] [1047/1582] time: 3456.4035, d_loss: 0.68558377, g_loss: 0.79715770\n",
      "Epoch: [ 1] [1048/1582] time: 3457.6575, d_loss: 0.78262526, g_loss: 0.76300240\n",
      "Epoch: [ 1] [1049/1582] time: 3458.9115, d_loss: 0.75614613, g_loss: 0.72061253\n",
      "Epoch: [ 1] [1050/1582] time: 3460.1626, d_loss: 0.84856689, g_loss: 0.67116714\n",
      "Epoch: [ 1] [1051/1582] time: 3461.4162, d_loss: 0.91326284, g_loss: 0.64017045\n",
      "Epoch: [ 1] [1052/1582] time: 3462.6767, d_loss: 0.89697397, g_loss: 0.59689772\n",
      "Epoch: [ 1] [1053/1582] time: 3463.9317, d_loss: 0.92352134, g_loss: 0.54651016\n",
      "Epoch: [ 1] [1054/1582] time: 3465.1941, d_loss: 0.98648667, g_loss: 0.52086771\n",
      "Epoch: [ 1] [1055/1582] time: 3466.4481, d_loss: 0.97098017, g_loss: 0.55563867\n",
      "Epoch: [ 1] [1056/1582] time: 3467.7040, d_loss: 0.92622507, g_loss: 0.57775927\n",
      "Epoch: [ 1] [1057/1582] time: 3468.9580, d_loss: 0.94758028, g_loss: 0.59008658\n",
      "Epoch: [ 1] [1058/1582] time: 3470.2120, d_loss: 0.89081013, g_loss: 0.61348504\n",
      "Epoch: [ 1] [1059/1582] time: 3471.4649, d_loss: 0.80373198, g_loss: 0.66513586\n",
      "Epoch: [ 1] [1060/1582] time: 3472.7189, d_loss: 0.78996092, g_loss: 0.67680526\n",
      "Epoch: [ 1] [1061/1582] time: 3473.9729, d_loss: 0.82333410, g_loss: 0.71738392\n",
      "Epoch: [ 1] [1062/1582] time: 3475.2278, d_loss: 0.81493777, g_loss: 0.70664024\n",
      "Epoch: [ 1] [1063/1582] time: 3476.4828, d_loss: 0.77001631, g_loss: 0.70623803\n",
      "Epoch: [ 1] [1064/1582] time: 3477.7378, d_loss: 0.77128816, g_loss: 0.71214104\n",
      "Epoch: [ 1] [1065/1582] time: 3478.9917, d_loss: 0.80676454, g_loss: 0.69820905\n",
      "Epoch: [ 1] [1066/1582] time: 3480.2457, d_loss: 0.80766153, g_loss: 0.66234881\n",
      "Epoch: [ 1] [1067/1582] time: 3481.4986, d_loss: 0.78022313, g_loss: 0.66058230\n",
      "Epoch: [ 1] [1068/1582] time: 3482.7558, d_loss: 0.75130796, g_loss: 0.70235723\n",
      "Epoch: [ 1] [1069/1582] time: 3484.0122, d_loss: 0.74122131, g_loss: 0.73019886\n",
      "Epoch: [ 1] [1070/1582] time: 3485.2674, d_loss: 0.72745174, g_loss: 0.79235911\n",
      "Epoch: [ 1] [1071/1582] time: 3486.5233, d_loss: 0.68531287, g_loss: 0.83918685\n",
      "Epoch: [ 1] [1072/1582] time: 3487.7787, d_loss: 0.65581536, g_loss: 0.86613023\n",
      "Epoch: [ 1] [1073/1582] time: 3489.0319, d_loss: 0.67141396, g_loss: 0.85439444\n",
      "Epoch: [ 1] [1074/1582] time: 3490.2879, d_loss: 0.74404287, g_loss: 0.85794806\n",
      "Epoch: [ 1] [1075/1582] time: 3491.5429, d_loss: 0.70222932, g_loss: 0.85820651\n",
      "Epoch: [ 1] [1076/1582] time: 3492.7978, d_loss: 0.80756867, g_loss: 0.76292562\n",
      "Epoch: [ 1] [1077/1582] time: 3494.0483, d_loss: 0.76153457, g_loss: 0.71684301\n",
      "Epoch: [ 1] [1078/1582] time: 3495.3023, d_loss: 0.86643559, g_loss: 0.65129876\n",
      "Epoch: [ 1] [1079/1582] time: 3496.5564, d_loss: 0.80073208, g_loss: 0.65919310\n",
      "Epoch: [ 1] [1080/1582] time: 3497.8124, d_loss: 0.85988975, g_loss: 0.66540635\n",
      "Epoch: [ 1] [1081/1582] time: 3499.0683, d_loss: 0.84715325, g_loss: 0.66945338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1] [1082/1582] time: 3500.3273, d_loss: 1.01098967, g_loss: 0.63226342\n",
      "Epoch: [ 1] [1083/1582] time: 3501.5805, d_loss: 0.92952698, g_loss: 0.57005149\n",
      "Epoch: [ 1] [1084/1582] time: 3502.8364, d_loss: 1.09128547, g_loss: 0.52703005\n",
      "Epoch: [ 1] [1085/1582] time: 3504.0919, d_loss: 1.12747681, g_loss: 0.48499948\n",
      "Epoch: [ 1] [1086/1582] time: 3505.3479, d_loss: 1.29330897, g_loss: 0.44210714\n",
      "Epoch: [ 1] [1087/1582] time: 3506.6018, d_loss: 1.25036073, g_loss: 0.42240787\n",
      "Epoch: [ 1] [1088/1582] time: 3507.8588, d_loss: 1.31832659, g_loss: 0.42342505\n",
      "Epoch: [ 1] [1089/1582] time: 3509.1118, d_loss: 1.17548871, g_loss: 0.47818163\n",
      "Epoch: [ 1] [1090/1582] time: 3510.3657, d_loss: 1.29535937, g_loss: 0.42016470\n",
      "Epoch: [ 1] [1091/1582] time: 3511.6207, d_loss: 1.13155115, g_loss: 0.52590483\n",
      "Epoch: [ 1] [1092/1582] time: 3512.8747, d_loss: 1.07688451, g_loss: 0.56042308\n",
      "Epoch: [ 1] [1093/1582] time: 3514.1286, d_loss: 0.91973537, g_loss: 0.65657014\n",
      "Epoch: [ 1] [1094/1582] time: 3515.3856, d_loss: 0.89539737, g_loss: 0.74862134\n",
      "Epoch: [ 1] [1095/1582] time: 3516.6396, d_loss: 0.74607313, g_loss: 0.94177556\n",
      "Epoch: [ 1] [1096/1582] time: 3517.8913, d_loss: 0.75862491, g_loss: 1.07432985\n",
      "Epoch: [ 1] [1097/1582] time: 3519.1453, d_loss: 0.71294737, g_loss: 1.19520140\n",
      "Epoch: [ 1] [1098/1582] time: 3520.4034, d_loss: 0.66796136, g_loss: 1.26010919\n",
      "Epoch: [ 1] [1099/1582] time: 3521.6605, d_loss: 0.66228402, g_loss: 1.28893256\n",
      "Epoch: [ 1] [1100/1582] time: 3522.9160, d_loss: 0.64022136, g_loss: 1.27176213\n",
      "Epoch: [ 1] [1101/1582] time: 3524.1731, d_loss: 0.59983784, g_loss: 1.31418347\n",
      "Epoch: [ 1] [1102/1582] time: 3525.4310, d_loss: 0.58782500, g_loss: 1.23292756\n",
      "Epoch: [ 1] [1103/1582] time: 3526.6960, d_loss: 0.63094574, g_loss: 1.09794033\n",
      "Epoch: [ 1] [1104/1582] time: 3527.9519, d_loss: 0.60837328, g_loss: 1.00776887\n",
      "Epoch: [ 1] [1105/1582] time: 3529.2039, d_loss: 0.55572689, g_loss: 1.04250097\n",
      "Epoch: [ 1] [1106/1582] time: 3530.4569, d_loss: 0.67057979, g_loss: 0.89124513\n",
      "Epoch: [ 1] [1107/1582] time: 3531.7078, d_loss: 0.62853241, g_loss: 0.82871455\n",
      "Epoch: [ 1] [1108/1582] time: 3532.9628, d_loss: 0.70625651, g_loss: 0.76631409\n",
      "Epoch: [ 1] [1109/1582] time: 3534.2147, d_loss: 0.70195818, g_loss: 0.70307642\n",
      "Epoch: [ 1] [1110/1582] time: 3535.4640, d_loss: 0.75211769, g_loss: 0.69170225\n",
      "Epoch: [ 1] [1111/1582] time: 3536.7150, d_loss: 0.83670074, g_loss: 0.63269043\n",
      "Epoch: [ 1] [1112/1582] time: 3537.9689, d_loss: 0.94264591, g_loss: 0.57709473\n",
      "Epoch: [ 1] [1113/1582] time: 3539.2189, d_loss: 0.87763643, g_loss: 0.57439339\n",
      "Epoch: [ 1] [1114/1582] time: 3540.4730, d_loss: 0.92272091, g_loss: 0.56946993\n",
      "Epoch: [ 1] [1115/1582] time: 3541.7260, d_loss: 0.92321390, g_loss: 0.54827172\n",
      "Epoch: [ 1] [1116/1582] time: 3542.9820, d_loss: 0.93318701, g_loss: 0.57667172\n",
      "Epoch: [ 1] [1117/1582] time: 3544.2339, d_loss: 0.91375172, g_loss: 0.58280295\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 1] [1118/1582] time: 3552.3644, d_loss: 0.94746381, g_loss: 0.58620727\n",
      "Epoch: [ 1] [1119/1582] time: 3553.6173, d_loss: 0.97097647, g_loss: 0.58069801\n",
      "Epoch: [ 1] [1120/1582] time: 3554.8722, d_loss: 0.85327375, g_loss: 0.58700597\n",
      "Epoch: [ 1] [1121/1582] time: 3556.1252, d_loss: 0.91917801, g_loss: 0.57413858\n",
      "Epoch: [ 1] [1122/1582] time: 3557.3792, d_loss: 0.89846063, g_loss: 0.58708757\n",
      "Epoch: [ 1] [1123/1582] time: 3558.6331, d_loss: 0.91112190, g_loss: 0.59061700\n",
      "Epoch: [ 1] [1124/1582] time: 3559.8891, d_loss: 0.95283127, g_loss: 0.56301242\n",
      "Epoch: [ 1] [1125/1582] time: 3561.1431, d_loss: 0.89625341, g_loss: 0.54324913\n",
      "Epoch: [ 1] [1126/1582] time: 3562.3972, d_loss: 0.92694485, g_loss: 0.50870156\n",
      "Epoch: [ 1] [1127/1582] time: 3563.6512, d_loss: 0.95040792, g_loss: 0.53375030\n",
      "Epoch: [ 1] [1128/1582] time: 3564.9052, d_loss: 0.96962178, g_loss: 0.50354475\n",
      "Epoch: [ 1] [1129/1582] time: 3566.1569, d_loss: 0.91819394, g_loss: 0.52241683\n",
      "Epoch: [ 1] [1130/1582] time: 3567.4108, d_loss: 0.95128995, g_loss: 0.54224074\n",
      "Epoch: [ 1] [1131/1582] time: 3568.6648, d_loss: 0.85726589, g_loss: 0.58391124\n",
      "Epoch: [ 1] [1132/1582] time: 3569.9167, d_loss: 0.85314894, g_loss: 0.60813498\n",
      "Epoch: [ 1] [1133/1582] time: 3571.1677, d_loss: 0.84625250, g_loss: 0.63027477\n",
      "Epoch: [ 1] [1134/1582] time: 3572.4213, d_loss: 0.78653324, g_loss: 0.69966114\n",
      "Epoch: [ 1] [1135/1582] time: 3573.6763, d_loss: 0.71243501, g_loss: 0.72165322\n",
      "Epoch: [ 1] [1136/1582] time: 3574.9312, d_loss: 0.75427282, g_loss: 0.72273457\n",
      "Epoch: [ 1] [1137/1582] time: 3576.1825, d_loss: 0.71532393, g_loss: 0.74754119\n",
      "Epoch: [ 1] [1138/1582] time: 3577.4364, d_loss: 0.69391453, g_loss: 0.74020517\n",
      "Epoch: [ 1] [1139/1582] time: 3578.6914, d_loss: 0.69491839, g_loss: 0.74565089\n",
      "Epoch: [ 1] [1140/1582] time: 3579.9453, d_loss: 0.67698693, g_loss: 0.76055521\n",
      "Epoch: [ 1] [1141/1582] time: 3581.1963, d_loss: 0.64201665, g_loss: 0.82092810\n",
      "Epoch: [ 1] [1142/1582] time: 3582.4473, d_loss: 0.63953161, g_loss: 0.85100901\n",
      "Epoch: [ 1] [1143/1582] time: 3583.6993, d_loss: 0.67214787, g_loss: 0.81424570\n",
      "Epoch: [ 1] [1144/1582] time: 3584.9532, d_loss: 0.66052967, g_loss: 0.82511765\n",
      "Epoch: [ 1] [1145/1582] time: 3586.2072, d_loss: 0.71333218, g_loss: 0.76163173\n",
      "Epoch: [ 1] [1146/1582] time: 3587.4601, d_loss: 0.65712857, g_loss: 0.76320773\n",
      "Epoch: [ 1] [1147/1582] time: 3588.7151, d_loss: 0.64459896, g_loss: 0.75297272\n",
      "Epoch: [ 1] [1148/1582] time: 3589.9681, d_loss: 0.69998950, g_loss: 0.72971237\n",
      "Epoch: [ 1] [1149/1582] time: 3591.2210, d_loss: 0.71463901, g_loss: 0.73704982\n",
      "Epoch: [ 1] [1150/1582] time: 3592.4754, d_loss: 0.73893452, g_loss: 0.71155745\n",
      "Epoch: [ 1] [1151/1582] time: 3593.7274, d_loss: 0.76916289, g_loss: 0.67355496\n",
      "Epoch: [ 1] [1152/1582] time: 3594.9824, d_loss: 0.85267353, g_loss: 0.66582978\n",
      "Epoch: [ 1] [1153/1582] time: 3596.2381, d_loss: 0.88486278, g_loss: 0.62422085\n",
      "Epoch: [ 1] [1154/1582] time: 3597.4950, d_loss: 1.00369072, g_loss: 0.59405351\n",
      "Epoch: [ 1] [1155/1582] time: 3598.7500, d_loss: 1.06953442, g_loss: 0.55040359\n",
      "Epoch: [ 1] [1156/1582] time: 3600.0070, d_loss: 1.03724742, g_loss: 0.52097356\n",
      "Epoch: [ 1] [1157/1582] time: 3601.2619, d_loss: 1.04534864, g_loss: 0.49050295\n",
      "Epoch: [ 1] [1158/1582] time: 3602.5179, d_loss: 1.08028638, g_loss: 0.55552030\n",
      "Epoch: [ 1] [1159/1582] time: 3603.7758, d_loss: 1.07865417, g_loss: 0.49864137\n",
      "Epoch: [ 1] [1160/1582] time: 3605.0338, d_loss: 0.97619957, g_loss: 0.59770530\n",
      "Epoch: [ 1] [1161/1582] time: 3606.2887, d_loss: 0.95973533, g_loss: 0.59700727\n",
      "Epoch: [ 1] [1162/1582] time: 3607.5457, d_loss: 0.88272214, g_loss: 0.67427087\n",
      "Epoch: [ 1] [1163/1582] time: 3608.8007, d_loss: 0.81568635, g_loss: 0.78133130\n",
      "Epoch: [ 1] [1164/1582] time: 3610.0617, d_loss: 0.71225655, g_loss: 0.91886985\n",
      "Epoch: [ 1] [1165/1582] time: 3611.3126, d_loss: 0.56694698, g_loss: 1.12594473\n",
      "Epoch: [ 1] [1166/1582] time: 3612.5694, d_loss: 0.57388467, g_loss: 1.23888922\n",
      "Epoch: [ 1] [1167/1582] time: 3613.8234, d_loss: 0.58430052, g_loss: 1.32455611\n",
      "Epoch: [ 1] [1168/1582] time: 3615.0797, d_loss: 0.51052117, g_loss: 1.43639517\n",
      "Epoch: [ 1] [1169/1582] time: 3616.3326, d_loss: 0.52189720, g_loss: 1.36745620\n",
      "Epoch: [ 1] [1170/1582] time: 3617.5896, d_loss: 0.49506077, g_loss: 1.28610909\n",
      "Epoch: [ 1] [1171/1582] time: 3618.8456, d_loss: 0.54016370, g_loss: 1.16974854\n",
      "Epoch: [ 1] [1172/1582] time: 3620.1025, d_loss: 0.55976152, g_loss: 1.03472984\n",
      "Epoch: [ 1] [1173/1582] time: 3621.3595, d_loss: 0.57235360, g_loss: 0.92883706\n",
      "Epoch: [ 1] [1174/1582] time: 3622.6144, d_loss: 0.62325865, g_loss: 0.85779184\n",
      "Epoch: [ 1] [1175/1582] time: 3623.8674, d_loss: 0.69442427, g_loss: 0.78015745\n",
      "Epoch: [ 1] [1176/1582] time: 3625.1254, d_loss: 0.71273017, g_loss: 0.70365322\n",
      "Epoch: [ 1] [1177/1582] time: 3626.3793, d_loss: 0.72494078, g_loss: 0.67119205\n",
      "Epoch: [ 1] [1178/1582] time: 3627.6372, d_loss: 0.72391671, g_loss: 0.68853939\n",
      "Epoch: [ 1] [1179/1582] time: 3628.8957, d_loss: 0.72730243, g_loss: 0.69925284\n",
      "Epoch: [ 1] [1180/1582] time: 3630.1494, d_loss: 0.72085851, g_loss: 0.72610617\n",
      "Epoch: [ 1] [1181/1582] time: 3631.4054, d_loss: 0.74926937, g_loss: 0.71822315\n",
      "Epoch: [ 1] [1182/1582] time: 3632.6655, d_loss: 0.75937706, g_loss: 0.71682113\n",
      "Epoch: [ 1] [1183/1582] time: 3633.9214, d_loss: 0.73291659, g_loss: 0.71877986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1] [1184/1582] time: 3635.1795, d_loss: 0.81595778, g_loss: 0.70246232\n",
      "Epoch: [ 1] [1185/1582] time: 3636.4334, d_loss: 0.73779261, g_loss: 0.72040015\n",
      "Epoch: [ 1] [1186/1582] time: 3637.6918, d_loss: 0.75499207, g_loss: 0.72417569\n",
      "Epoch: [ 1] [1187/1582] time: 3638.9478, d_loss: 0.76754826, g_loss: 0.75134790\n",
      "Epoch: [ 1] [1188/1582] time: 3640.2049, d_loss: 0.75527865, g_loss: 0.73276103\n",
      "Epoch: [ 1] [1189/1582] time: 3641.4589, d_loss: 0.77806830, g_loss: 0.70211357\n",
      "Epoch: [ 1] [1190/1582] time: 3642.7158, d_loss: 0.71888787, g_loss: 0.72669458\n",
      "Epoch: [ 1] [1191/1582] time: 3643.9678, d_loss: 0.73024869, g_loss: 0.72685510\n",
      "Epoch: [ 1] [1192/1582] time: 3645.2217, d_loss: 0.69462389, g_loss: 0.78711128\n",
      "Epoch: [ 1] [1193/1582] time: 3646.4770, d_loss: 0.71518981, g_loss: 0.76183951\n",
      "Epoch: [ 1] [1194/1582] time: 3647.7330, d_loss: 0.67253804, g_loss: 0.82540131\n",
      "Epoch: [ 1] [1195/1582] time: 3649.0029, d_loss: 0.66190284, g_loss: 0.82493234\n",
      "Epoch: [ 1] [1196/1582] time: 3650.2609, d_loss: 0.64514339, g_loss: 0.89208001\n",
      "Epoch: [ 1] [1197/1582] time: 3651.5169, d_loss: 0.62340128, g_loss: 0.90372401\n",
      "Epoch: [ 1] [1198/1582] time: 3652.7738, d_loss: 0.60954463, g_loss: 0.91861153\n",
      "Epoch: [ 1] [1199/1582] time: 3654.0318, d_loss: 0.64604646, g_loss: 0.89501071\n",
      "Epoch: [ 1] [1200/1582] time: 3655.2888, d_loss: 0.67957008, g_loss: 0.89576280\n",
      "Epoch: [ 1] [1201/1582] time: 3656.5427, d_loss: 0.70645660, g_loss: 0.88975739\n",
      "Epoch: [ 1] [1202/1582] time: 3657.7967, d_loss: 0.74048090, g_loss: 0.86376923\n",
      "Epoch: [ 1] [1203/1582] time: 3659.0516, d_loss: 0.77252334, g_loss: 0.80232280\n",
      "Epoch: [ 1] [1204/1582] time: 3660.3076, d_loss: 0.80895531, g_loss: 0.72863543\n",
      "Epoch: [ 1] [1205/1582] time: 3661.5616, d_loss: 0.81363839, g_loss: 0.66098464\n",
      "Epoch: [ 1] [1206/1582] time: 3662.8165, d_loss: 0.80665910, g_loss: 0.71904993\n",
      "Epoch: [ 1] [1207/1582] time: 3664.0705, d_loss: 0.98160410, g_loss: 0.64419305\n",
      "Epoch: [ 1] [1208/1582] time: 3665.3265, d_loss: 0.87106186, g_loss: 0.63039303\n",
      "Epoch: [ 1] [1209/1582] time: 3666.5804, d_loss: 1.03507102, g_loss: 0.57148498\n",
      "Epoch: [ 1] [1210/1582] time: 3667.8384, d_loss: 0.95173264, g_loss: 0.57848078\n",
      "Epoch: [ 1] [1211/1582] time: 3669.0943, d_loss: 1.02928257, g_loss: 0.57782209\n",
      "Epoch: [ 1] [1212/1582] time: 3670.3493, d_loss: 0.95610309, g_loss: 0.59359956\n",
      "Epoch: [ 1] [1213/1582] time: 3671.6044, d_loss: 1.06205010, g_loss: 0.59106189\n",
      "Epoch: [ 1] [1214/1582] time: 3672.8628, d_loss: 1.04714370, g_loss: 0.55463171\n",
      "Epoch: [ 1] [1215/1582] time: 3674.1158, d_loss: 1.05787146, g_loss: 0.59233111\n",
      "Epoch: [ 1] [1216/1582] time: 3675.3717, d_loss: 1.06731999, g_loss: 0.53974330\n",
      "Epoch: [ 1] [1217/1582] time: 3676.6257, d_loss: 1.08171558, g_loss: 0.55178005\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 1] [1218/1582] time: 3684.7909, d_loss: 0.99588323, g_loss: 0.55327374\n",
      "Epoch: [ 1] [1219/1582] time: 3686.0458, d_loss: 0.79031610, g_loss: 0.75599951\n",
      "Epoch: [ 1] [1220/1582] time: 3687.3048, d_loss: 0.79510772, g_loss: 0.91924703\n",
      "Epoch: [ 1] [1221/1582] time: 3688.5607, d_loss: 0.87797177, g_loss: 0.93287593\n",
      "Epoch: [ 1] [1222/1582] time: 3689.8187, d_loss: 0.69924986, g_loss: 1.04494298\n",
      "Epoch: [ 1] [1223/1582] time: 3691.0746, d_loss: 0.70365250, g_loss: 1.19587815\n",
      "Epoch: [ 1] [1224/1582] time: 3692.3316, d_loss: 0.57894820, g_loss: 1.38074923\n",
      "Epoch: [ 1] [1225/1582] time: 3693.5875, d_loss: 0.59934211, g_loss: 1.34813416\n",
      "Epoch: [ 1] [1226/1582] time: 3694.8455, d_loss: 0.57413810, g_loss: 1.29898405\n",
      "Epoch: [ 1] [1227/1582] time: 3696.1035, d_loss: 0.61010510, g_loss: 1.20667911\n",
      "Epoch: [ 1] [1228/1582] time: 3697.3625, d_loss: 0.51457167, g_loss: 1.07165766\n",
      "Epoch: [ 1] [1229/1582] time: 3698.6194, d_loss: 0.51470459, g_loss: 1.03088295\n",
      "Epoch: [ 1] [1230/1582] time: 3699.8814, d_loss: 0.48628458, g_loss: 0.99985361\n",
      "Epoch: [ 1] [1231/1582] time: 3701.1383, d_loss: 0.51804751, g_loss: 0.94209307\n",
      "Epoch: [ 1] [1232/1582] time: 3702.3963, d_loss: 0.61516595, g_loss: 0.86394846\n",
      "Epoch: [ 1] [1233/1582] time: 3703.6523, d_loss: 0.65054756, g_loss: 0.77686483\n",
      "Epoch: [ 1] [1234/1582] time: 3704.9112, d_loss: 0.71724200, g_loss: 0.75094658\n",
      "Epoch: [ 1] [1235/1582] time: 3706.1711, d_loss: 0.68288934, g_loss: 0.74254429\n",
      "Epoch: [ 1] [1236/1582] time: 3707.4274, d_loss: 0.62100345, g_loss: 0.75749975\n",
      "Epoch: [ 1] [1237/1582] time: 3708.6852, d_loss: 0.67193437, g_loss: 0.78181916\n",
      "Epoch: [ 1] [1238/1582] time: 3709.9395, d_loss: 0.68679410, g_loss: 0.81438386\n",
      "Epoch: [ 1] [1239/1582] time: 3711.1943, d_loss: 0.70469272, g_loss: 0.81981927\n",
      "Epoch: [ 1] [1240/1582] time: 3712.4532, d_loss: 0.71364969, g_loss: 0.79620111\n",
      "Epoch: [ 1] [1241/1582] time: 3713.7092, d_loss: 0.63700056, g_loss: 0.81242800\n",
      "Epoch: [ 1] [1242/1582] time: 3714.9681, d_loss: 0.62971038, g_loss: 0.83389521\n",
      "Epoch: [ 1] [1243/1582] time: 3716.2251, d_loss: 0.63844782, g_loss: 0.84459984\n",
      "Epoch: [ 1] [1244/1582] time: 3717.4820, d_loss: 0.63146693, g_loss: 0.88008082\n",
      "Epoch: [ 1] [1245/1582] time: 3718.7400, d_loss: 0.61075014, g_loss: 0.89443880\n",
      "Epoch: [ 1] [1246/1582] time: 3719.9981, d_loss: 0.72532332, g_loss: 0.88000536\n",
      "Epoch: [ 1] [1247/1582] time: 3721.2511, d_loss: 0.68251270, g_loss: 0.86328393\n",
      "Epoch: [ 1] [1248/1582] time: 3722.5041, d_loss: 0.68374830, g_loss: 0.81565416\n",
      "Epoch: [ 1] [1249/1582] time: 3723.7540, d_loss: 0.76555347, g_loss: 0.81608510\n",
      "Epoch: [ 1] [1250/1582] time: 3725.0083, d_loss: 0.71148139, g_loss: 0.76788408\n",
      "Epoch: [ 1] [1251/1582] time: 3726.2613, d_loss: 0.85893095, g_loss: 0.71715569\n",
      "Epoch: [ 1] [1252/1582] time: 3727.5153, d_loss: 0.80772614, g_loss: 0.71056151\n",
      "Epoch: [ 1] [1253/1582] time: 3728.7682, d_loss: 0.71695948, g_loss: 0.71731675\n",
      "Epoch: [ 1] [1254/1582] time: 3730.0272, d_loss: 0.61969560, g_loss: 0.78488111\n",
      "Epoch: [ 1] [1255/1582] time: 3731.2812, d_loss: 0.64507687, g_loss: 0.83112282\n",
      "Epoch: [ 1] [1256/1582] time: 3732.5373, d_loss: 0.57864434, g_loss: 0.98518610\n",
      "Epoch: [ 1] [1257/1582] time: 3733.7983, d_loss: 0.56691611, g_loss: 1.08583951\n",
      "Epoch: [ 1] [1258/1582] time: 3735.0602, d_loss: 0.57594913, g_loss: 1.12092626\n",
      "Epoch: [ 1] [1259/1582] time: 3736.3212, d_loss: 0.65238750, g_loss: 1.08910906\n",
      "Epoch: [ 1] [1260/1582] time: 3737.5801, d_loss: 0.56797922, g_loss: 1.09909487\n",
      "Epoch: [ 1] [1261/1582] time: 3738.8396, d_loss: 0.62339371, g_loss: 1.10313845\n",
      "Epoch: [ 1] [1262/1582] time: 3740.0976, d_loss: 0.60351920, g_loss: 1.16682005\n",
      "Epoch: [ 1] [1263/1582] time: 3741.3501, d_loss: 0.56349152, g_loss: 1.21991932\n",
      "Epoch: [ 1] [1264/1582] time: 3742.6092, d_loss: 0.61104190, g_loss: 1.24580336\n",
      "Epoch: [ 1] [1265/1582] time: 3743.8642, d_loss: 0.53091115, g_loss: 1.39682150\n",
      "Epoch: [ 1] [1266/1582] time: 3745.1214, d_loss: 0.59391373, g_loss: 1.32870460\n",
      "Epoch: [ 1] [1267/1582] time: 3746.3784, d_loss: 0.70649958, g_loss: 1.18749559\n",
      "Epoch: [ 1] [1268/1582] time: 3747.6382, d_loss: 0.84797490, g_loss: 0.93103611\n",
      "Epoch: [ 1] [1269/1582] time: 3748.8892, d_loss: 0.98385632, g_loss: 0.65708327\n",
      "Epoch: [ 1] [1270/1582] time: 3750.1451, d_loss: 1.23983812, g_loss: 0.46012032\n",
      "Epoch: [ 1] [1271/1582] time: 3751.3971, d_loss: 1.44304812, g_loss: 0.36207622\n",
      "Epoch: [ 1] [1272/1582] time: 3752.6521, d_loss: 1.55165625, g_loss: 0.29606292\n",
      "Epoch: [ 1] [1273/1582] time: 3753.9080, d_loss: 1.76354790, g_loss: 0.27814072\n",
      "Epoch: [ 1] [1274/1582] time: 3755.1610, d_loss: 1.46537375, g_loss: 0.33234766\n",
      "Epoch: [ 1] [1275/1582] time: 3756.4150, d_loss: 1.40798175, g_loss: 0.38211054\n",
      "Epoch: [ 1] [1276/1582] time: 3757.6689, d_loss: 1.35770679, g_loss: 0.45870888\n",
      "Epoch: [ 1] [1277/1582] time: 3758.9189, d_loss: 1.18277907, g_loss: 0.54809678\n",
      "Epoch: [ 1] [1278/1582] time: 3760.1730, d_loss: 1.22633696, g_loss: 0.53524864\n",
      "Epoch: [ 1] [1279/1582] time: 3761.4283, d_loss: 1.29973412, g_loss: 0.53290820\n",
      "Epoch: [ 1] [1280/1582] time: 3762.6876, d_loss: 1.34771240, g_loss: 0.50119907\n",
      "Epoch: [ 1] [1281/1582] time: 3763.9445, d_loss: 1.38388276, g_loss: 0.38909394\n",
      "Epoch: [ 1] [1282/1582] time: 3765.2015, d_loss: 1.36949205, g_loss: 0.36002395\n",
      "Epoch: [ 1] [1283/1582] time: 3766.4538, d_loss: 1.40048599, g_loss: 0.32770628\n",
      "Epoch: [ 1] [1284/1582] time: 3767.7247, d_loss: 1.32322931, g_loss: 0.34759992\n",
      "Epoch: [ 1] [1285/1582] time: 3768.9857, d_loss: 1.18587542, g_loss: 0.39466804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1] [1286/1582] time: 3770.2407, d_loss: 1.10154068, g_loss: 0.45820981\n",
      "Epoch: [ 1] [1287/1582] time: 3771.4936, d_loss: 0.94553411, g_loss: 0.51494837\n",
      "Epoch: [ 1] [1288/1582] time: 3772.7516, d_loss: 0.88592404, g_loss: 0.61306357\n",
      "Epoch: [ 1] [1289/1582] time: 3774.0066, d_loss: 0.80540878, g_loss: 0.69255769\n",
      "Epoch: [ 1] [1290/1582] time: 3775.2615, d_loss: 0.73712784, g_loss: 0.73147130\n",
      "Epoch: [ 1] [1291/1582] time: 3776.5135, d_loss: 0.67947161, g_loss: 0.77545482\n",
      "Epoch: [ 1] [1292/1582] time: 3777.7685, d_loss: 0.70006740, g_loss: 0.75802648\n",
      "Epoch: [ 1] [1293/1582] time: 3779.0234, d_loss: 0.72452611, g_loss: 0.75726694\n",
      "Epoch: [ 1] [1294/1582] time: 3780.2794, d_loss: 0.62280589, g_loss: 0.76397717\n",
      "Epoch: [ 1] [1295/1582] time: 3781.5334, d_loss: 0.66027582, g_loss: 0.79295087\n",
      "Epoch: [ 1] [1296/1582] time: 3782.7903, d_loss: 0.60698944, g_loss: 0.80122900\n",
      "Epoch: [ 1] [1297/1582] time: 3784.0443, d_loss: 0.62398708, g_loss: 0.80469882\n",
      "Epoch: [ 1] [1298/1582] time: 3785.2972, d_loss: 0.56149971, g_loss: 0.83960503\n",
      "Epoch: [ 1] [1299/1582] time: 3786.5482, d_loss: 0.57670850, g_loss: 0.84402585\n",
      "Epoch: [ 1] [1300/1582] time: 3787.8032, d_loss: 0.54662174, g_loss: 0.88796544\n",
      "Epoch: [ 1] [1301/1582] time: 3789.0571, d_loss: 0.53037298, g_loss: 0.90370059\n",
      "Epoch: [ 1] [1302/1582] time: 3790.3111, d_loss: 0.50226474, g_loss: 0.91567284\n",
      "Epoch: [ 1] [1303/1582] time: 3791.5640, d_loss: 0.46382421, g_loss: 0.94198626\n",
      "Epoch: [ 1] [1304/1582] time: 3792.8170, d_loss: 0.45706999, g_loss: 0.98086149\n",
      "Epoch: [ 1] [1305/1582] time: 3794.0720, d_loss: 0.41441622, g_loss: 1.04517233\n",
      "Epoch: [ 1] [1306/1582] time: 3795.3269, d_loss: 0.43586254, g_loss: 1.07809198\n",
      "Epoch: [ 1] [1307/1582] time: 3796.5799, d_loss: 0.43282923, g_loss: 1.08990145\n",
      "Epoch: [ 1] [1308/1582] time: 3797.8339, d_loss: 0.42924482, g_loss: 1.11078334\n",
      "Epoch: [ 1] [1309/1582] time: 3799.0898, d_loss: 0.41432136, g_loss: 1.13122678\n",
      "Epoch: [ 1] [1310/1582] time: 3800.3458, d_loss: 0.39454070, g_loss: 1.13321042\n",
      "Epoch: [ 1] [1311/1582] time: 3801.6008, d_loss: 0.41087922, g_loss: 1.13158393\n",
      "Epoch: [ 1] [1312/1582] time: 3802.8537, d_loss: 0.41264984, g_loss: 1.13351893\n",
      "Epoch: [ 1] [1313/1582] time: 3804.1057, d_loss: 0.38795048, g_loss: 1.15106440\n",
      "Epoch: [ 1] [1314/1582] time: 3805.3556, d_loss: 0.38454118, g_loss: 1.13890934\n",
      "Epoch: [ 1] [1315/1582] time: 3806.6086, d_loss: 0.40845871, g_loss: 1.12453699\n",
      "Epoch: [ 1] [1316/1582] time: 3807.8616, d_loss: 0.38058922, g_loss: 1.12117100\n",
      "Epoch: [ 1] [1317/1582] time: 3809.1156, d_loss: 0.39035276, g_loss: 1.11620021\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 1] [1318/1582] time: 3817.3021, d_loss: 0.44775677, g_loss: 1.07893205\n",
      "Epoch: [ 1] [1319/1582] time: 3818.5551, d_loss: 0.38578993, g_loss: 1.08753479\n",
      "Epoch: [ 1] [1320/1582] time: 3819.8110, d_loss: 0.46226054, g_loss: 1.04530716\n",
      "Epoch: [ 1] [1321/1582] time: 3821.0640, d_loss: 0.49259654, g_loss: 0.99063075\n",
      "Epoch: [ 1] [1322/1582] time: 3822.3190, d_loss: 0.50998676, g_loss: 0.94418603\n",
      "Epoch: [ 1] [1323/1582] time: 3823.5739, d_loss: 0.61896974, g_loss: 0.85809493\n",
      "Epoch: [ 1] [1324/1582] time: 3824.8289, d_loss: 0.68351668, g_loss: 0.79106897\n",
      "Epoch: [ 1] [1325/1582] time: 3826.0838, d_loss: 0.85910600, g_loss: 0.65876412\n",
      "Epoch: [ 1] [1326/1582] time: 3827.3388, d_loss: 1.02528048, g_loss: 0.61790562\n",
      "Epoch: [ 1] [1327/1582] time: 3828.5928, d_loss: 1.22692060, g_loss: 0.50426459\n",
      "Epoch: [ 1] [1328/1582] time: 3829.8477, d_loss: 1.36684382, g_loss: 0.42885876\n",
      "Epoch: [ 1] [1329/1582] time: 3831.1017, d_loss: 1.54252684, g_loss: 0.41487581\n",
      "Epoch: [ 1] [1330/1582] time: 3832.3567, d_loss: 1.69395709, g_loss: 0.39647502\n",
      "Epoch: [ 1] [1331/1582] time: 3833.6126, d_loss: 1.59457123, g_loss: 0.37685388\n",
      "Epoch: [ 1] [1332/1582] time: 3834.8706, d_loss: 1.44289100, g_loss: 0.41953170\n",
      "Epoch: [ 1] [1333/1582] time: 3836.1256, d_loss: 1.22488904, g_loss: 0.53187644\n",
      "Epoch: [ 1] [1334/1582] time: 3837.3805, d_loss: 0.97947955, g_loss: 0.68031430\n",
      "Epoch: [ 1] [1335/1582] time: 3838.6345, d_loss: 0.80168933, g_loss: 0.90358883\n",
      "Epoch: [ 1] [1336/1582] time: 3839.8894, d_loss: 0.52478009, g_loss: 1.30531895\n",
      "Epoch: [ 1] [1337/1582] time: 3841.1414, d_loss: 0.37857670, g_loss: 1.82755518\n",
      "Epoch: [ 1] [1338/1582] time: 3842.3954, d_loss: 0.23648492, g_loss: 2.30354929\n",
      "Epoch: [ 1] [1339/1582] time: 3843.6503, d_loss: 0.33671924, g_loss: 2.55852604\n",
      "Epoch: [ 1] [1340/1582] time: 3844.9056, d_loss: 0.26613736, g_loss: 2.66246295\n",
      "Epoch: [ 1] [1341/1582] time: 3846.1586, d_loss: 0.33598661, g_loss: 2.38635826\n",
      "Epoch: [ 1] [1342/1582] time: 3847.4136, d_loss: 0.36856073, g_loss: 2.06623816\n",
      "Epoch: [ 1] [1343/1582] time: 3848.6705, d_loss: 0.77961808, g_loss: 1.60457850\n",
      "Epoch: [ 1] [1344/1582] time: 3849.9385, d_loss: 0.74178475, g_loss: 1.24997234\n",
      "Epoch: [ 1] [1345/1582] time: 3851.1934, d_loss: 0.91169828, g_loss: 0.94284487\n",
      "Epoch: [ 1] [1346/1582] time: 3852.4504, d_loss: 1.04942274, g_loss: 0.82906884\n",
      "Epoch: [ 1] [1347/1582] time: 3853.7044, d_loss: 1.11069226, g_loss: 0.69535011\n",
      "Epoch: [ 1] [1348/1582] time: 3854.9623, d_loss: 1.24669755, g_loss: 0.56138909\n",
      "Epoch: [ 1] [1349/1582] time: 3856.2183, d_loss: 1.41792166, g_loss: 0.43424970\n",
      "Epoch: [ 1] [1350/1582] time: 3857.4743, d_loss: 1.52483976, g_loss: 0.35151303\n",
      "Epoch: [ 1] [1351/1582] time: 3858.7332, d_loss: 1.47348034, g_loss: 0.31893429\n",
      "Epoch: [ 1] [1352/1582] time: 3859.9912, d_loss: 1.52325892, g_loss: 0.27828425\n",
      "Epoch: [ 1] [1353/1582] time: 3861.2451, d_loss: 1.40057206, g_loss: 0.30859539\n",
      "Epoch: [ 1] [1354/1582] time: 3862.4999, d_loss: 1.45499504, g_loss: 0.29994386\n",
      "Epoch: [ 1] [1355/1582] time: 3863.7539, d_loss: 1.18868387, g_loss: 0.39724398\n",
      "Epoch: [ 1] [1356/1582] time: 3865.0108, d_loss: 1.04341185, g_loss: 0.50591159\n",
      "Epoch: [ 1] [1357/1582] time: 3866.2648, d_loss: 0.86005306, g_loss: 0.69979995\n",
      "Epoch: [ 1] [1358/1582] time: 3867.5207, d_loss: 0.79524350, g_loss: 0.85922778\n",
      "Epoch: [ 1] [1359/1582] time: 3868.7778, d_loss: 0.78183925, g_loss: 0.94626617\n",
      "Epoch: [ 1] [1360/1582] time: 3870.0325, d_loss: 0.70911235, g_loss: 1.01244879\n",
      "Epoch: [ 1] [1361/1582] time: 3871.2875, d_loss: 0.73147893, g_loss: 1.00237429\n",
      "Epoch: [ 1] [1362/1582] time: 3872.5434, d_loss: 0.68027711, g_loss: 0.94117880\n",
      "Epoch: [ 1] [1363/1582] time: 3873.7994, d_loss: 0.70956463, g_loss: 0.99433124\n",
      "Epoch: [ 1] [1364/1582] time: 3875.0558, d_loss: 0.80821395, g_loss: 0.91144478\n",
      "Epoch: [ 1] [1365/1582] time: 3876.3116, d_loss: 0.69365287, g_loss: 0.89396328\n",
      "Epoch: [ 1] [1366/1582] time: 3877.5706, d_loss: 0.64560765, g_loss: 0.98554182\n",
      "Epoch: [ 1] [1367/1582] time: 3878.8315, d_loss: 0.68188047, g_loss: 1.08015728\n",
      "Epoch: [ 1] [1368/1582] time: 3880.0903, d_loss: 0.67047685, g_loss: 1.13100159\n",
      "Epoch: [ 1] [1369/1582] time: 3881.3443, d_loss: 0.69189870, g_loss: 1.11320674\n",
      "Epoch: [ 1] [1370/1582] time: 3882.5998, d_loss: 0.69385314, g_loss: 1.15309930\n",
      "Epoch: [ 1] [1371/1582] time: 3883.8548, d_loss: 0.65849793, g_loss: 1.13208926\n",
      "Epoch: [ 1] [1372/1582] time: 3885.1107, d_loss: 0.63982069, g_loss: 1.11226952\n",
      "Epoch: [ 1] [1373/1582] time: 3886.3655, d_loss: 0.64646554, g_loss: 1.10170317\n",
      "Epoch: [ 1] [1374/1582] time: 3887.6195, d_loss: 0.65272379, g_loss: 1.05982542\n",
      "Epoch: [ 1] [1375/1582] time: 3888.8734, d_loss: 0.61008734, g_loss: 1.14088345\n",
      "Epoch: [ 1] [1376/1582] time: 3890.1294, d_loss: 0.60714811, g_loss: 1.09794700\n",
      "Epoch: [ 1] [1377/1582] time: 3891.3834, d_loss: 0.65218508, g_loss: 1.02854586\n",
      "Epoch: [ 1] [1378/1582] time: 3892.6373, d_loss: 0.65362066, g_loss: 0.95455837\n",
      "Epoch: [ 1] [1379/1582] time: 3893.8933, d_loss: 0.69695961, g_loss: 0.92448395\n",
      "Epoch: [ 1] [1380/1582] time: 3895.1512, d_loss: 0.72626573, g_loss: 0.82031149\n",
      "Epoch: [ 1] [1381/1582] time: 3896.4062, d_loss: 0.68070132, g_loss: 0.79768306\n",
      "Epoch: [ 1] [1382/1582] time: 3897.6632, d_loss: 0.79627025, g_loss: 0.72180343\n",
      "Epoch: [ 1] [1383/1582] time: 3898.9181, d_loss: 0.78061366, g_loss: 0.70579982\n",
      "Epoch: [ 1] [1384/1582] time: 3900.1746, d_loss: 0.78186923, g_loss: 0.70203066\n",
      "Epoch: [ 1] [1385/1582] time: 3901.4285, d_loss: 0.75218797, g_loss: 0.73098922\n",
      "Epoch: [ 1] [1386/1582] time: 3902.6835, d_loss: 0.69042623, g_loss: 0.76449960\n",
      "Epoch: [ 1] [1387/1582] time: 3903.9405, d_loss: 0.71269971, g_loss: 0.75775838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1] [1388/1582] time: 3905.1984, d_loss: 0.76650417, g_loss: 0.75848877\n",
      "Epoch: [ 1] [1389/1582] time: 3906.4534, d_loss: 0.75468516, g_loss: 0.79666817\n",
      "Epoch: [ 1] [1390/1582] time: 3907.7084, d_loss: 0.84827602, g_loss: 0.70105797\n",
      "Epoch: [ 1] [1391/1582] time: 3908.9653, d_loss: 1.00519443, g_loss: 0.60947514\n",
      "Epoch: [ 1] [1392/1582] time: 3910.2253, d_loss: 0.80089891, g_loss: 0.61224067\n",
      "Epoch: [ 1] [1393/1582] time: 3911.4852, d_loss: 0.98465484, g_loss: 0.57413000\n",
      "Epoch: [ 1] [1394/1582] time: 3912.7462, d_loss: 0.93092811, g_loss: 0.55790031\n",
      "Epoch: [ 1] [1395/1582] time: 3914.0052, d_loss: 1.09026372, g_loss: 0.52476335\n",
      "Epoch: [ 1] [1396/1582] time: 3915.2631, d_loss: 1.12065303, g_loss: 0.48630631\n",
      "Epoch: [ 1] [1397/1582] time: 3916.5191, d_loss: 1.09411788, g_loss: 0.48322964\n",
      "Epoch: [ 1] [1398/1582] time: 3917.7750, d_loss: 1.10127103, g_loss: 0.45491618\n",
      "Epoch: [ 1] [1399/1582] time: 3919.0320, d_loss: 1.10620379, g_loss: 0.46416879\n",
      "Epoch: [ 1] [1400/1582] time: 3920.2870, d_loss: 1.02634108, g_loss: 0.48544347\n",
      "Epoch: [ 1] [1401/1582] time: 3921.5450, d_loss: 1.06615877, g_loss: 0.50035942\n",
      "Epoch: [ 1] [1402/1582] time: 3922.8009, d_loss: 1.03299940, g_loss: 0.50578856\n",
      "Epoch: [ 1] [1403/1582] time: 3924.0579, d_loss: 1.01042283, g_loss: 0.50772589\n",
      "Epoch: [ 1] [1404/1582] time: 3925.3151, d_loss: 0.92580414, g_loss: 0.55198830\n",
      "Epoch: [ 1] [1405/1582] time: 3926.5710, d_loss: 0.96352041, g_loss: 0.53834212\n",
      "Epoch: [ 1] [1406/1582] time: 3927.8290, d_loss: 0.93563259, g_loss: 0.51098287\n",
      "Epoch: [ 1] [1407/1582] time: 3929.0870, d_loss: 0.88047278, g_loss: 0.53279775\n",
      "Epoch: [ 1] [1408/1582] time: 3930.3442, d_loss: 0.90312791, g_loss: 0.55308151\n",
      "Epoch: [ 1] [1409/1582] time: 3931.6002, d_loss: 0.89834714, g_loss: 0.53382224\n",
      "Epoch: [ 1] [1410/1582] time: 3932.8572, d_loss: 0.92779005, g_loss: 0.54279894\n",
      "Epoch: [ 1] [1411/1582] time: 3934.1171, d_loss: 0.87288147, g_loss: 0.56105685\n",
      "Epoch: [ 1] [1412/1582] time: 3935.3761, d_loss: 0.82241762, g_loss: 0.59297562\n",
      "Epoch: [ 1] [1413/1582] time: 3936.6350, d_loss: 0.83867681, g_loss: 0.60208827\n",
      "Epoch: [ 1] [1414/1582] time: 3937.8950, d_loss: 0.92477918, g_loss: 0.58799833\n",
      "Epoch: [ 1] [1415/1582] time: 3939.1503, d_loss: 0.85103232, g_loss: 0.58321744\n",
      "Epoch: [ 1] [1416/1582] time: 3940.4033, d_loss: 0.86238432, g_loss: 0.60387540\n",
      "Epoch: [ 1] [1417/1582] time: 3941.6597, d_loss: 0.86288202, g_loss: 0.59213519\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 1] [1418/1582] time: 3950.2732, d_loss: 0.80337775, g_loss: 0.63840735\n",
      "Epoch: [ 1] [1419/1582] time: 3951.5282, d_loss: 0.74696535, g_loss: 0.67252511\n",
      "Epoch: [ 1] [1420/1582] time: 3952.7831, d_loss: 0.76869035, g_loss: 0.69452953\n",
      "Epoch: [ 1] [1421/1582] time: 3954.0391, d_loss: 0.86200374, g_loss: 0.63329285\n",
      "Epoch: [ 1] [1422/1582] time: 3955.2931, d_loss: 0.82385814, g_loss: 0.59836030\n",
      "Epoch: [ 1] [1423/1582] time: 3956.5471, d_loss: 0.85326266, g_loss: 0.58408022\n",
      "Epoch: [ 1] [1424/1582] time: 3957.8061, d_loss: 0.82354099, g_loss: 0.57187247\n",
      "Epoch: [ 1] [1425/1582] time: 3959.0933, d_loss: 0.81668043, g_loss: 0.57200217\n",
      "Epoch: [ 1] [1426/1582] time: 3960.3616, d_loss: 0.82050598, g_loss: 0.61609101\n",
      "Epoch: [ 1] [1427/1582] time: 3961.6286, d_loss: 0.83487117, g_loss: 0.63410389\n",
      "Epoch: [ 1] [1428/1582] time: 3962.8950, d_loss: 0.79995418, g_loss: 0.64735645\n",
      "Epoch: [ 1] [1429/1582] time: 3964.1550, d_loss: 0.80625874, g_loss: 0.66563070\n",
      "Epoch: [ 1] [1430/1582] time: 3965.4170, d_loss: 0.83450752, g_loss: 0.61749077\n",
      "Epoch: [ 1] [1431/1582] time: 3966.6789, d_loss: 0.93581641, g_loss: 0.56540191\n",
      "Epoch: [ 1] [1432/1582] time: 3967.9389, d_loss: 0.89596337, g_loss: 0.51260066\n",
      "Epoch: [ 1] [1433/1582] time: 3969.1989, d_loss: 0.98277271, g_loss: 0.46221486\n",
      "Epoch: [ 1] [1434/1582] time: 3970.4577, d_loss: 1.04911613, g_loss: 0.44210306\n",
      "Epoch: [ 1] [1435/1582] time: 3971.7166, d_loss: 1.03455329, g_loss: 0.43089703\n",
      "Epoch: [ 1] [1436/1582] time: 3972.9756, d_loss: 1.05045700, g_loss: 0.41427577\n",
      "Epoch: [ 1] [1437/1582] time: 3974.2337, d_loss: 1.05549920, g_loss: 0.41123405\n",
      "Epoch: [ 1] [1438/1582] time: 3975.4936, d_loss: 1.03725374, g_loss: 0.41677439\n",
      "Epoch: [ 1] [1439/1582] time: 3976.7556, d_loss: 1.06968868, g_loss: 0.41466683\n",
      "Epoch: [ 1] [1440/1582] time: 3978.0186, d_loss: 0.94280630, g_loss: 0.46489900\n",
      "Epoch: [ 1] [1441/1582] time: 3979.2798, d_loss: 0.96373802, g_loss: 0.48321441\n",
      "Epoch: [ 1] [1442/1582] time: 3980.5410, d_loss: 0.98188263, g_loss: 0.47505325\n",
      "Epoch: [ 1] [1443/1582] time: 3981.8080, d_loss: 0.93993264, g_loss: 0.50093704\n",
      "Epoch: [ 1] [1444/1582] time: 3983.0688, d_loss: 0.96133190, g_loss: 0.50683749\n",
      "Epoch: [ 1] [1445/1582] time: 3984.3248, d_loss: 0.91905624, g_loss: 0.53009683\n",
      "Epoch: [ 1] [1446/1582] time: 3985.5828, d_loss: 0.90856969, g_loss: 0.50152040\n",
      "Epoch: [ 1] [1447/1582] time: 3986.8397, d_loss: 0.89267081, g_loss: 0.50812173\n",
      "Epoch: [ 1] [1448/1582] time: 3988.1008, d_loss: 0.90766633, g_loss: 0.50002569\n",
      "Epoch: [ 1] [1449/1582] time: 3989.3618, d_loss: 0.93434203, g_loss: 0.50684887\n",
      "Epoch: [ 1] [1450/1582] time: 3990.6238, d_loss: 0.90690744, g_loss: 0.49007890\n",
      "Epoch: [ 1] [1451/1582] time: 3991.8818, d_loss: 0.93734932, g_loss: 0.47141773\n",
      "Epoch: [ 1] [1452/1582] time: 3993.2757, d_loss: 0.90347457, g_loss: 0.50355774\n",
      "Epoch: [ 1] [1453/1582] time: 3994.5393, d_loss: 0.89066446, g_loss: 0.50459093\n",
      "Epoch: [ 1] [1454/1582] time: 3995.8092, d_loss: 0.89511299, g_loss: 0.52670926\n",
      "Epoch: [ 1] [1455/1582] time: 3997.1052, d_loss: 0.88462824, g_loss: 0.53521264\n",
      "Epoch: [ 1] [1456/1582] time: 3998.3822, d_loss: 0.87330210, g_loss: 0.56754249\n",
      "Epoch: [ 1] [1457/1582] time: 3999.6581, d_loss: 0.85596812, g_loss: 0.59007347\n",
      "Epoch: [ 1] [1458/1582] time: 4000.9231, d_loss: 0.78489327, g_loss: 0.59773326\n",
      "Epoch: [ 1] [1459/1582] time: 4002.1841, d_loss: 0.79331684, g_loss: 0.62026572\n",
      "Epoch: [ 1] [1460/1582] time: 4003.4440, d_loss: 0.85329735, g_loss: 0.61797929\n",
      "Epoch: [ 1] [1461/1582] time: 4004.7040, d_loss: 0.82038355, g_loss: 0.62291729\n",
      "Epoch: [ 1] [1462/1582] time: 4005.9679, d_loss: 0.81787103, g_loss: 0.65449369\n",
      "Epoch: [ 1] [1463/1582] time: 4007.2409, d_loss: 0.80576485, g_loss: 0.62607360\n",
      "Epoch: [ 1] [1464/1582] time: 4008.5393, d_loss: 0.81968540, g_loss: 0.63945800\n",
      "Epoch: [ 1] [1465/1582] time: 4009.8433, d_loss: 0.80476743, g_loss: 0.61724782\n",
      "Epoch: [ 1] [1466/1582] time: 4011.1363, d_loss: 0.84240860, g_loss: 0.66103297\n",
      "Epoch: [ 1] [1467/1582] time: 4012.4372, d_loss: 0.80677712, g_loss: 0.65692532\n",
      "Epoch: [ 1] [1468/1582] time: 4013.7265, d_loss: 0.78968513, g_loss: 0.63412720\n",
      "Epoch: [ 1] [1469/1582] time: 4015.0225, d_loss: 0.81026787, g_loss: 0.67890638\n",
      "Epoch: [ 1] [1470/1582] time: 4016.3095, d_loss: 0.75442535, g_loss: 0.71885967\n",
      "Epoch: [ 1] [1471/1582] time: 4017.5995, d_loss: 0.76974839, g_loss: 0.76401931\n",
      "Epoch: [ 1] [1472/1582] time: 4018.8954, d_loss: 0.73887312, g_loss: 0.80773509\n",
      "Epoch: [ 1] [1473/1582] time: 4020.1974, d_loss: 0.65683943, g_loss: 0.88235056\n",
      "Epoch: [ 1] [1474/1582] time: 4021.4984, d_loss: 0.62284970, g_loss: 0.96282190\n",
      "Epoch: [ 1] [1475/1582] time: 4022.7873, d_loss: 0.55155092, g_loss: 1.04670942\n",
      "Epoch: [ 1] [1476/1582] time: 4024.0523, d_loss: 0.48542845, g_loss: 1.19054174\n",
      "Epoch: [ 1] [1477/1582] time: 4025.3292, d_loss: 0.53001982, g_loss: 1.36534977\n",
      "Epoch: [ 1] [1478/1582] time: 4026.6062, d_loss: 0.46735415, g_loss: 1.33333743\n",
      "Epoch: [ 1] [1479/1582] time: 4027.8864, d_loss: 0.37564987, g_loss: 1.48616314\n",
      "Epoch: [ 1] [1480/1582] time: 4029.1914, d_loss: 0.37226933, g_loss: 1.50893974\n",
      "Epoch: [ 1] [1481/1582] time: 4030.4644, d_loss: 0.38083667, g_loss: 1.63638127\n",
      "Epoch: [ 1] [1482/1582] time: 4031.7481, d_loss: 0.45935068, g_loss: 1.41104317\n",
      "Epoch: [ 1] [1483/1582] time: 4033.0345, d_loss: 0.51049763, g_loss: 1.17279804\n",
      "Epoch: [ 1] [1484/1582] time: 4034.3115, d_loss: 0.56663477, g_loss: 1.00644588\n",
      "Epoch: [ 1] [1485/1582] time: 4035.5845, d_loss: 0.61298645, g_loss: 0.91528648\n",
      "Epoch: [ 1] [1486/1582] time: 4036.8624, d_loss: 0.90917122, g_loss: 0.77271837\n",
      "Epoch: [ 1] [1487/1582] time: 4038.1364, d_loss: 0.88379407, g_loss: 0.68367416\n",
      "Epoch: [ 1] [1488/1582] time: 4039.3984, d_loss: 0.96767330, g_loss: 0.61818326\n",
      "Epoch: [ 1] [1489/1582] time: 4040.6683, d_loss: 0.92773372, g_loss: 0.55883718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1] [1490/1582] time: 4041.9313, d_loss: 0.94665837, g_loss: 0.56087887\n",
      "Epoch: [ 1] [1491/1582] time: 4043.1992, d_loss: 0.91073072, g_loss: 0.57866693\n",
      "Epoch: [ 1] [1492/1582] time: 4044.4790, d_loss: 0.83933347, g_loss: 0.59954274\n",
      "Epoch: [ 1] [1493/1582] time: 4045.7600, d_loss: 0.78169215, g_loss: 0.60580629\n",
      "Epoch: [ 1] [1494/1582] time: 4047.0430, d_loss: 0.80261034, g_loss: 0.64477211\n",
      "Epoch: [ 1] [1495/1582] time: 4048.3199, d_loss: 0.77660185, g_loss: 0.65437919\n",
      "Epoch: [ 1] [1496/1582] time: 4049.5759, d_loss: 0.69240338, g_loss: 0.71519995\n",
      "Epoch: [ 1] [1497/1582] time: 4050.8448, d_loss: 0.73343259, g_loss: 0.71489704\n",
      "Epoch: [ 1] [1498/1582] time: 4052.1198, d_loss: 0.73090321, g_loss: 0.69252688\n",
      "Epoch: [ 1] [1499/1582] time: 4053.3829, d_loss: 0.77542365, g_loss: 0.66396540\n",
      "Epoch: [ 1] [1500/1582] time: 4054.6495, d_loss: 0.75482255, g_loss: 0.64445382\n",
      "Epoch: [ 1] [1501/1582] time: 4055.9115, d_loss: 0.88673198, g_loss: 0.59565616\n",
      "Epoch: [ 1] [1502/1582] time: 4057.1715, d_loss: 0.81133354, g_loss: 0.57317406\n",
      "Epoch: [ 1] [1503/1582] time: 4058.4294, d_loss: 0.91537404, g_loss: 0.54164690\n",
      "Epoch: [ 1] [1504/1582] time: 4059.6924, d_loss: 0.87830025, g_loss: 0.53824437\n",
      "Epoch: [ 1] [1505/1582] time: 4060.9504, d_loss: 0.95134622, g_loss: 0.49326313\n",
      "Epoch: [ 1] [1506/1582] time: 4062.2103, d_loss: 1.00587082, g_loss: 0.49133408\n",
      "Epoch: [ 1] [1507/1582] time: 4063.4783, d_loss: 1.03407097, g_loss: 0.47740602\n",
      "Epoch: [ 1] [1508/1582] time: 4064.7552, d_loss: 1.08373141, g_loss: 0.48281628\n",
      "Epoch: [ 1] [1509/1582] time: 4066.0242, d_loss: 1.14772069, g_loss: 0.46813178\n",
      "Epoch: [ 1] [1510/1582] time: 4067.2842, d_loss: 1.04745436, g_loss: 0.45174873\n",
      "Epoch: [ 1] [1511/1582] time: 4068.5491, d_loss: 1.11092901, g_loss: 0.45193014\n",
      "Epoch: [ 1] [1512/1582] time: 4069.8096, d_loss: 1.06548083, g_loss: 0.47797751\n",
      "Epoch: [ 1] [1513/1582] time: 4071.0656, d_loss: 1.01393390, g_loss: 0.49829265\n",
      "Epoch: [ 1] [1514/1582] time: 4072.3266, d_loss: 0.98354292, g_loss: 0.54106551\n",
      "Epoch: [ 1] [1515/1582] time: 4073.5865, d_loss: 0.94570220, g_loss: 0.58108723\n",
      "Epoch: [ 1] [1516/1582] time: 4074.8465, d_loss: 0.84939528, g_loss: 0.63598013\n",
      "Epoch: [ 1] [1517/1582] time: 4076.1054, d_loss: 0.75906980, g_loss: 0.73689604\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 1] [1518/1582] time: 4084.3424, d_loss: 0.81322020, g_loss: 0.76229012\n",
      "Epoch: [ 1] [1519/1582] time: 4085.5994, d_loss: 0.72728121, g_loss: 0.88046741\n",
      "Epoch: [ 1] [1520/1582] time: 4086.8603, d_loss: 0.77842128, g_loss: 0.75908291\n",
      "Epoch: [ 1] [1521/1582] time: 4088.1262, d_loss: 0.82448035, g_loss: 0.80298471\n",
      "Epoch: [ 1] [1522/1582] time: 4089.3942, d_loss: 0.82340670, g_loss: 0.70135343\n",
      "Epoch: [ 1] [1523/1582] time: 4090.6661, d_loss: 0.68658453, g_loss: 0.75579357\n",
      "Epoch: [ 1] [1524/1582] time: 4091.9391, d_loss: 0.69301599, g_loss: 0.85422117\n",
      "Epoch: [ 1] [1525/1582] time: 4093.2047, d_loss: 0.65404755, g_loss: 0.91461027\n",
      "Epoch: [ 1] [1526/1582] time: 4094.4707, d_loss: 0.61004084, g_loss: 1.01293111\n",
      "Epoch: [ 1] [1527/1582] time: 4095.7306, d_loss: 0.66892350, g_loss: 0.91405749\n",
      "Epoch: [ 1] [1528/1582] time: 4096.9956, d_loss: 0.69135922, g_loss: 0.94977319\n",
      "Epoch: [ 1] [1529/1582] time: 4098.2696, d_loss: 0.61442602, g_loss: 0.89774066\n",
      "Epoch: [ 1] [1530/1582] time: 4099.5473, d_loss: 0.66279912, g_loss: 0.78973520\n",
      "Epoch: [ 1] [1531/1582] time: 4100.8152, d_loss: 0.67859691, g_loss: 0.79380757\n",
      "Epoch: [ 1] [1532/1582] time: 4102.0832, d_loss: 0.75971228, g_loss: 0.73397237\n",
      "Epoch: [ 1] [1533/1582] time: 4103.3481, d_loss: 0.84566683, g_loss: 0.64208639\n",
      "Epoch: [ 1] [1534/1582] time: 4104.6203, d_loss: 0.91485900, g_loss: 0.61916685\n",
      "Epoch: [ 1] [1535/1582] time: 4105.8883, d_loss: 0.98313242, g_loss: 0.57462668\n",
      "Epoch: [ 1] [1536/1582] time: 4107.1553, d_loss: 1.10166955, g_loss: 0.49891797\n",
      "Epoch: [ 1] [1537/1582] time: 4108.4195, d_loss: 1.10533631, g_loss: 0.48188129\n",
      "Epoch: [ 1] [1538/1582] time: 4109.6944, d_loss: 1.11364961, g_loss: 0.48636737\n",
      "Epoch: [ 1] [1539/1582] time: 4110.9617, d_loss: 1.07019413, g_loss: 0.49974805\n",
      "Epoch: [ 1] [1540/1582] time: 4112.2336, d_loss: 0.91728568, g_loss: 0.52033710\n",
      "Epoch: [ 1] [1541/1582] time: 4113.5016, d_loss: 0.92980599, g_loss: 0.55128980\n",
      "Epoch: [ 1] [1542/1582] time: 4114.7796, d_loss: 0.95260435, g_loss: 0.57544005\n",
      "Epoch: [ 1] [1543/1582] time: 4116.0475, d_loss: 0.84625727, g_loss: 0.58499807\n",
      "Epoch: [ 1] [1544/1582] time: 4117.3180, d_loss: 0.96545184, g_loss: 0.58098799\n",
      "Epoch: [ 1] [1545/1582] time: 4118.5840, d_loss: 0.86791110, g_loss: 0.57872224\n",
      "Epoch: [ 1] [1546/1582] time: 4119.8510, d_loss: 0.85230261, g_loss: 0.59825844\n",
      "Epoch: [ 1] [1547/1582] time: 4121.1129, d_loss: 0.81939960, g_loss: 0.63953876\n",
      "Epoch: [ 1] [1548/1582] time: 4122.3789, d_loss: 0.85228860, g_loss: 0.64453733\n",
      "Epoch: [ 1] [1549/1582] time: 4123.6458, d_loss: 0.82838631, g_loss: 0.65413773\n",
      "Epoch: [ 1] [1550/1582] time: 4124.9092, d_loss: 0.79840612, g_loss: 0.70213580\n",
      "Epoch: [ 1] [1551/1582] time: 4126.1712, d_loss: 0.77221555, g_loss: 0.70059419\n",
      "Epoch: [ 1] [1552/1582] time: 4127.4412, d_loss: 0.82031578, g_loss: 0.72673869\n",
      "Epoch: [ 1] [1553/1582] time: 4128.7121, d_loss: 0.81438828, g_loss: 0.74405128\n",
      "Epoch: [ 1] [1554/1582] time: 4129.9740, d_loss: 0.82654947, g_loss: 0.74941730\n",
      "Epoch: [ 1] [1555/1582] time: 4131.2359, d_loss: 0.83666354, g_loss: 0.76537526\n",
      "Epoch: [ 1] [1556/1582] time: 4132.5025, d_loss: 0.81952083, g_loss: 0.79822814\n",
      "Epoch: [ 1] [1557/1582] time: 4133.7735, d_loss: 0.89328301, g_loss: 0.82842767\n",
      "Epoch: [ 1] [1558/1582] time: 4135.0475, d_loss: 0.77714455, g_loss: 0.91823006\n",
      "Epoch: [ 1] [1559/1582] time: 4136.3147, d_loss: 0.84779871, g_loss: 0.93128747\n",
      "Epoch: [ 1] [1560/1582] time: 4137.5913, d_loss: 0.92786896, g_loss: 0.92795432\n",
      "Epoch: [ 1] [1561/1582] time: 4138.8633, d_loss: 0.84856999, g_loss: 0.86174977\n",
      "Epoch: [ 1] [1562/1582] time: 4140.1283, d_loss: 0.86755288, g_loss: 0.84971321\n",
      "Epoch: [ 1] [1563/1582] time: 4141.3915, d_loss: 0.98765600, g_loss: 0.82827842\n",
      "Epoch: [ 1] [1564/1582] time: 4142.6605, d_loss: 1.17952752, g_loss: 0.70983553\n",
      "Epoch: [ 1] [1565/1582] time: 4143.9225, d_loss: 1.19782007, g_loss: 0.62748432\n",
      "Epoch: [ 1] [1566/1582] time: 4145.1914, d_loss: 1.16632700, g_loss: 0.55723298\n",
      "Epoch: [ 1] [1567/1582] time: 4146.4534, d_loss: 1.31726646, g_loss: 0.47266713\n",
      "Epoch: [ 1] [1568/1582] time: 4147.7158, d_loss: 1.31427956, g_loss: 0.43751696\n",
      "Epoch: [ 1] [1569/1582] time: 4148.9804, d_loss: 1.21195972, g_loss: 0.46396422\n",
      "Epoch: [ 1] [1570/1582] time: 4150.2513, d_loss: 1.21170878, g_loss: 0.48214322\n",
      "Epoch: [ 1] [1571/1582] time: 4151.5333, d_loss: 1.11202955, g_loss: 0.53783602\n",
      "Epoch: [ 1] [1572/1582] time: 4152.8103, d_loss: 1.05017459, g_loss: 0.59196699\n",
      "Epoch: [ 1] [1573/1582] time: 4154.0822, d_loss: 0.96331120, g_loss: 0.64873123\n",
      "Epoch: [ 1] [1574/1582] time: 4155.3472, d_loss: 0.94068205, g_loss: 0.68545872\n",
      "Epoch: [ 1] [1575/1582] time: 4156.6071, d_loss: 0.91742539, g_loss: 0.63864970\n",
      "Epoch: [ 1] [1576/1582] time: 4157.8681, d_loss: 0.93954211, g_loss: 0.63551021\n",
      "Epoch: [ 1] [1577/1582] time: 4159.1281, d_loss: 0.88891780, g_loss: 0.63642228\n",
      "Epoch: [ 1] [1578/1582] time: 4160.3905, d_loss: 0.93095148, g_loss: 0.56161052\n",
      "Epoch: [ 1] [1579/1582] time: 4161.6484, d_loss: 0.87857932, g_loss: 0.53944051\n",
      "Epoch: [ 1] [1580/1582] time: 4162.9055, d_loss: 0.95426691, g_loss: 0.55222952\n",
      "Epoch: [ 1] [1581/1582] time: 4164.1640, d_loss: 0.82210755, g_loss: 0.60611016\n",
      "Epoch: [ 2] [   0/1582] time: 4165.4409, d_loss: 0.86152583, g_loss: 0.61485934\n",
      "Epoch: [ 2] [   1/1582] time: 4166.6973, d_loss: 0.88754356, g_loss: 0.59380496\n",
      "Epoch: [ 2] [   2/1582] time: 4167.9593, d_loss: 0.87798893, g_loss: 0.58738142\n",
      "Epoch: [ 2] [   3/1582] time: 4169.2262, d_loss: 0.81660366, g_loss: 0.59931910\n",
      "Epoch: [ 2] [   4/1582] time: 4170.4867, d_loss: 0.86083031, g_loss: 0.62698966\n",
      "Epoch: [ 2] [   5/1582] time: 4171.7506, d_loss: 0.96553218, g_loss: 0.58557272\n",
      "Epoch: [ 2] [   6/1582] time: 4173.0136, d_loss: 0.91943586, g_loss: 0.59146196\n",
      "Epoch: [ 2] [   7/1582] time: 4174.2761, d_loss: 0.83052301, g_loss: 0.62420177\n",
      "Epoch: [ 2] [   8/1582] time: 4175.5431, d_loss: 0.84969395, g_loss: 0.66851699\n",
      "Epoch: [ 2] [   9/1582] time: 4176.8050, d_loss: 0.78893977, g_loss: 0.72098106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 2] [  10/1582] time: 4178.0750, d_loss: 0.85578054, g_loss: 0.73083568\n",
      "Epoch: [ 2] [  11/1582] time: 4179.3499, d_loss: 0.83237690, g_loss: 0.70935404\n",
      "Epoch: [ 2] [  12/1582] time: 4180.6169, d_loss: 1.00209320, g_loss: 0.67520577\n",
      "Epoch: [ 2] [  13/1582] time: 4181.8859, d_loss: 0.99283445, g_loss: 0.62981814\n",
      "Epoch: [ 2] [  14/1582] time: 4183.1648, d_loss: 1.32764161, g_loss: 0.48989898\n",
      "Epoch: [ 2] [  15/1582] time: 4184.4408, d_loss: 1.26516497, g_loss: 0.48003581\n",
      "Epoch: [ 2] [  16/1582] time: 4185.7187, d_loss: 1.35267460, g_loss: 0.42512912\n",
      "Epoch: [ 2] [  17/1582] time: 4186.9947, d_loss: 1.19354880, g_loss: 0.44242007\n",
      "Epoch: [ 2] [  18/1582] time: 4188.2627, d_loss: 1.25024927, g_loss: 0.44644308\n",
      "Epoch: [ 2] [  19/1582] time: 4189.5246, d_loss: 1.17954934, g_loss: 0.46692422\n",
      "Epoch: [ 2] [  20/1582] time: 4190.7840, d_loss: 1.08939481, g_loss: 0.50779492\n",
      "Epoch: [ 2] [  21/1582] time: 4192.0489, d_loss: 0.95819020, g_loss: 0.57538211\n",
      "Epoch: [ 2] [  22/1582] time: 4193.3089, d_loss: 1.01679778, g_loss: 0.63095003\n",
      "Epoch: [ 2] [  23/1582] time: 4194.5740, d_loss: 0.95770741, g_loss: 0.63510406\n",
      "Epoch: [ 2] [  24/1582] time: 4195.8359, d_loss: 0.99724799, g_loss: 0.60795170\n",
      "Epoch: [ 2] [  25/1582] time: 4197.0958, d_loss: 0.97865963, g_loss: 0.58558583\n",
      "Epoch: [ 2] [  26/1582] time: 4198.3568, d_loss: 0.97478741, g_loss: 0.54678541\n",
      "Epoch: [ 2] [  27/1582] time: 4199.6147, d_loss: 0.93098384, g_loss: 0.53712726\n",
      "Epoch: [ 2] [  28/1582] time: 4200.8767, d_loss: 0.97440225, g_loss: 0.51928687\n",
      "Epoch: [ 2] [  29/1582] time: 4202.1367, d_loss: 0.93524945, g_loss: 0.53508484\n",
      "Epoch: [ 2] [  30/1582] time: 4203.3996, d_loss: 0.90507019, g_loss: 0.55799031\n",
      "Epoch: [ 2] [  31/1582] time: 4204.6606, d_loss: 0.84883666, g_loss: 0.59625596\n",
      "Epoch: [ 2] [  32/1582] time: 4205.9225, d_loss: 0.80453348, g_loss: 0.64878345\n",
      "Epoch: [ 2] [  33/1582] time: 4207.1825, d_loss: 0.79250753, g_loss: 0.70007443\n",
      "Epoch: [ 2] [  34/1582] time: 4208.4435, d_loss: 0.79430354, g_loss: 0.72029090\n",
      "Epoch: [ 2] [  35/1582] time: 4209.7044, d_loss: 0.71853805, g_loss: 0.75297391\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 2] [  36/1582] time: 4217.9727, d_loss: 0.74436837, g_loss: 0.75636172\n",
      "Epoch: [ 2] [  37/1582] time: 4219.2328, d_loss: 0.67824614, g_loss: 0.76732737\n",
      "Epoch: [ 2] [  38/1582] time: 4220.4940, d_loss: 0.70844471, g_loss: 0.78831553\n",
      "Epoch: [ 2] [  39/1582] time: 4221.7500, d_loss: 0.67934275, g_loss: 0.81343007\n",
      "Epoch: [ 2] [  40/1582] time: 4223.0095, d_loss: 0.70448035, g_loss: 0.79185772\n",
      "Epoch: [ 2] [  41/1582] time: 4224.2644, d_loss: 0.66245389, g_loss: 0.81318986\n",
      "Epoch: [ 2] [  42/1582] time: 4225.5294, d_loss: 0.65022290, g_loss: 0.82489324\n",
      "Epoch: [ 2] [  43/1582] time: 4226.7881, d_loss: 0.70590317, g_loss: 0.79825711\n",
      "Epoch: [ 2] [  44/1582] time: 4228.0495, d_loss: 0.72413802, g_loss: 0.76800096\n",
      "Epoch: [ 2] [  45/1582] time: 4229.3075, d_loss: 0.65684807, g_loss: 0.79034907\n",
      "Epoch: [ 2] [  46/1582] time: 4230.5715, d_loss: 0.72128129, g_loss: 0.76949525\n",
      "Epoch: [ 2] [  47/1582] time: 4231.8284, d_loss: 0.66409636, g_loss: 0.76966602\n",
      "Epoch: [ 2] [  48/1582] time: 4233.0896, d_loss: 0.69682789, g_loss: 0.80065739\n",
      "Epoch: [ 2] [  49/1582] time: 4234.3485, d_loss: 0.68915993, g_loss: 0.81384766\n",
      "Epoch: [ 2] [  50/1582] time: 4235.6105, d_loss: 0.67728716, g_loss: 0.79796171\n",
      "Epoch: [ 2] [  51/1582] time: 4236.8691, d_loss: 0.73384416, g_loss: 0.78604513\n",
      "Epoch: [ 2] [  52/1582] time: 4238.1301, d_loss: 0.83591062, g_loss: 0.73522848\n",
      "Epoch: [ 2] [  53/1582] time: 4239.3870, d_loss: 0.72195768, g_loss: 0.70751184\n",
      "Epoch: [ 2] [  54/1582] time: 4240.6570, d_loss: 0.83189648, g_loss: 0.73901004\n",
      "Epoch: [ 2] [  55/1582] time: 4241.9170, d_loss: 0.89025718, g_loss: 0.65864515\n",
      "Epoch: [ 2] [  56/1582] time: 4243.1806, d_loss: 0.88114309, g_loss: 0.65040612\n",
      "Epoch: [ 2] [  57/1582] time: 4244.4456, d_loss: 0.94377506, g_loss: 0.58537507\n",
      "Epoch: [ 2] [  58/1582] time: 4245.7083, d_loss: 1.04065943, g_loss: 0.56532598\n",
      "Epoch: [ 2] [  59/1582] time: 4246.9732, d_loss: 1.21302950, g_loss: 0.49610049\n",
      "Epoch: [ 2] [  60/1582] time: 4248.2482, d_loss: 1.23383081, g_loss: 0.43345010\n",
      "Epoch: [ 2] [  61/1582] time: 4249.5242, d_loss: 1.30858421, g_loss: 0.39869294\n",
      "Epoch: [ 2] [  62/1582] time: 4250.8101, d_loss: 1.32213891, g_loss: 0.35632646\n",
      "Epoch: [ 2] [  63/1582] time: 4252.0839, d_loss: 1.34222674, g_loss: 0.36140376\n",
      "Epoch: [ 2] [  64/1582] time: 4253.3609, d_loss: 1.37025154, g_loss: 0.37375739\n",
      "Epoch: [ 2] [  65/1582] time: 4254.6248, d_loss: 1.31177950, g_loss: 0.35222030\n",
      "Epoch: [ 2] [  66/1582] time: 4255.8878, d_loss: 1.29183304, g_loss: 0.37606549\n",
      "Epoch: [ 2] [  67/1582] time: 4257.1477, d_loss: 1.09177279, g_loss: 0.43194461\n",
      "Epoch: [ 2] [  68/1582] time: 4258.4057, d_loss: 1.05925775, g_loss: 0.45950365\n",
      "Epoch: [ 2] [  69/1582] time: 4259.6650, d_loss: 1.01497555, g_loss: 0.49201545\n",
      "Epoch: [ 2] [  70/1582] time: 4261.0819, d_loss: 0.96570820, g_loss: 0.54980403\n",
      "Epoch: [ 2] [  71/1582] time: 4262.3495, d_loss: 0.82939625, g_loss: 0.61020571\n",
      "Epoch: [ 2] [  72/1582] time: 4263.6289, d_loss: 0.79265058, g_loss: 0.63823378\n",
      "Epoch: [ 2] [  73/1582] time: 4264.8929, d_loss: 0.77244025, g_loss: 0.71904790\n",
      "Epoch: [ 2] [  74/1582] time: 4266.1538, d_loss: 0.71316361, g_loss: 0.75627184\n",
      "Epoch: [ 2] [  75/1582] time: 4267.4108, d_loss: 0.71168464, g_loss: 0.83197349\n",
      "Epoch: [ 2] [  76/1582] time: 4268.6698, d_loss: 0.68744451, g_loss: 0.81160289\n",
      "Epoch: [ 2] [  77/1582] time: 4269.9317, d_loss: 0.66746753, g_loss: 0.87246549\n",
      "Epoch: [ 2] [  78/1582] time: 4271.2127, d_loss: 0.67931956, g_loss: 0.82258934\n",
      "Epoch: [ 2] [  79/1582] time: 4272.4857, d_loss: 0.74690819, g_loss: 0.80794406\n",
      "Epoch: [ 2] [  80/1582] time: 4273.7576, d_loss: 0.72009224, g_loss: 0.78015065\n",
      "Epoch: [ 2] [  81/1582] time: 4275.0176, d_loss: 0.71822405, g_loss: 0.74673665\n",
      "Epoch: [ 2] [  82/1582] time: 4276.2816, d_loss: 0.71906602, g_loss: 0.73565030\n",
      "Epoch: [ 2] [  83/1582] time: 4277.5485, d_loss: 0.75666064, g_loss: 0.66728425\n",
      "Epoch: [ 2] [  84/1582] time: 4278.8249, d_loss: 0.85226655, g_loss: 0.67028844\n",
      "Epoch: [ 2] [  85/1582] time: 4280.0879, d_loss: 1.09119177, g_loss: 0.56349182\n",
      "Epoch: [ 2] [  86/1582] time: 4281.3679, d_loss: 1.00420964, g_loss: 0.56936353\n",
      "Epoch: [ 2] [  87/1582] time: 4282.6510, d_loss: 1.07133567, g_loss: 0.53995198\n",
      "Epoch: [ 2] [  88/1582] time: 4283.9256, d_loss: 1.18102205, g_loss: 0.52489722\n",
      "Epoch: [ 2] [  89/1582] time: 4285.1925, d_loss: 1.29126060, g_loss: 0.44175005\n",
      "Epoch: [ 2] [  90/1582] time: 4286.4595, d_loss: 1.21848786, g_loss: 0.45038497\n",
      "Epoch: [ 2] [  91/1582] time: 4287.7265, d_loss: 1.26627433, g_loss: 0.47067171\n",
      "Epoch: [ 2] [  92/1582] time: 4288.9884, d_loss: 1.20706677, g_loss: 0.41582465\n",
      "Epoch: [ 2] [  93/1582] time: 4290.2484, d_loss: 1.19495356, g_loss: 0.45292321\n",
      "Epoch: [ 2] [  94/1582] time: 4291.5114, d_loss: 1.17456818, g_loss: 0.46858764\n",
      "Epoch: [ 2] [  95/1582] time: 4292.7735, d_loss: 1.12258482, g_loss: 0.42863217\n",
      "Epoch: [ 2] [  96/1582] time: 4294.0355, d_loss: 1.09674263, g_loss: 0.46963322\n",
      "Epoch: [ 2] [  97/1582] time: 4295.2955, d_loss: 1.07898974, g_loss: 0.46173859\n",
      "Epoch: [ 2] [  98/1582] time: 4296.5574, d_loss: 1.09658289, g_loss: 0.46283439\n",
      "Epoch: [ 2] [  99/1582] time: 4297.8174, d_loss: 1.05189776, g_loss: 0.46895346\n",
      "Epoch: [ 2] [ 100/1582] time: 4299.0794, d_loss: 1.09961784, g_loss: 0.45043996\n",
      "Epoch: [ 2] [ 101/1582] time: 4300.3383, d_loss: 1.06882131, g_loss: 0.43867093\n",
      "Epoch: [ 2] [ 102/1582] time: 4301.5987, d_loss: 1.14854789, g_loss: 0.39590842\n",
      "Epoch: [ 2] [ 103/1582] time: 4302.8687, d_loss: 1.17221701, g_loss: 0.39962566\n",
      "Epoch: [ 2] [ 104/1582] time: 4304.1306, d_loss: 1.15689385, g_loss: 0.39943951\n",
      "Epoch: [ 2] [ 105/1582] time: 4305.4036, d_loss: 1.15323627, g_loss: 0.38151231\n",
      "Epoch: [ 2] [ 106/1582] time: 4306.6650, d_loss: 1.20008218, g_loss: 0.36939377\n",
      "Epoch: [ 2] [ 107/1582] time: 4307.9283, d_loss: 1.19909322, g_loss: 0.36756849\n",
      "Epoch: [ 2] [ 108/1582] time: 4309.2022, d_loss: 1.17494082, g_loss: 0.39429212\n",
      "Epoch: [ 2] [ 109/1582] time: 4310.4874, d_loss: 1.11610317, g_loss: 0.41993350\n",
      "Epoch: [ 2] [ 110/1582] time: 4311.7613, d_loss: 1.11467767, g_loss: 0.46194592\n",
      "Epoch: [ 2] [ 111/1582] time: 4313.0283, d_loss: 1.12605476, g_loss: 0.48522270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 2] [ 112/1582] time: 4314.2934, d_loss: 1.12224829, g_loss: 0.50137758\n",
      "Epoch: [ 2] [ 113/1582] time: 4315.5562, d_loss: 1.13712919, g_loss: 0.46292600\n",
      "Epoch: [ 2] [ 114/1582] time: 4316.8201, d_loss: 1.13671541, g_loss: 0.48071641\n",
      "Epoch: [ 2] [ 115/1582] time: 4318.0819, d_loss: 1.12036872, g_loss: 0.49427772\n",
      "Epoch: [ 2] [ 116/1582] time: 4319.3408, d_loss: 1.08256662, g_loss: 0.50147140\n",
      "Epoch: [ 2] [ 117/1582] time: 4320.6015, d_loss: 0.99225873, g_loss: 0.58497441\n",
      "Epoch: [ 2] [ 118/1582] time: 4321.8625, d_loss: 0.91557693, g_loss: 0.71930277\n",
      "Epoch: [ 2] [ 119/1582] time: 4323.1224, d_loss: 0.84848726, g_loss: 0.77642751\n",
      "Epoch: [ 2] [ 120/1582] time: 4324.3854, d_loss: 0.80450231, g_loss: 0.80867755\n",
      "Epoch: [ 2] [ 121/1582] time: 4325.6442, d_loss: 0.77708948, g_loss: 0.81749237\n",
      "Epoch: [ 2] [ 122/1582] time: 4326.9052, d_loss: 0.75172764, g_loss: 0.80276179\n",
      "Epoch: [ 2] [ 123/1582] time: 4328.1654, d_loss: 0.76987052, g_loss: 0.80242395\n",
      "Epoch: [ 2] [ 124/1582] time: 4329.4269, d_loss: 0.78024477, g_loss: 0.71028918\n",
      "Epoch: [ 2] [ 125/1582] time: 4330.6859, d_loss: 0.77152985, g_loss: 0.64268756\n",
      "Epoch: [ 2] [ 126/1582] time: 4331.9478, d_loss: 0.77040654, g_loss: 0.65173578\n",
      "Epoch: [ 2] [ 127/1582] time: 4333.2088, d_loss: 0.81324583, g_loss: 0.67891556\n",
      "Epoch: [ 2] [ 128/1582] time: 4334.4678, d_loss: 0.80941057, g_loss: 0.63563490\n",
      "Epoch: [ 2] [ 129/1582] time: 4335.7287, d_loss: 0.85046810, g_loss: 0.59025300\n",
      "Epoch: [ 2] [ 130/1582] time: 4337.0017, d_loss: 0.87929016, g_loss: 0.57242703\n",
      "Epoch: [ 2] [ 131/1582] time: 4338.2586, d_loss: 0.96467298, g_loss: 0.52355200\n",
      "Epoch: [ 2] [ 132/1582] time: 4339.5176, d_loss: 0.93743557, g_loss: 0.51092678\n",
      "Epoch: [ 2] [ 133/1582] time: 4340.7786, d_loss: 0.91168678, g_loss: 0.52283573\n",
      "Epoch: [ 2] [ 134/1582] time: 4342.0365, d_loss: 0.88437641, g_loss: 0.53408635\n",
      "Epoch: [ 2] [ 135/1582] time: 4343.2945, d_loss: 0.87761223, g_loss: 0.53842700\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 2] [ 136/1582] time: 4351.5473, d_loss: 0.87196624, g_loss: 0.56802464\n",
      "Epoch: [ 2] [ 137/1582] time: 4352.8322, d_loss: 0.79179847, g_loss: 0.61952358\n",
      "Epoch: [ 2] [ 138/1582] time: 4354.1102, d_loss: 0.81324166, g_loss: 0.62763953\n",
      "Epoch: [ 2] [ 139/1582] time: 4355.3902, d_loss: 0.77764225, g_loss: 0.64094615\n",
      "Epoch: [ 2] [ 140/1582] time: 4356.6816, d_loss: 0.78399980, g_loss: 0.65091008\n",
      "Epoch: [ 2] [ 141/1582] time: 4357.9456, d_loss: 0.82085812, g_loss: 0.64215195\n",
      "Epoch: [ 2] [ 142/1582] time: 4359.2173, d_loss: 0.83335400, g_loss: 0.62883282\n",
      "Epoch: [ 2] [ 143/1582] time: 4360.4988, d_loss: 0.82877702, g_loss: 0.59206259\n",
      "Epoch: [ 2] [ 144/1582] time: 4361.7687, d_loss: 0.94307452, g_loss: 0.58181667\n",
      "Epoch: [ 2] [ 145/1582] time: 4363.0387, d_loss: 0.89413148, g_loss: 0.58624339\n",
      "Epoch: [ 2] [ 146/1582] time: 4364.2993, d_loss: 1.01411402, g_loss: 0.54336971\n",
      "Epoch: [ 2] [ 147/1582] time: 4365.5594, d_loss: 0.95219982, g_loss: 0.58637023\n",
      "Epoch: [ 2] [ 148/1582] time: 4366.8214, d_loss: 0.92233044, g_loss: 0.58913606\n",
      "Epoch: [ 2] [ 149/1582] time: 4368.0823, d_loss: 0.85251927, g_loss: 0.62465727\n",
      "Epoch: [ 2] [ 150/1582] time: 4369.3443, d_loss: 0.97532356, g_loss: 0.60459548\n",
      "Epoch: [ 2] [ 151/1582] time: 4370.6093, d_loss: 0.96543252, g_loss: 0.60756356\n",
      "Epoch: [ 2] [ 152/1582] time: 4371.8843, d_loss: 1.03844583, g_loss: 0.55613387\n",
      "Epoch: [ 2] [ 153/1582] time: 4373.1700, d_loss: 1.07992554, g_loss: 0.57105321\n",
      "Epoch: [ 2] [ 154/1582] time: 4374.4535, d_loss: 1.21024358, g_loss: 0.53706014\n",
      "Epoch: [ 2] [ 155/1582] time: 4375.7174, d_loss: 1.12762523, g_loss: 0.55106920\n",
      "Epoch: [ 2] [ 156/1582] time: 4376.9954, d_loss: 1.03955364, g_loss: 0.58695447\n",
      "Epoch: [ 2] [ 157/1582] time: 4378.3074, d_loss: 1.12394321, g_loss: 0.57307130\n",
      "Epoch: [ 2] [ 158/1582] time: 4379.5804, d_loss: 1.17444730, g_loss: 0.58605802\n",
      "Epoch: [ 2] [ 159/1582] time: 4380.8484, d_loss: 1.17736578, g_loss: 0.57108319\n",
      "Epoch: [ 2] [ 160/1582] time: 4382.1183, d_loss: 1.27898395, g_loss: 0.54141092\n",
      "Epoch: [ 2] [ 161/1582] time: 4383.4168, d_loss: 1.38653624, g_loss: 0.52003455\n",
      "Epoch: [ 2] [ 162/1582] time: 4384.7218, d_loss: 1.37473822, g_loss: 0.53133297\n",
      "Epoch: [ 2] [ 163/1582] time: 4386.0277, d_loss: 1.32506490, g_loss: 0.50428957\n",
      "Epoch: [ 2] [ 164/1582] time: 4387.3337, d_loss: 1.17233253, g_loss: 0.55274200\n",
      "Epoch: [ 2] [ 165/1582] time: 4388.6306, d_loss: 1.01652837, g_loss: 0.60251749\n",
      "Epoch: [ 2] [ 166/1582] time: 4389.9526, d_loss: 0.89758319, g_loss: 0.67154622\n",
      "Epoch: [ 2] [ 167/1582] time: 4391.2723, d_loss: 1.06068635, g_loss: 0.63583440\n",
      "Epoch: [ 2] [ 168/1582] time: 4392.5913, d_loss: 1.03406918, g_loss: 0.63450599\n",
      "Epoch: [ 2] [ 169/1582] time: 4393.9097, d_loss: 0.99610144, g_loss: 0.63941914\n",
      "Epoch: [ 2] [ 170/1582] time: 4395.2317, d_loss: 0.93837565, g_loss: 0.65447891\n",
      "Epoch: [ 2] [ 171/1582] time: 4396.5517, d_loss: 0.93861431, g_loss: 0.68161255\n",
      "Epoch: [ 2] [ 172/1582] time: 4397.8706, d_loss: 0.80842608, g_loss: 0.75982720\n",
      "Epoch: [ 2] [ 173/1582] time: 4399.1856, d_loss: 0.85863721, g_loss: 0.82394910\n",
      "Epoch: [ 2] [ 174/1582] time: 4400.5011, d_loss: 0.68263191, g_loss: 0.90487051\n",
      "Epoch: [ 2] [ 175/1582] time: 4401.8220, d_loss: 0.68405342, g_loss: 0.99462748\n",
      "Epoch: [ 2] [ 176/1582] time: 4403.1445, d_loss: 0.72691232, g_loss: 1.07446742\n",
      "Epoch: [ 2] [ 177/1582] time: 4404.4606, d_loss: 0.71728551, g_loss: 0.95109433\n",
      "Epoch: [ 2] [ 178/1582] time: 4405.7816, d_loss: 0.64321196, g_loss: 0.96389043\n",
      "Epoch: [ 2] [ 179/1582] time: 4407.1001, d_loss: 0.70111918, g_loss: 0.85822976\n",
      "Epoch: [ 2] [ 180/1582] time: 4408.4492, d_loss: 0.73628247, g_loss: 0.79552996\n",
      "Epoch: [ 2] [ 181/1582] time: 4409.7151, d_loss: 0.78452468, g_loss: 0.74967802\n",
      "Epoch: [ 2] [ 182/1582] time: 4410.9945, d_loss: 0.79725683, g_loss: 0.68201107\n",
      "Epoch: [ 2] [ 183/1582] time: 4412.2601, d_loss: 0.74786711, g_loss: 0.66911346\n",
      "Epoch: [ 2] [ 184/1582] time: 4413.5280, d_loss: 0.73278356, g_loss: 0.71056283\n",
      "Epoch: [ 2] [ 185/1582] time: 4414.7960, d_loss: 0.79601991, g_loss: 0.71163487\n",
      "Epoch: [ 2] [ 186/1582] time: 4416.1080, d_loss: 0.77584916, g_loss: 0.72845179\n",
      "Epoch: [ 2] [ 187/1582] time: 4417.4099, d_loss: 0.77434224, g_loss: 0.71081936\n",
      "Epoch: [ 2] [ 188/1582] time: 4418.7039, d_loss: 0.82232845, g_loss: 0.67662525\n",
      "Epoch: [ 2] [ 189/1582] time: 4420.0278, d_loss: 0.85032386, g_loss: 0.64505684\n",
      "Epoch: [ 2] [ 190/1582] time: 4421.3235, d_loss: 0.92002004, g_loss: 0.59235328\n",
      "Epoch: [ 2] [ 191/1582] time: 4422.6044, d_loss: 0.96350968, g_loss: 0.54766232\n",
      "Epoch: [ 2] [ 192/1582] time: 4423.8753, d_loss: 0.96561182, g_loss: 0.51521504\n",
      "Epoch: [ 2] [ 193/1582] time: 4425.1743, d_loss: 1.02945685, g_loss: 0.49698246\n",
      "Epoch: [ 2] [ 194/1582] time: 4426.4483, d_loss: 0.97837830, g_loss: 0.47163558\n",
      "Epoch: [ 2] [ 195/1582] time: 4427.7242, d_loss: 1.06562269, g_loss: 0.46257880\n",
      "Epoch: [ 2] [ 196/1582] time: 4429.0322, d_loss: 1.11003256, g_loss: 0.47856110\n",
      "Epoch: [ 2] [ 197/1582] time: 4430.3049, d_loss: 1.09128642, g_loss: 0.45675817\n",
      "Epoch: [ 2] [ 198/1582] time: 4431.5819, d_loss: 1.11366677, g_loss: 0.45489216\n",
      "Epoch: [ 2] [ 199/1582] time: 4432.8639, d_loss: 1.07948458, g_loss: 0.43885350\n",
      "Epoch: [ 2] [ 200/1582] time: 4434.1328, d_loss: 1.14720106, g_loss: 0.45449811\n",
      "Epoch: [ 2] [ 201/1582] time: 4435.4108, d_loss: 1.07374060, g_loss: 0.44206327\n",
      "Epoch: [ 2] [ 202/1582] time: 4436.6802, d_loss: 1.03833616, g_loss: 0.46474093\n",
      "Epoch: [ 2] [ 203/1582] time: 4437.9901, d_loss: 1.02463710, g_loss: 0.48679525\n",
      "Epoch: [ 2] [ 204/1582] time: 4439.2611, d_loss: 1.02290189, g_loss: 0.50199234\n",
      "Epoch: [ 2] [ 205/1582] time: 4440.5271, d_loss: 1.03469861, g_loss: 0.53616679\n",
      "Epoch: [ 2] [ 206/1582] time: 4441.7967, d_loss: 0.95686758, g_loss: 0.58669043\n",
      "Epoch: [ 2] [ 207/1582] time: 4443.0747, d_loss: 0.89762664, g_loss: 0.60143971\n",
      "Epoch: [ 2] [ 208/1582] time: 4444.3486, d_loss: 0.85694766, g_loss: 0.66870272\n",
      "Epoch: [ 2] [ 209/1582] time: 4445.6321, d_loss: 0.87007451, g_loss: 0.71947104\n",
      "Epoch: [ 2] [ 210/1582] time: 4446.9110, d_loss: 0.91587865, g_loss: 0.70032442\n",
      "Epoch: [ 2] [ 211/1582] time: 4448.1876, d_loss: 0.81407255, g_loss: 0.73518479\n",
      "Epoch: [ 2] [ 212/1582] time: 4449.4656, d_loss: 0.81521589, g_loss: 0.71688437\n",
      "Epoch: [ 2] [ 213/1582] time: 4450.7659, d_loss: 0.77962756, g_loss: 0.76183784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 2] [ 214/1582] time: 4452.0470, d_loss: 0.76031959, g_loss: 0.74301338\n",
      "Epoch: [ 2] [ 215/1582] time: 4453.3279, d_loss: 0.79528368, g_loss: 0.76577735\n",
      "Epoch: [ 2] [ 216/1582] time: 4454.6169, d_loss: 0.75540876, g_loss: 0.72494841\n",
      "Epoch: [ 2] [ 217/1582] time: 4455.8810, d_loss: 0.76213920, g_loss: 0.79312503\n",
      "Epoch: [ 2] [ 218/1582] time: 4457.1492, d_loss: 0.71039045, g_loss: 0.80971789\n",
      "Epoch: [ 2] [ 219/1582] time: 4458.4327, d_loss: 0.77166069, g_loss: 0.78635663\n",
      "Epoch: [ 2] [ 220/1582] time: 4459.7197, d_loss: 0.82838684, g_loss: 0.73863226\n",
      "Epoch: [ 2] [ 221/1582] time: 4460.9977, d_loss: 0.78674054, g_loss: 0.66486204\n",
      "Epoch: [ 2] [ 222/1582] time: 4462.2817, d_loss: 0.84293675, g_loss: 0.62909055\n",
      "Epoch: [ 2] [ 223/1582] time: 4463.5506, d_loss: 0.99478483, g_loss: 0.52278435\n",
      "Epoch: [ 2] [ 224/1582] time: 4464.8136, d_loss: 1.06203139, g_loss: 0.48312297\n",
      "Epoch: [ 2] [ 225/1582] time: 4466.0826, d_loss: 1.10834289, g_loss: 0.42608148\n",
      "Epoch: [ 2] [ 226/1582] time: 4467.3506, d_loss: 1.08220220, g_loss: 0.40488610\n",
      "Epoch: [ 2] [ 227/1582] time: 4468.6345, d_loss: 1.06524408, g_loss: 0.41424137\n",
      "Epoch: [ 2] [ 228/1582] time: 4469.9195, d_loss: 1.06892836, g_loss: 0.42958325\n",
      "Epoch: [ 2] [ 229/1582] time: 4471.2065, d_loss: 1.07806063, g_loss: 0.44066849\n",
      "Epoch: [ 2] [ 230/1582] time: 4472.4884, d_loss: 1.07419729, g_loss: 0.45342916\n",
      "Epoch: [ 2] [ 231/1582] time: 4473.7641, d_loss: 1.07640195, g_loss: 0.46543041\n",
      "Epoch: [ 2] [ 232/1582] time: 4475.0401, d_loss: 1.04044247, g_loss: 0.49350077\n",
      "Epoch: [ 2] [ 233/1582] time: 4476.3476, d_loss: 1.07784200, g_loss: 0.49292904\n",
      "Epoch: [ 2] [ 234/1582] time: 4477.6125, d_loss: 0.97714931, g_loss: 0.54438472\n",
      "Epoch: [ 2] [ 235/1582] time: 4478.8768, d_loss: 1.02405560, g_loss: 0.53770733\n",
      "Saved model\n",
      "(128, 64, 64, 3)\n",
      "Sample\n",
      "Epoch: [ 2] [ 236/1582] time: 4486.9101, d_loss: 1.05031490, g_loss: 0.55207169\n",
      "Epoch: [ 2] [ 237/1582] time: 4488.1940, d_loss: 0.94961280, g_loss: 0.58280134\n",
      "Epoch: [ 2] [ 238/1582] time: 4489.4910, d_loss: 0.93239951, g_loss: 0.64699805\n",
      "Epoch: [ 2] [ 239/1582] time: 4490.7735, d_loss: 0.85595304, g_loss: 0.72564077\n",
      "Epoch: [ 2] [ 240/1582] time: 4492.0504, d_loss: 0.77880657, g_loss: 0.81425315\n",
      "Epoch: [ 2] [ 241/1582] time: 4493.3364, d_loss: 0.73261034, g_loss: 0.90404832\n",
      "Epoch: [ 2] [ 242/1582] time: 4494.6074, d_loss: 0.69043469, g_loss: 0.95575839\n",
      "Epoch: [ 2] [ 243/1582] time: 4495.9443, d_loss: 0.66523850, g_loss: 0.93851340\n",
      "Epoch: [ 2] [ 244/1582] time: 4497.2050, d_loss: 0.66255319, g_loss: 0.96080148\n",
      "Epoch: [ 2] [ 245/1582] time: 4498.4639, d_loss: 0.67340648, g_loss: 0.90659529\n",
      "Epoch: [ 2] [ 246/1582] time: 4499.7249, d_loss: 0.64107615, g_loss: 0.78185177\n",
      "Epoch: [ 2] [ 247/1582] time: 4500.9904, d_loss: 0.74167430, g_loss: 0.78371876\n",
      "Epoch: [ 2] [ 248/1582] time: 4502.2554, d_loss: 0.70401537, g_loss: 0.73315346\n",
      "Epoch: [ 2] [ 249/1582] time: 4503.5153, d_loss: 0.72515315, g_loss: 0.75154299\n",
      "Epoch: [ 2] [ 250/1582] time: 4504.8019, d_loss: 0.72334516, g_loss: 0.72497439\n",
      "Epoch: [ 2] [ 251/1582] time: 4506.1909, d_loss: 0.73013049, g_loss: 0.71458030\n",
      "Epoch: [ 2] [ 252/1582] time: 4507.4708, d_loss: 0.87122583, g_loss: 0.64141500\n",
      "Epoch: [ 2] [ 253/1582] time: 4508.7393, d_loss: 0.86908185, g_loss: 0.58686751\n",
      "Epoch: [ 2] [ 254/1582] time: 4510.0483, d_loss: 0.98026776, g_loss: 0.51752782\n",
      "Epoch: [ 2] [ 255/1582] time: 4511.3099, d_loss: 1.08991599, g_loss: 0.44632402\n",
      "Epoch: [ 2] [ 256/1582] time: 4512.6078, d_loss: 1.06703877, g_loss: 0.43254361\n",
      "Epoch: [ 2] [ 257/1582] time: 4513.8948, d_loss: 1.23445177, g_loss: 0.39196661\n",
      "Epoch: [ 2] [ 258/1582] time: 4515.2028, d_loss: 1.25064659, g_loss: 0.36806706\n",
      "Epoch: [ 2] [ 259/1582] time: 4516.5149, d_loss: 1.22282135, g_loss: 0.37712705\n",
      "Epoch: [ 2] [ 260/1582] time: 4517.7869, d_loss: 1.28879881, g_loss: 0.38943627\n",
      "Epoch: [ 2] [ 261/1582] time: 4519.0929, d_loss: 1.26300299, g_loss: 0.36408699\n",
      "Epoch: [ 2] [ 262/1582] time: 4520.3823, d_loss: 1.29285264, g_loss: 0.36701334\n",
      "Epoch: [ 2] [ 263/1582] time: 4521.6483, d_loss: 1.26965177, g_loss: 0.35594612\n",
      "Epoch: [ 2] [ 264/1582] time: 4522.9470, d_loss: 1.32719815, g_loss: 0.37341708\n",
      "Epoch: [ 2] [ 265/1582] time: 4524.2160, d_loss: 1.27934432, g_loss: 0.37480271\n",
      "Epoch: [ 2] [ 266/1582] time: 4525.4830, d_loss: 1.27844214, g_loss: 0.42440236\n",
      "Epoch: [ 2] [ 267/1582] time: 4526.7549, d_loss: 1.27721822, g_loss: 0.44069889\n",
      "Epoch: [ 2] [ 268/1582] time: 4528.0299, d_loss: 1.31670833, g_loss: 0.41669640\n",
      "Epoch: [ 2] [ 269/1582] time: 4529.2960, d_loss: 1.09493423, g_loss: 0.49068967\n",
      "Epoch: [ 2] [ 270/1582] time: 4530.6110, d_loss: 1.09143972, g_loss: 0.57642144\n",
      "Epoch: [ 2] [ 271/1582] time: 4531.8830, d_loss: 1.13223076, g_loss: 0.60194415\n",
      "Epoch: [ 2] [ 272/1582] time: 4533.1615, d_loss: 1.07172942, g_loss: 0.60782135\n",
      "Epoch: [ 2] [ 273/1582] time: 4534.4795, d_loss: 1.11258340, g_loss: 0.58548516\n",
      "Epoch: [ 2] [ 274/1582] time: 4535.7507, d_loss: 1.02052903, g_loss: 0.58615649\n",
      "Epoch: [ 2] [ 275/1582] time: 4537.0244, d_loss: 1.06484568, g_loss: 0.60923284\n",
      "Epoch: [ 2] [ 276/1582] time: 4538.2974, d_loss: 0.92582512, g_loss: 0.69403189\n",
      "Epoch: [ 2] [ 277/1582] time: 4539.5694, d_loss: 0.81128335, g_loss: 0.76628518\n",
      "Epoch: [ 2] [ 278/1582] time: 4540.8523, d_loss: 0.83663791, g_loss: 0.88067186\n",
      "Epoch: [ 2] [ 279/1582] time: 4542.1338, d_loss: 0.74857545, g_loss: 0.90803301\n",
      "Epoch: [ 2] [ 280/1582] time: 4543.4108, d_loss: 0.85862041, g_loss: 0.81561852\n",
      "Epoch: [ 2] [ 281/1582] time: 4544.6848, d_loss: 0.95783401, g_loss: 0.75003153\n",
      "Epoch: [ 2] [ 282/1582] time: 4545.9589, d_loss: 1.04622293, g_loss: 0.69431424\n",
      "Epoch: [ 2] [ 283/1582] time: 4547.2265, d_loss: 1.18335009, g_loss: 0.63196051\n",
      "Epoch: [ 2] [ 284/1582] time: 4548.5465, d_loss: 1.15006745, g_loss: 0.56094635\n",
      "Epoch: [ 2] [ 285/1582] time: 4549.8355, d_loss: 1.21140432, g_loss: 0.57818359\n",
      "Epoch: [ 2] [ 286/1582] time: 4551.0994, d_loss: 1.15011513, g_loss: 0.55310631\n",
      "Epoch: [ 2] [ 287/1582] time: 4552.3719, d_loss: 1.14734411, g_loss: 0.54931450\n",
      "Epoch: [ 2] [ 288/1582] time: 4553.6422, d_loss: 1.11302114, g_loss: 0.55419385\n",
      "Epoch: [ 2] [ 289/1582] time: 4554.9071, d_loss: 1.14960849, g_loss: 0.52616274\n",
      "Epoch: [ 2] [ 290/1582] time: 4556.1851, d_loss: 1.21297097, g_loss: 0.48735183\n",
      "Epoch: [ 2] [ 291/1582] time: 4557.4591, d_loss: 1.30843472, g_loss: 0.40649629\n",
      "Epoch: [ 2] [ 292/1582] time: 4558.7390, d_loss: 1.24674261, g_loss: 0.45417750\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: 'D:\\arkadiumarena_vsts\\cv_course\\w5\\aligned_celebA\\037505.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-99fb032b5272>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'checkpoint'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_frequency\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_generator_update\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-4ccb2b06c148>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(sess, load_dir, save_frequency, sample_frequency, sample_dir, save_dir, max_to_keep, model_name, n_epochs, n_generator_update)\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0mbatch_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mget_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbatch_file\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_files\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m             \u001b[0mbatch_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-4ccb2b06c148>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0mbatch_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mget_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbatch_file\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_files\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m             \u001b[0mbatch_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\arkadiumarena_vsts\\cv_course\\w5\\utils.py\u001b[0m in \u001b[0;36mget_image\u001b[1;34m(image_path, image_size, is_crop)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_crop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_crop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msave_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\arkadiumarena_vsts\\cv_course\\w5\\utils.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mimsave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ml\\lib\\site-packages\\skimage\\io\\_io.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'imread'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ndim'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ml\\lib\\site-packages\\skimage\\io\\manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[1;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m                                (plugin, kind))\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ml\\lib\\site-packages\\skimage\\io\\_plugins\\imageio_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ml\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;31m# Get reader and read first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"i\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ml\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[1;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# Create request object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m     \u001b[0mrequest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;31m# Get format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ml\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, uri, mode, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# Parse what was given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;31m# Set extension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ml\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[1;34m(self, uri)\u001b[0m\n\u001b[0;32m    258\u001b[0m                 \u001b[1;31m# Reading: check that the file exists (but is allowed a dir)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No such file: '%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m                 \u001b[1;31m# Writing: check that the directory to write to does exist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file: 'D:\\arkadiumarena_vsts\\cv_course\\w5\\aligned_celebA\\037505.jpg'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    train(sess, save_dir='checkpoint', n_epochs=100, sample_frequency=100, n_generator_update=2, max_to_keep=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you generated something that looks like a face - it's cool! Add 2 points to your mark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face interpolation (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's interpolate between faces: generate two vectors $z_1$ and $z_2$ and get a batch of vectors of the form $\\alpha\\cdot z_1 + (1- \\alpha)\\cdot  z_2, \\alpha \\in [0,1].$ Generate faces on them and look at results. The generator displays pictures in the range from -1 to 1, so use the inverse transform function from the file utils.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchz = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a smile (1 point + 1 point for good results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's make face smiling. Find several vectors z, such that the generator generates smiling faces and not. Five vectors in every group should be enough (but the more, the better)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Calculate \"smile vector\" as mean of vectors z with generated smile on it minus mean of vectors z with generated not smile on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the result of applying the smile vector: compare the results of generation before and after the addition of the smile vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If faces looks really cool, add bonus 1 point to your score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
